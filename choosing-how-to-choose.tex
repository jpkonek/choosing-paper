\documentclass[a4paper]{article}
\usepackage[pagewise]{lineno}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amsthm}
%\usepackage{a4wide}
\usepackage{setspace}
\usepackage{makeidx}
\usepackage[skip=5pt plus1pt]{parskip}
\usepackage{natbib}
\usepackage{latexsym}
\usepackage[dvipsnames]{xcolor}
\usepackage{tabularx}
\usepackage{enumitem}
\usepackage{makecell}

\usepackage[breaklinks,colorlinks,linkcolor=black,citecolor=black,urlcolor=gray,hypertexnames=false]{hyperref} % the addition of hypertexnames is for autonum
\usepackage[capitalize]{cleveref}
\usepackage{tikz}
\usepackage{xfrac}
\usepackage{wrapfig}
\usepackage{mathpazo}
\usepackage{lscape}
\usepackage{stmaryrd}
%\usepackage{caption}\captionsetup{font=footnotesize} %% CCM: it was breaking labels that come after table!
%\usepackage[USenglish]{babel}
\usepackage{graphicx}

\usepackage{showlabels}


\usepackage{multirow}


% Define "struts" as suggested by Claudio Beccari in
% a piece in TeX and TUG News, Vol. 2, 1993.
\newcommand\Tstrut{\rule{0pt}{2.6ex}}       % "top" strut
\newcommand\Bstrut{\rule[-0.9ex]{0pt}{0pt}} % "bottom" strut
\newcommand{\TBstrut}{\Tstrut\Bstrut} % top&bottom struts


\newtheorem{theorem}{Theorem}[section]
\newtheorem{axiom}{Axiom}
\newtheorem{metatheorem}[theorem]{Metatheorem}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{metadefinition}[theorem]{Metadefinition}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{metaproposition}[theorem]{Metaproposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{metalemma}[theorem]{Metalemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{metacorollary}[theorem]{Metacorollary}
\newtheorem{example}[theorem]{Example}
\newtheorem{ruleinf}{Rule of Inference}
\newtheorem{sublemma}{Sublemma}[theorem]
%\doublespacing

%\linenumbersx

\DeclareMathOperator*{\argmin}{\arg\,\min}
\DeclareMathOperator*{\argmax}{\arg\,\max}

\DeclareMathOperator*{\arginf}{\arg\,\inf}
\DeclareMathOperator*{\argsup}{\arg\,\sup}
\DeclareMathOperator{\posi}{posi}

% Load amsfonts for \mathbb (optional, but recommended)
%\usepackage{amsfonts}
% Load mathbbol to extend \mathbb to Greek letters




	\newcommand{\quotient}[2]{\left.#1\middle/#2\right.}

\newcommand\F{\mathcal{F}}
\newcommand\X{\mathcal{X}}
\newcommand\Y{\mathcal{Y}}
\newcommand\A{\mathcal{A}}
\renewcommand\P{\mathbb{P}} % impreicse prob 
\newcommand\cl{\mathrm{cl}}
%\newcommand\PowN{\imprecpickstrat} % power set of set of prob strategies
\newcommand\Uset{\mathbb{U}} % set of utility functions
\newcommand\Prob{\mathcal{P}} % set of all probs

\newcommand\C{\mathcal{C}}
\newcommand\Exp{\mathsf{Exp}}
\newcommand\RExp{\mathrm{R}\Exp} % Risk-weighted expected utility 
\newcommand\EU{\mathrm{EU}}
\newcommand\MEU{\mathrm{MEU}}
\newcommand\REU{\mathrm{REU}}
\newcommand\EAd{\mathrm{EAd}}
\renewcommand\O{\mathcal{O}}
\newcommand\U{\mathfrak{U}} % utility random variable 
\newcommand\Uwald{\mathcal{U}} % utility random variable 
\newcommand\ut{u}
\newcommand\Maxi{\Gamma\mathrm{M}}
\newcommand\Maximality{\mathrm{Max}}
\newcommand\Maximin{\Gamma}
\newcommand\GD{\mathrm{GD}}

%\newcommand\D{\mathsf{DecProblems}}
\newcommand{\D}{\mathcal{D}}
	\newcommand{\Decs}{\mathcal{D}}
		\newcommand{\mass}{\mathcal{M}}
	
\renewcommand\S{\mathcal{S}}
\newcommand\s{\mathsf{s}}
\renewcommand\c{\mathsf{c}} % choice function

\newcommand{\n}{\mathsf{n}}
\renewcommand{\nu}{\n}
\newcommand\Nu{\mathcal{N}}
\newcommand{\imprecpickstrat}{\mathbb{N}}

\newcommand{\IB}{\mathbb{B}}
\newcommand{\ID}{\mathbb{M}}
\newcommand{\IP}{\P}
\newcommand{\pb}{b}
%\newcommand{b}{}
%\renewcommand{\color}[2]{}
\newcommand{\Dom}{\mathsf{Dom}}


\renewcommand{\Re}{\mathbb{R}}


\renewcommand{\mathsterling}{\text{\normalfont\textsterling}} % to be able to use \pounds in math mode
\newcommand{\million}{\mathrm{m}}   % million shorthand


% CCM added
\usepackage[textsize=footnotesize,obeyFinal,backgroundcolor=orange!50,bordercolor=gray!20,linecolor=gray!20]{todonotes} % use "\PassOptionsToPackage{disable}{todonotes}" to disable in a document
\newcommand{\todoinfo}[2][]{\todo[inline,{#1}]{#2}}
\newcommand{\todoold}[2][]{\todo[backgroundcolor=white,bordercolor=orange!10,linecolor=gray!10, #1,caption={},textcolor=gray]{Pre-rev: #2}}
\newcommand{\comment}[2][]{\todoold[#1]{#2}}
\newcommand{\todooldinfo}[2][]{\todoold[#1]{#2}}
\usepackage{booktabs}  % For improved table formatting


\makeatletter
\@ifclasswith{article}{final}{
	% Redefine commands or settings for the final version.
\renewcommand{\color}[1]{}
}{
	% Alternative definition for when final is not present.
%	\renewcommand{\mycommand}{Draft Version}
}
\makeatother


\usepackage{mathtools} % using it for definition of \Set
\usepackage{autonum} % only number equations referenced to
\usepackage{bm} % get bold greek symbols
\newenvironment{colored}[1]{\leavevmode\color{#1}}{}
\usepackage{nicefrac}

\newcommand{\Strategies}{\S}
\newcommand{\Conv}{\mathsf{ConvHull}}

\newcommand\SetDelimiter[1][]{
	\nonscript\,#1\vert \allowbreak \nonscript\,\mathopen{}}
\providecommand\given{\SetDelimiter}
\DeclarePairedDelimiterX\Set[1]{\lbrace}{\rbrace}%
{ \renewcommand\given{\SetDelimiter[\delimsize]} #1 } % Spacing around \given in a set. \Set{x\given blah} has good spacing. Can also use starred version \Set*{x\given blah} when blah is multilined so it'll stretch to contain everything. 
\DeclarePairedDelimiterX\seq[1]{\langle}{\rangle}%
{ \renewcommand\given{\SetDelimiter[\delimsize]} #1 } % Spacing around \given in a set. \Set{x\given blah} has good spacing. Can also use starred version \Set*{x\given blah} when blah is multilined so it'll stretch to contain everything. 
\DeclarePairedDelimiter\abs{\lvert}{\rvert}%

%\newrobustcmd*{\citefirstlastauthor}{\AtNextCite{\DeclareNameAlias{labelname}{given-family}}\citeauthor}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
%\newcommand{\vec}{def}

\renewcommand{\emptyset}{\varnothing}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}




\newenvironment{CCM rewritten}
{\begingroup\color{blue}} % Begin environment
{\endgroup}              % End environment


\usepackage{versions}
\excludeversion{infversion}

\begin{document}

\title{Choosing How to Choose}
%\date{\today}
\author{Richard Pettigrew, Catrin Campbell-Moore, Jason Konek}
\maketitle

%\tableofcontents


\begin{comment}
	\todooldinfo[inline]{CCM
	
Todo/questions:
\begin{enumerate}
	\item Refs to Teddy?
	\item Indep stuff
	\item imprecise nu and ead?
	\item Add a bit more explicit proof of result for maximality stuff, it's not immediate and I need to think it through to get the non-independence version clear in my head!
	\item ...?
\end{enumerate}
}
\end{comment}


%\todo{somewhere need reference to Seidenfeld ``DECISION THEORY WITHOUT
%	"INDEPENDENCE" OR WITHOUT
%	"ORDERING"''}



%\todooldinfo[color=red]{19/2 - I've come to a halt at least today. The imprecise nu etc is still fluffy. not sure if I'll come back to it soon}
%\todooldinfo{from CCM: red text =  delete, but not ready to do so yet. Purple is stuff I'm considering and think would be good to be}
%CCM trying to rewrite with strategies. 

It is our lot to face decisions when it is uncertain which act from among those available to us will lead to the best outcome. Uncertain about the day's weather, you must choose whether or not to take an umbrella when you leave your house; uncertain about what it would help them most to hear, you must choose what to say to a friend who is going through a bad time; and uncertain what effect different approaches will have, a parent must choose how to raise their child. How are we to make such choices? It is the task of decision theory to provide an answer. And philosophers, economists, and psychologists have met this remit by developing a slew of rival theories of rational decision. Expected utility theory is the most well known and widely used, but there are many alternatives available, and we will meet a good few in the course of this paper.

There are various ways to argue for your preferred decision theory. You might note that it agrees with your intuitive verdict about a specific decision problem that you describe, while its rivals don't. For instance, you might intuitively judge the Allais or Ellsberg preferences rationally permissible, and note that certain risk- or ambiguity-sensitive decision theories permit them, while expected utility theory does not. Or you might note that your favoured theory has a formal feature that you find intuitively desirable, while its rivals lack that feature. For instance, you might intuitively judge the Independence Axiom or the Sure Thing Principle a requirement of rationality, and note that expected utility theory satisfies both, while its risk-sensitive rivals don't.
	
But there is another approach, and it has the advantage that it avoids such appeals to our intuitive judgments and the stalemates in which they often result. It begins with the observation that a decision theory is an account of rational means-ends reasoning: agnostic about whether your ends are good or bad, desirable or undesirable, benevolent or malign, it purports to tell you the rational way to pick between different possible means to the ends you in fact have. Granted this, it seems natural to assess a decision theory by asking how well it performs in the role of getting you those ends. The only problem with this approach is that, in order to assess a decision theory or anything else as a means to your ends, we need an account of which means to your ends it is rational to use. And without a decision theory, we don't have that. 
	
Yet all is not lost, for this line of thinking nonetheless furnishes us with a test we can conduct on a theory of decision-making, and while it might not tell in favour of the theory if it passes, it seems to tell against it if it fails. We can ask of the theory: If I were to use you not only to make my normal day-to-day decisions, but also to make the higher-order decision about which decision theory to use, would you recommend yourself? If it would, we call it \emph{self-recommending}; if it wouldn't, we call it \emph{self-undermining}. We claim that no self-undermining decision theory can be correct. This is not to say that a self-recommending theory is thereby adequate---for instance, the theory that says that any available act is rationally permissible is self-recommending, but it is not correct. Nonetheless, we can use this test to winnow the list of candidate decision theories, removing those that fail it.

	\subsection{Our forthcoming results}

	
	
	In this paper, we show that this idea gives rise to a challenge for a host of theories that diverge from expected utility theory. The strength of our results varies over these different theories, and so we provide a summary here.
	
	Decision theories that accommodate risk, by rationalising the Allais preferences, lead to ways of being uncertain over which decision problem you'll face such that they deem their own recommendations impermissible. Such theories therefore undermine themselves in a particularly strong sense. However, this initial result is limited to particular ways of being uncertain about which decision problem you'll face. We strengthen the result a little by showing the same follows for some natural ways of being uncertain over a much wider range of decisions, but we do not have a general result that holds for a whole host of ways of being uncertain (\Cref{sect:reu}). It is thus still open to a defender of this theory to argue that they are not uncertain over which decision they will face in one of these seemingly natural ways; or at least they should not be. 
	
	Decision theories that accommodate ambiguity or imprecision also differ from expected utility theory. $\Gamma$-Maximin is such a decision theory, and we show that it is self-undermining in the same strong sense just described, at least for certain ways of being uncertain about which decision problem you'll face (\Cref{sect:gamma}).
	
	Two other prominent decision theories for imprecision are E-Admissibility and Maximality. 	
	These theories deem some actions impermissible, but there are often many actions they don't rule out. There are thus typically many different ways of acting that are compatible with the recommendations of the theory. 
	As before, we wish to use a decision theory to judge which decision theory to use by looking at the utility of what the decision theory to be judged recommends you pick. But these imprecise decision theories do not offer univocal recommendations concerning what to pick. Initially, then, we simply consider the theory's judgements about what we call picking strategies, which specify, for each possible decision we might face, a specific act to pick from those that are available. We say that a picking strategy is almost surely an expected utility strategy if there is a probability function over the states of the world such that we are certain the strategy selects an act that maximizes expected utility relative to that probability function.
	 
	E-Admissibility deems a picking strategy impermissible just in case it is not almost surely an expected utility strategy (\Cref{sect:e-admiss}). Since picking in accordance with expected utility theory is also picking in accordance with E-Admissibility, this decision theory is not self-undermining in the strong sense we've considered so far: it does not rule out all ways of picking compatible with itself. However, it does rule some out.
	 It is compatible with E-Admissibility to pick in accordance with different probability functions from the credal set when faced with different decision problems. 
	 Such picking strategies, however, are often deemed impermissible according to the theory.
	 These theories therefore demand a decision-maker coordinates across different possible decision problems to ensure there is a single probability function such that she almost surely chooses what maximizes expected utility from the point of view of that probability function whichever decision problem she faces.
	 
	 The theory also deems it impermissible to pick in accordance with some randomisation procedure over those actions that are not ruled out,
	 as again this does not amount to picking almost surely in accordance with expected utility theory applied to a specific probability function. 
	 We might then ask the defender of one of these theories how our decision-maker should use the non-committal recommendations of their theory? As we've seen, she should not randomise amongst the options that aren't ruled out. Instead, again, she needs to select some probability function from her credal set and use that to determine her plan for what to pick, whatever decision she is faced with. 
	 It is an interesting question how this then differs from a permissivist approach to expected utility theory. 
	 
	 The same formal result also shows that these theories are self-undermining in the same sense if, rather than knowing you'll randomize over the actions the theory hasn't ruled out, you simply don't know which you'll pick, and you have precise credences over the possibilities that gives each positive credence to each.%One might wonder whether we could assign a utility value to the recommendations of the decision theory itself or explicitly consider the utility of adopting a decision theory, whatever that'll lead to, rather than looking at various picking strategies. What will you pick when you've adopted a decision theory which leaves various actions open. It seems natural to us to suggest that you're unsure how you'll pick amongst the options that are not rejected, and you happen to have a precise probability over the possible actions. But this is equivalent to a randomisation procedure. Similarly if we simply specify that the utility of a choice set leaving various options open is a mixture, this again is equivalent to a randomisation procedure. 
	 
	 Next, we ask what happens if, instead of having precise credences concerning which actions you'll pick, you have imprecise credences. We consider how to extend E-Admissibility to judge such imprecise ways of picking.	 
	 We note that each probability function concerning how you'll pick consider the imprecise picking strategy to be sub-optimal; it 
	  prefers instead to adopt a precise expected utility picking strategy. Thus, in the spirit of E-Admissibility, we suggest that the set of probability functions that represents your imprecise credences concerning how you'll pick deems this imprecise picking strategy impermissible too; it again prefers that you select a probability function from the credal set and run with it. 
	 
 	Thus, whilst E-Admissibility is not strictly undermining in the way that $\Gamma$-Maximin and the risk-sensitive decision theories are, our results do force its defenders to think more carefully about what it means to adopt such a theory and how to make use of its advice. It is again an open question to what extent the version of E-Admissibility that renders it self-recommending is like a permissivist version of expected utility theory. %\todo{maybe weaken this claim}
	 
	 Maximality is an alternative prominent decision theory for imprecise probabilities. It is less committal than E-Admissibility (\Cref{sect:Max}). Thus picking in accordance with expected utility theory according to one of the probabilities in the credal set is not rejected by the decision theory. 
	 We can again show that it deems impermissible any way of picking that does not amount to expected utility theory, at least when one's uncertainty over which decisions you'll face has some particular features. When your uncertainty over which decision you'll face is precise and spread over a sufficiently broad range of decisions, the only ways to pick that are not impermissible are those that pick almost surely in accordance with expected utility theory. Again we see that this rules out picking by randomising over the acts that Maximality does not rule out, and it requires modal coordination in how one plans to use the recommendations of the theory. 
	 
%	 For Maximality, 
	 
	 
	 
	 
	
	
%	In these cases, they do not rule out choosing in accordance with expected utility theory as impermissible, they just allow for other picking strategies too. They are thus not undermining in the way that $\Gamma$-maximin or theories accommodating risk were, as \emph{some} ways of acting compatible with the theory are deemed acceptable by the theory. 
%	
%	For E-Admissibility, any way of picking which does not correspond to expected utility theory is deemed impermissible, whatever the uncertainty over possible decisions is.
%	The defender of these theories can argue that what this shows is that one has to hold a deep commitment for coordinating how one picks across various strategies, even though applying E-Admissibility to each decision problem doesn't guarantee this. It requires the user of the theory to first pick a probability function for which they will then plan to pick in accordance with expected utility theory for it in each decision problem, although various probabilities are permitted. 
%	We will also show that the theory deems it impermissible to pick amongst the options which are not ruled out by a randomisation procedure, unless its recommendations already correspond to expected utility theory.
%	Thus, whilst not strictly undermining in the way that the recommendations of the risk-aware decision theories are, it forces the defender of these theories to more carefully consider what it means to adopt such a theory and how to make use of its advice. 
%	
%	For Maximality, we obtain the same results as in the E-Admissibility case, although restricted to cases where one's uncertainty over which decisions you'll face has some particular features. When your uncertainty over which decision you'll be faced with is precise and spread over a sufficiently broad range of decisions, then the only ways to pick which are not impermissible is to pick in accordance with expected utility theory. Thus requiring one's way of picking to be coordinated across different decision problems, and deeming it impermissible to pick using randomisation. 
%	
%	A defender of imprecise probability may argue that one's way of using the decision theory and picking amongst the options that are not ruled out should be captured instead by something of an imprecise nature. For E-Admissibility we also consider how to extend the theory to judge such imprecise ways of picking and see that also here each probability function judges the imprecise picking as sub-optimal, preferring to adopt a precise expected utility picking strategy; and thus, in the spirit of E-Admissibility, the imprecise picking strategy is also deemed impermissible. 
	
	What we see, therefore, is that considerations of whether the decision theory undermines itself lead to challenges for theories that diverge from expected utility theory by accommodating risk or imprecision. In the cases of imprecision, whilst not in a strong sense undermining, as only some ways of picking are deemed impermissible, such considerations force the defenders of these theories to more carefully discuss how to use the theory. 
	



%\section{What does it mean to be self-undermining?}

%We now try to make the foregoing more precise. Throughout, we assume a finite state space $\Omega$ and a set of possible acts $\A$. A utility function $\ut$ is a function that takes any act $a$ in $\A$ and state $\omega$ in $\Omega$ and returns a real number $\ut(a, \omega)$ that gives the utility of $a$ at $\omega$. A \emph{decision problem} $D$ is a finite non-empty set of acts. A \emph{choice function} $C$ takes any decision problem $D$ and returns a non-empty subset $C(D)$ of $D$. A \emph{picking strategy} $\s$ takes any decision problem $D$ and returns a specific act $\s(D)$ in $D$. A \emph{decision theory} is a function that takes in certain representations of an agent's attitudes and returns a choice function. So, for instance, expected utility theory takes in your utility function $u$ and your precise probabilities $p$ over $\Omega$ and returns a choice function $\EU_p$ that selects from any decision problem those acts that maximize expected utility by the lights of your probabilities.% $\EU_p(D) = \Set{a \in D \given (\forall a' \in D)(\Exp_p(\ut(a')) \leq \Exp_p(\ut(a)))}.$

%Now, we wish to take a decision theory and ask it to evaluate itself. We wish to ask it: were you to face a choice between using yourself or using any other decision theory, would you consider it permissible to choose to use yourself? In fact, in the first instance, we will ask decision theories to evaluate not decision theories but picking strategies. This is because it is straightforward to define the utility of a picking strategy: faced with a decision problem $D$ and in a state $\omega$, the utility of $\s$ is $\s(D)(\omega)$; that is, it is the utility, at that state, of the act the picking strategy recommends you choose when faced with that decision problem.





%Decision theories provide an account of which available acts are good or bad at getting you to your ends, whether those ends be love or money or something else, and which we capture with a measure of utility. Now, suppose I ask you to decide how you will choose; that is, I ask you to choose which decision theory will guide your choices. We want to say the utility of a particular decision theory is the utility of the act it leads you to choose. But, of course, for most decision theories, there are decisions in the face of which they will not specify a unique recommended act: they may be indifferent between various acts; or, in the case of imprecise probabilities, they may take various actions to be incomparable and not identify a single action to do but instead just rule out some as impermissible. So, in the first instance, we will use decision theories not to judge decision theories, but to judge what we call \emph{picking strategies}. Given a decision problem, a picking strategy specifies a unique act. So we take the utility of a picking strategy to be the utility of the act it recommends you choose.  This utility depends on what the world is like---for instance, does it rain or not---and also which decision problem you face with the decision theory you use---for instance, do you have to choose whether to take an umbrella when you leave the house, or do you have to choose whether to cancel a picnic you've planned. It is the task of a decision theory to say which means to your ends are acceptable or permissible or choiceworthy, and which should be unacceptable or impermissible or rejectionworthy. Some accounts of decision making undermine themselves: when asked which decision theory to choose, they say of themselves that they are unacceptable or impermissible or rejectionworthy. On the face of it, this is a bad thing for a decision theory to do. We say that such a decision theory is \emph{self-undermining}; of the others, we say they're \emph{self-recommending}. We do not say a self-recommending theory is thereby adequate---for instance, the theory that says that any available act is rationally permissible is self-recommending, but it is not correct. Nonetheless, we can use this test to winnow the list of candidate decision theories, removing those that fail it.




%
%It is our lot to have to make decisions between options with uncertain outcomes. Uncertain about the day's weather, you must choose whether or not to take your umbrella when you leave your house. Uncertain about X, you must choose Y. Decision theories can offer some guidance. 

%Expected utility theory is the most well known theory of rational decision. Depending on your credence that it'll rain, and how much you dislike getting wet, it gives recommendations of whether you should take an umbrella or not. Other decision theories have been developed and are argued for, for example, Lara Buchak's (\citeyear{buchak2014rr}) risk-weighted expected utility theory (REU) and Chris Bottomley\ \&\ Timothy Luke Williamson's (\citeyear{bottomley2024rra}) weighted-linear utility theory (WLU) also take into account one's attitudes towards risk.\footnote{Buchak's theory adapts John Quiggin's (\citeyear{quiggin1982tau,quiggin1993geut})  \emph{rank-dependent utility theory} to allow for subjective probabilities, while Bottomley\ \&\ Williamson's adapts a definition due to Soo Hong Chew (\citeyear{chew1983wlu,chew1989aut}).} Still more decision theories say that one's uncertainty should be captured not by precise probabilities, as is done for EUT but instead by imprecise probabilities, and then there are various decision theories to choose from, including E-Admissibility, $\Gamma$-Maximin, and Maximality.

%Now, we said that the utility of a decision theory is the utility of In some cases it is easy to apply the decision theory to judge itself, in particular, when there is a unique recommended action for you to take; in which case we just judge the utility of it to be the utility of what it will lead you to do. But decision theories typically don't specify a unique recommended action; they may be indifferent between various actions or, in the case of imprecise probabilities, they may take various actions to be incomparable and not identify a single action to do but instead just rule out some as impermissible. We will simplify our task by in the first instance asking the decision theory to judge various \emph{picking strategies} which are required to specify a unique action to be undertaken for each decision, in which case it is then easy for us to judge the utility of such a picking strategy by looking at its fruits. 


\section{Risk-sensitive decision theories}\label{sect:reu}

Expected utility theory rules out as irrational certain natural ways of taking risk into account in decision-making. In particular, as noted above, it rules out the so-called \emph{Allais preferences} \citep{allais1953c}. In response, decision theorists have presented a range of alternatives that permit those preferences \citep{kahneman1979pt,machina1982eua,quiggin1982tau, buchak2014rr}. Let's begin by showing a straightforward way in which any such decision theory is self-undermining.

%{\color{red}\todoinfo{CCM playing with rewriting. Actually 3 versions/attempts. }
%	\subsection*{v2}
%			\todoinfo{v2 }
%			
%	A decision problem is given by a set of acts which are available in it. 
%	A decision theory is an account of means-ends reasoning, guiding agents on how to best get to their specified ends. 
%	The agent specifies various parameters, say her utilities and credences, and, at least in the simple case, it tells an agent which option to pick in each decision problem. 
%	
%	We might think of it a bit like any kind of advisor, for example a financial advisor or just a best friend; someone who has the agent's best interests at heart and makes recommendations purely on the basis of the agent's ends, advising the agent on what to do in the various decision problems she might face. 
%	
%	Consider a decision problem with two options, a risky bet and a safe option. Let's say the risky one depends on some particular outcome, say whether this particular company goes bust; and let's suppose that the agent thinks that the odds of this company going bust are $1:10$. She may thus be faced with this decision problem:
%	$$
%	\begin{array}{r|cc}
%		\text{Decision problem } {D}^* & \text{goes bust} &  \text{not bust}  \Bstrut \\\hline \Tstrut		p & \sfrac{1}{11} & \sfrac{10}{11} \Bstrut \\\hline \hline\Tstrut 
%		\text{Safe} &\text{\pounds 1m}&\text{\pounds 1m}                      \\
%		\text{Risky} & \text{\pounds 0m}&\text{\pounds 5m}
%	\end{array}
%	$$	
%%	Consider a decision theory, $\s$ which recommend taking the safe option over the risky option in $D^*$. 
%	
%	A decision theory will specify which is a better option to choose in this decision problem. 
%	Consider two candidate decision theories which differ by means of what they recommend picking in $D^*$. 
%	They provide picking strategies $\s_{\text{Safe}}$ and $\s_{\text{Risky}}$ which pick, respectively, Safe and Risky in $D^*$. 
%	
%	Now suppose that our agent is unsure which decision problem she'll be faced with.
%	Let's suppose her credence in being offered $D^*$ are just $11\%$, and that otherwise she'll get \pounds1m for sure. And, moreover, that you think that whether you'll be facing $D^*$ is probabilistically independent of whether the company will go bust. \todo{why would that be?}
%	Consider a higher-order decision: a decision about whether to use picking strategy $\s_{\text{Safe}}$ and $\s_{\text{Risky}}$.
%	
%	We will evaluate this in the same way we evaluate other decisions: by evaluating which is best at getting to the agent's goals. 
%	We are thus facing this decision: 		
%	$$
%	\begin{array}{c|ccc}
%		\multirow{2}{*}{\text{Version 1}}	&\multicolumn{2}{c}{\text{choice offered}}&\text{choice not offered}\\
%		& \text{goes bust} &  \text{not bust}  \Bstrut \\\hline \Tstrut		P &  \sfrac{1}{11} \times \sfrac{11}{100} & \sfrac{10}{11}\times\sfrac{11}{100} & \sfrac{89}{100} \\
%		& = \sfrac{1}{100} & = \sfrac{10}{100} & = \sfrac{89}{100} \Bstrut \\\hline \hline\Tstrut 
%		1A: \s_{\text{Safe}} & \text{\pounds 1m}&\text{\pounds 1m}         &\text{\pounds 1m}               \\
%		1B: \s_{\text{Risky}}& \text{\pounds 0m}&\text{\pounds 5m}& \text{\pounds 1m}
%	\end{array}
%	$$
%	
%	This is extensionally equivalent to one of the choices from the Allais preferences, and the empirically observed preference is to judge 1A over 1B; i.e., $\s_{\text{Safe}}$ as preferable to $\s_{\text{Safe}}$.
%	
%	The other choice offered in the Allais paradox is extensionally equivalent to one where, when the choice is not offered, she is given nothing.
%	$$
%	\begin{array}{c|ccc}
%		\multirow{2}{*}{\text{Version 2}}	&\multicolumn{2}{c}{\text{choice offered}}&\text{choice not offered}\\
%		& \text{goes bust} &  \text{not bust}  \Bstrut \\\hline \Tstrut		P & \sfrac{1}{100} &  \sfrac{10}{100} &  \sfrac{89}{100} \Bstrut \\\hline \hline\Tstrut 
%		2A:\s_{\text{Safe}} & \text{\pounds 1m}&\text{\pounds 1m}         &\text{\pounds 0m}               \\
%		2A: \s_{\text{Risky}}& \text{\pounds 0m}&\text{\pounds 5m}& \text{\pounds 0m}
%	\end{array}
%	$$
%	And here, the empirically observed preference is to prefer 2B to 1A; i.e., now judge $\s_{\text{Risky}}$ as preferable to $\s_{\text{Risky}}$.
%	
%	This is not possible in expected utility theory: her preference cannot depend on the other amount offered. This is essentially Savage's Sure Thing Principle. It thus cannot capture these Allais preferences as rational. 
%	
%	If one adopts a decision theory that permits these Allais preferences, then in one of the cases, it switches its judgement from what is preferable in the individual decision problem $D^*$ to what is preferable if there's only some chance that she's offered it, either in version 1 or version 2. 
%	
%	Let's consider a decision theory which results in picking Safe in $D^*$ but in version 1 of the higher order decision problem, judges 1B to be preferable. 
%	In this case, it judges the only picking strategy which is compatible with its recommendations, $\s_{\text{Safe}}$ to be worse than an alternative picking strategy: $\s_{\text{Risky}}$.
%	The decision theory rules as impermissible picking in accordance with its own recommendations, judging that some other way of picking would be a better means to the agents goals. 
%	
%	The same happens if instead of picking Safe in $D^*$ the theory recommends picking Risky; now in version 2 of the higher order decision problem it judges an alternative picking strategy to be better. 
%	
%	Being self-undermining is \emph{prima facie} bad. Your decision theory makes recommendations both about \emph{picking strategies} and which \emph{options} to choose in different decision problems. But these recommendations pull you in different directions. The picking strategy it recommends tells you to do one thing when faced with $D_1$, and the decision theory itself tells you to do another thing. So there's an instability in the theory's recommendations. The oddity of the situation is akin to one that David \citet[56]{lewis1971iim} identified in a different context:
%	\begin{quote}
%		It is as if Consumer Bulletin were to advise you that Consumer Reports was a best
%		buy whereas Consumer Bulletin itself was not acceptable; you could not possibly
%		trust Consumer Bulletin completely thereafter.
%	\end{quote}
%	
%	Any theory that deems the Allais preferences permissible has this \emph{prima facie} bad-making feature. It is self-undermining in the following sense: (1) there is some precise state of uncertainty you could have about which decision problem you'll face---uncertainty that is represented by a precise probability distribution over the possible decision problems; (2) if you are in that state and apply your decision theory to the question of which picking strategy to use, it rules out any compatible strategy, \emph{i.e.}, any strategy that always avoids picking options that are impermissible according to the original decision theory. %always picks options that are choiceworthy according to the original decision theory. 
%	It demands that you use some picking strategy that is not compatible with it. 
%	
%	
%		This isn't unique to the Allais preferences. Other failures of the Savage's Sure Thing Principle would generate such a way of being uncertain over which decision problem you'll face where the decision theory undermines its recommendations, at least when the failure generates a preference reversal. Similarly for von Neumann-Morgenstern's Independence Principle: if your decision theory deems action $a$ to be preferable to action $b$, but when evaluating an action which tosses a biased coin and selects $a$ (or $b$) if the coin lands Heads and $c$ if the coin lands Tails, the decision theory evaluates the $b$ version to be preferable, then similarly we can generate a way of being uncertain over which decision problem you'll be faced with so that the unique picking strategy which is compatible with the decision theory is itself impermissible according to the theory. 
%		
%		%such that, if you have that uncertainty, and you then apply your decision theory to the question of which picking to use when you face whichever decision problem you in fact face, it says that none of the picking strategies compatible with it are rationally permissible; it demands you use some alternative picking strategy that is not compatible with it. 
%		
%		
%		%We will be able to generate such a challenge using any failure of von Neumann-Morgenstern independence principle or Savage's sure thing principle. 
%		%If your decision theory deems action $a$ to be preferable to $b$ but a certain probabilistic mixture of $b$ with $c$ to be preferable to the same mixture of $a$ with $c$, then supposing you're uncertain if you'll be faced with $D_1$ a choice between $a$ and $b$ and $D_2$ the trivial choice of $c$, with your credences matching the independence violation, then we have a case where the unique picking strategy compatible with the decision theory is deemed impermissible by the decision theory. 
%		%If your decision theory deems action $a$ preferable to $b$ but when there's only a certain probability $p$ that you get $a$ or $b$, and otherwise will get $c$, it deems the mixture with $b$ to be preferable to the mixture with $a$. This 
%	
%	
%	 
%	
%	
%	
%	
%	
%	
%%	Consider also the 
%%	
%%	Consider a higher-order decision: which decision theory to use. 
%%	This is another kind of decision, and we can apply the decision theory to help make this kind of decision too. 
%%	We will ask which decision theory is the best means to the agents ends. 
%%	\todo{picking startegy vs dec theory??}
%%	
%%
%%	
%%	
%%	Now, suppose she is choosing amongst \emph{decision theories}. 
%%	We will judge decision theories by their fruits: by their 
%%	Or, rather, choosing amongst picking strategies. 
%%	In this case, a picking strategy amounts 
%	
%	
%	
%	---
%	
%	\subsection*{v1}
%	
%		\todoinfo{v1 - I'd had in mind to make it like a person recommending rather than the abstract dec theory... but it feels so much just like VoI stuff!}
%	
%	Suppose that you're a financial advisor.
%	You are offering your client advice about how to choose between two options, a risky one and a safe one. Let's say the risky one depends on some particular outcome, say whether this particular company goes bust. Let's suppose that you think the odds of the market crashing are $1:10$. 
%	(For simplicity, we will assume that you are adopting the clients utilities to give the guidance).
%	$$
%	\begin{array}{r|cc}
%		\text{Decision problem} & \text{goes bust} &  \text{not bust}  \Bstrut \\\hline \Tstrut		p & \sfrac{1}{11} & \sfrac{10}{11} \Bstrut \\\hline \hline\Tstrut 
%		\text{Safe} &\text{\pounds 1m}&\text{\pounds 1m}                      \\
%		\text{Risky} & \text{\pounds 0m}&\text{\pounds 5m}
%	\end{array}
%	$$	
%	Perhaps you recommend taking the safe option over the risky option. 
%	
%	Now, suppose that you think that your client is only possibly going to be offered this decision in the morning, let's say your credence is $11\%$. And otherwise she just gets nothing. 
%	You are advising her over what she should pick if offered. 
%	Now the decision problem looks like:
%	$$
%	\begin{array}{r|ccc}
%	\multirow{2}{*}{\text{Scenario 1}}	&\multicolumn{2}{c}{\text{choice offered}}&\text{choice not offered}\\
%		& \text{goes bust} &  \text{not bust}  \Bstrut \\\hline \Tstrut		P &  \sfrac{1}{11} \times \sfrac{11}{100} & \sfrac{10}{11}\times\sfrac{11}{100} & \sfrac{89}{100} \\
%		& = \sfrac{1}{100} & = \sfrac{10}{100} & = \sfrac{89}{100} \Bstrut \\\hline \hline\Tstrut 
%		\text{Safe if offered (scenario 1)} & \text{\pounds 1m}&\text{\pounds 1m}         &\text{\pounds 0m}               \\
%		\text{Risky if offered (scenario 1)}& \text{\pounds 0m}&\text{\pounds 5m}& \text{\pounds 0m}
%	\end{array}
%	$$
%	
%	
%	Perhaps you still recommend that if she is offered the choice, she takes the risky option. 
%	Suppose your client has the option of ringing you in the morning to ask what she should do now that she has been offered it. You think she should ring you and do this. 
%	
%	Now suppose that instead, you think that when she's not offered the choice, she is given \pounds 1m rather than nothing. 
%	$$
%	\begin{array}{r|ccc}
%		\multirow{2}{*}{\text{Scenario 2}}	&\multicolumn{2}{c}{\text{choice offered}}&\text{choice not offered}\\
%		& \text{goes bust} &  \text{not bust}  \Bstrut \\\hline \Tstrut%		P &  \sfrac{1}{11} \times \sfrac{11}{100} & \sfrac{10}{11}\times\sfrac{11}{100} & \sfrac{89}{100} \\
%	P	&  \sfrac{1}{100} & \sfrac{10}{100} &  \sfrac{89}{100} \Bstrut \\\hline \hline\Tstrut 
%		\text{Safe if offered (scenario 2)} &\text{\pounds 1m}&\text{\pounds 1m}         &\text{\pounds 1m}               \\
%		\text{Risky if offered (scenario 2)}& \text{\pounds 0m}&\text{\pounds 5m}& \text{\pounds 1m}
%	\end{array}
%	$$	
%	
%	
%	Expected utility theory says that your evaluation in scenario 1 and scenario 2 should be the same. Whether you recommend taking the risky or the safe option if offered does not depend on the amount you will get if not offered. 
%	This is essentially Savage's Sure Thing Principle. 
%	
%	It is, however, rejected by various alternative theories. The Scenario 1 and Scenario 2 choice are extensionally equivalent to the Allais scenario and the empirically observed preferences are to take the risky option in scenario 1 but the safe option in scenario 2. 
%		
%	What this means as a financial advisor is that if you are in Scenario 2, you think that it would be better for your client to not ring you up in the morning, once she knows what she's faced with, to check what she should do; she should instead just stick with her safe option, or, put another way, you think she should ring up a different financial advisor, one who will tell her to take the safe option. 
%	
%	This is an instability in your recommendation. It cannot be resolved by saying that she recommends the safe option, as this would create instability instead in Scenario 1. Any decision theory which violates the Sure Thing Principle is susceptible to such cases. 
%
%	
%	
%	\bigskip ---
%	
%	This is how we are suggesting to consider how decision theories evaluate their own recommendations.
%	
%	A decision problem is a set of available acts. 
%	Simplifying a bit, a decision theory specifies which act to pick in each decision problem, thus providing what we call a picking strategy. 
%	
%	A decision theory specifies which act to choose in each decision problem, or at least specifies some acts as bad choices. It provides you with a picking strategy 
%	
%	A picking strategy selects one of the available acts from each decision problem. Decision theories give guidance on what are sensible ways to pick when faced with various decision problems.
%	
%	A decision theory gives an account of means-end reasoning, specifying how to choose to best trade off the risk and benefits of various actions that may be available. We can also apply a decision theory itself to evaluate various picking strategies. 
%
%	
%	
%	\bigskip 
%	\subsection*{v3}
%	
%	\todoinfo{v3 - A more minimal alteration:}
%	
%	
%	
%	Here are the four gambles over which the Allais preferences are defined, with the payout of the actions depending on, lets say, the outcome of a lottery with 100 tickets. 
%	$$
%	\begin{array}{r|cccc}
%		& \text{ticket 1} &\text{ticket 2-11}& \text{ticket 12-100}\Bstrut \\\hline \Tstrut		P & \sfrac{1}{100} & \sfrac{10}{100} & \sfrac{89}{100} \Bstrut \\\hline 		\hline\Tstrut
%		\text{1A} & \text{\pounds 1m} & \text{\pounds 1m}  & \text{\pounds 1m} \\
%		\text{1B} & \text{\pounds 0m} & \text{\pounds 5m}  & \text{\pounds 1m}\\\hline
%		\text{2A} & \text{\pounds 1m} & \text{\pounds 1m}  & \text{\pounds 0m} \\
%		\text{2B} & \text{\pounds 0m} & \text{\pounds 5m}  & \text{\pounds 0m}  \\
%	\end{array}
%	$$
%	And the empirically observed preferences are these: $\text{1A} \succ \text{1B}$ and $\text{2A} \prec \text{2B}$. 
%	
%	
%	Now, suppose our agent is facing a decision problem 
%		Consider a decision problem with two options, a risky bet and a safe option. Let's say the risky one depends on some particular outcome, say whether this particular company goes bust; and let's suppose that the agent thinks that the odds of this company going bust are $1:10$. She may thus be faced with this decision problem:
%	$$
%	\begin{array}{r|cc}
%		\text{Decision problem } D^* & \text{goes bust} &  \text{not bust}  \Bstrut \\\hline \Tstrut		p & \sfrac{1}{11} & \sfrac{10}{11} \Bstrut \\\hline \hline\Tstrut 
%		\text{Safe} &\text{\pounds 1m}&\text{\pounds 1m}                      \\
%		\text{Risky} & \text{\pounds 0m}&\text{\pounds 5m}
%	\end{array}
%	$$	
%	
%
%	A decision problem is given by a set of acts which are available in it. 
%	A decision theory is an account of means-ends reasoning, guiding agents on how to best get to their specified ends. 
%	The agent specifies various parameters, say her utilities and credences, and, at least in the simple case, it tells an agent which option to pick in each decision problem. 
%	
%	We might think of it a bit like any kind of advisor, for example a financial advisor or just a best friend; someone who has the agent's best interests at heart and makes recommendations purely on the basis of the agent's ends, advising the agent on what to do in the various decision problems she might face. 
%	
%	A decision theory will specify which is a better option to choose in this decision problem. It guides the agent not only in this particular decision problem but also in a whole range of other decision problems which the agent might face. In simple cases, in each decision problem it identifies the particular act which should be chosen to best get the agent to her goals. 
%	Sometimes, however, there may be matters of incomparability or indifference, in which case it just judges various bad ways of picking.
%	
%	Consider two candidate decision theories which differ by means of what they recommend picking in $D^*$, but which both recommend the Allais preferences. These are spelled out by what we will call a picking strategy, which selects an individual act from each possible decision problem. So consider picking strategies 
%	$\s_{\text{Safe}}$ and $\s_{\text{Risky}}$ with 
%	$$\begin{array}{r|ccc}
%		\s(D)=?&D^*&D_{\text{Allais1}}&D_{\text{Allais2}}\\\hline
%		\s_{\text{Safe}}&\text{Safe}&1A&2B\\
%		\s_{\text{Risky}}&\text{Risky}&1A&2B\\
%	\end{array}$$
%	
%	
%	A \emph{picking strategy} is a function $\s$ that takes a decision problem $D$, which is just a set of available acts, and returns one of those available acts $\s(D)$ from $D$. As \cite{ullman1977} emphasize, there is an important difference between \emph{picking} and \emph{choosing}. Choosing is a matter of settling on what to do in a decision problem for reasons grounded in your preferences. Picking on the other hand is a matter of settling on what to do even after your reasons have run out, either because you are indifferent between the options that you have not rejected or because you find them incomparable. Picking strategies fully settle what to do in every decision problem. We will understand picking inclusively in what follows. If you choose, then you pick, but not vice versa. That is, if you settle on an option for reasons grounded in your preferences, then you count as both choosing and picking that option. If you settle on an option not for preference-based reasons but simply because you must \emph{do something}, then you count as picking but not choosing that option.
%	
%	Now, suppose that you are unsure whether you will be offered $D^*$ or just be given \pounds 1m for sure. 
%	
%	
%	
%
%	
%
%		
%	Now suppose that our agent is unsure which decision problem she'll be faced with.
%	Let's suppose her credence in being offered $D^*$ are just $11\%$, and that otherwise she'll get \pounds1m for sure. And, moreover, that you think that whether you'll be facing $D^*$ is probabilistically independent of whether the company will go bust. \todo{why would that be?}
%	Consider a higher-order decision: a decision about whether to use picking strategy $\s_{\text{Safe}}$ and $\s_{\text{Risky}}$.
%	
%	Just as we said above we'd judge decision theories by how good they are as means to our ends, let us first do that for picking strategies. So, the utility of a picking strategy in a decision problem is just the utility of the act it tells you to pick in that problem. %is just the utility of the act it requires you to choose. That is, we can specify the utility of $\s_1$ and $\s_2$ if we specify the decision problem you face and the state of the world.  
%		To specify the utility of a picking strategy, $\s$, then, we need to specify both the decision problem that you face, $D$, and the state of the world, $\omega$. The strategy selects a unique option from $D$, $\s(D)$, and the world determines the utility of that option, $\s(D)(\omega)$. 
%	We are thus facing this decision: 		
%	$$
%	\begin{array}{c|ccc}
%		\multirow{2}{*}{\text{Version 1}}	&\multicolumn{2}{c}{\text{choice offered}}&\text{choice not offered}\\
%		& \text{goes bust} &  \text{not bust}  \Bstrut \\\hline \Tstrut		P &  \sfrac{1}{11} \times \sfrac{11}{100} & \sfrac{10}{11}\times\sfrac{11}{100} & \sfrac{89}{100} \\
%		& = \sfrac{1}{100} & = \sfrac{10}{100} & = \sfrac{89}{100} \Bstrut \\\hline \hline\Tstrut 
%		 \s_{\text{Safe}} & \text{\pounds 1m}&\text{\pounds 1m}         &\text{\pounds 1m}               \\
%		 \s_{\text{Risky}}& \text{\pounds 0m}&\text{\pounds 5m}& \text{\pounds 1m}
%	\end{array}
%	$$
%	But note that this is extensionally equivalent to $D_{\text{Allais1}}$. So since 1A is preferred to 1B by both these picking strategies, $\s_{\text{Safe}}$ judges $\s_{\text{Risky}}$ as preferable to itself. 
%	
%	
%	So if your decision theory rationalises the Allais preferences and also deems Safe as uniquely rational in $D^*$ then if offered the decision over which decision theory to use, it will recommend instead picking $\s_{\text{Risky}}$ rather than in accordance with its own recommendations. Such a decision theory is self-undermining. 
%	
%	Being self-undermining is \emph{prima facie} bad. Your decision theory makes recommendations both about \emph{picking strategies} and which \emph{options} to choose in different decision problems. But these recommendations pull you in different directions. The picking strategy it recommends tells you to do one thing when faced with $D_1$, and the decision theory itself tells you to do another thing. So there's an instability in the theory's recommendations. The oddity of the situation is akin to one that David \citet[56]{lewis1971iim} identified in a different context:
%	\begin{quote}
%		It is as if Consumer Bulletin were to advise you that Consumer Reports was a best
%		buy whereas Consumer Bulletin itself was not acceptable; you could not possibly
%		trust Consumer Bulletin completely thereafter.
%	\end{quote}
%	
%	
%	An analogous challenge arises for a decision theory which recommends Safe over Risky in $D^*$. 
%	Whilst it is self-recommending in our version 1 case, where the agent thinks there's $11\%$ probability that she'll be offered $D^*$ choice and otherwise is given \pounds1m, it is self-undermining when the agent is uncertain whether she'll be offered $D^*$, with probability $11\%$, or whether she'll be given nothing for sure. 
%	$$
%	\begin{array}{c|ccc}
%		\multirow{2}{*}{\text{Version 2}}	&\multicolumn{2}{c}{\text{choice offered}}&\text{choice not offered}\\
%		& \text{goes bust} &  \text{not bust}  \Bstrut \\\hline \Tstrut		P & \sfrac{1}{100} &  \sfrac{10}{100} &  \sfrac{89}{100} \Bstrut \\\hline \hline\Tstrut 
%		2A:\s_{\text{Safe}} & \text{\pounds 1m}&\text{\pounds 1m}         &\text{\pounds 0m}               \\
%		2A: \s_{\text{Risky}}& \text{\pounds 0m}&\text{\pounds 5m}& \text{\pounds 0m}
%	\end{array}
%	$$
%	This is now extensionally equivalent to $D_{\text{Allais2}}$ where it is specified that she prefers 2B to 1A, and thus judges $\s_{\text{Safe}}$ as preferable to $\s_{\text{Risky}}$.
%	
%	
%	\todo{I seemed to need to assume a strict preference of Risky or Safe. What if they're deemed equivalent??}
%	
%	And there is no funny business going on here. Learning that you face decision problem $D_1$ does not tell you anything about which ticket will win, for we assumed that the decision problem is independent of the state of the world. And picking one option or another in $D_1$ does not tell you anything about which state of the world you're in, for we assumed the acts are independent of the states of the world as well.
%	
%	
%	Any theory that deems the Allais preferences permissible has this \emph{prima facie} bad-making feature. It is self-undermining in the following sense: (1) there is some precise state of uncertainty you could have about which decision problem you'll face---uncertainty that is represented by a precise probability distribution over the possible decision problems; (2) if you are in that state and apply your decision theory to the question of which picking strategy to use, it rules out any compatible strategy, \emph{i.e.}, any strategy that always avoids picking options that are impermissible according to the original decision theory. %always picks options that are choiceworthy according to the original decision theory. 
%	It demands that you use some picking strategy that is not compatible with it. 
%	
%	
%	This isn't unique to the Allais preferences. Other failures of the Savage's Sure Thing Principle would generate such a way of being uncertain over which decision problem you'll face where the decision theory undermines its recommendations, at least when the failure generates a preference reversal. Similarly for von Neumann-Morgenstern's Independence Principle: if your decision theory deems action $a$ to be preferable to action $b$, but when evaluating an action which tosses a biased coin and selects $a$ (or $b$) if the coin lands Heads and $c$ if the coin lands Tails, the decision theory evaluates the $b$ version to be preferable, then similarly we can generate a way of being uncertain over which decision problem you'll be faced with so that the unique picking strategy which is compatible with the decision theory is itself impermissible according to the theory. 
%}
%
%{\color{red}

%\subsection*{v4}
%
%\todoinfo{v4}
%
%
%%
%Here are the four gambles over which the Allais preferences are defined, with the payout of the actions depending on, lets say, the outcome of a lottery with 100 tickets. 
%$$
%\begin{array}{r|cccc}
%	& \text{ticket 1} &\text{ticket 2-11}& \text{ticket 12-100}\Bstrut \\\hline \Tstrut	p & \sfrac{1}{100} & \sfrac{10}{100} & \sfrac{89}{100} \Bstrut \\\hline	\hline\Tstrut
%	\text{1A} & \text{\pounds 1m} & \text{\pounds 1m}  & \text{\pounds 1m} \\
%	\text{1B} & \text{\pounds 0m} & \text{\pounds 5m}  & \text{\pounds 1m}\\\hline
%	\text{2A} & \text{\pounds 1m} & \text{\pounds 1m}  & \text{\pounds 0m} \\
%	\text{2B} & \text{\pounds 0m} & \text{\pounds 5m}  & \text{\pounds 0m}  \\
%\end{array}
%$$
%The empirically observed preferences are $\text{1A} \succ \text{1B}$ and $\text{2A} \prec \text{2B}$. 
%Let's suppose that our agent has a decision theory which endorses these preferences. 
%
%%A decision problem is given by a set of acts which are available in it. 
%%A decision theory is an account of means-end reasoning which, when parameters such as credences and utilities are specified, specifies which options should be picked, or which shouldn't be pic...???
%
%Now, instead consider this decision problem. It has two options, a risky bet and a safe option which depend on, lets say, whether this particular company goes bust. The options might be, for example, options for stocks she can invest in. Let's suppose that the agent thinks that the odds of this company going bust are $1:10$. \todo{I'm happy to instead keep the example as one with lottery tickets, now with 11 tickets... And then whether she's offered it is determined by a toss of a biased coin??}
%She is thus be faced with this decision problem:
%$$
%\begin{array}{r|cc}
%	\text{Decision problem } D^{\mathrm{Allais}}_{\mathrm{local}} & \text{goes bust} &  \text{not bust}  \Bstrut \\\hline \Tstrut	p & \sfrac{1}{11} & \sfrac{10}{11} \Bstrut \\\hline 	\hline\Tstrut
%	\text{Safe} &\text{\pounds 1m}&\text{\pounds 1m}                      \\
%	\text{Risky} & \text{\pounds 0m}&\text{\pounds 5m}
%\end{array}
%$$	
%Perhaps her decision theory prefers Safe over Risky.
%
%We will now turn to a higher-order decision that the agent might face: a choice amongst various so-called picking strategies. She is unsure which decision problem she will face, and is choosing a strategy for what to pick in each possible decision problem. 
%%She has some credence over various decision problems that she might be faced with.
%
%Perhaps she is leaving instructions for which options her stockbroker should pick, unsure what will be on offer. 
%Or perhaps she has to choose a proxy to act on her behalf, knowing what they'll pick in each decision problem, but unsure which decision problem will be in play. 
%%As she is unavailable to make the decision at the later time. 
%
%
%The form that these options have are what we call \emph{picking strategies}. They are functions, $\s$, which select one of the available acts from each (relevant) decision problem. 
%For example, a picking function will specify either Safe or Risky as its pick in $D^{\mathrm{Allais}}_{\mathrm{local}}$.
%
%The choice between picking functions is another kind of decision problem, a higher-order decision. She can make use of her decision theory to determine which picking function to choose, depending on her credences over which decision problem she'll be faced with, and the utility that the picking strategy leads to in each possibility. We will evaluate picking strategies by their fruits: by the utility of what they select when faced with the specified decision problem and given the state of the world. 
%
%Suppose that she thinks she might be faced with $D^{\mathrm{Allais}}_{\mathrm{local}}$ or just be given \pounds1m for sure. And suppose that her credence that she'll face $D^{\mathrm{Allais}}_{\mathrm{local}}$ is $11\%$. She is deciding amongst various picking strategies. 
%Here, the only relevant consideration in choosing amongst picking strategies is what they will pick when facing $D^{\mathrm{Allais}}_{\mathrm{local}}$. There are thus two options: $\s_{\mathrm{Safe}}$ or $\s_{\mathrm{Risky}}$, which pick Safe or Risky, respectively, in $D^{\mathrm{Allais}}_{\mathrm{local}}$. 
%The decision amongst picking strategies thus amounts to this decision:
%$$
%\begin{array}{c|ccc}
%	\multirow{2}{*}{\text{Version 1}}	&\multicolumn{2}{c}{\text{choice offered}}&\text{choice not offered}\\
%	& \text{goes bust} &  \text{not bust}  \Bstrut \\\hline \Tstrut	p &  \sfrac{1}{11} \times \sfrac{11}{100} & \sfrac{10}{11}\times\sfrac{11}{100} & \sfrac{89}{100} \\
%	& = \sfrac{1}{100} & = \sfrac{10}{100} & = \sfrac{89}{100} \Bstrut \\\hline 	\hline\Tstrut
%	\s_{\mathrm{Safe}} & \text{\pounds 1m}&\text{\pounds 1m}         &\text{\pounds 1m}               \\
%	\s_{\mathrm{Risky}}& \text{\pounds 0m}&\text{\pounds 5m}& \text{\pounds 1m}
%\end{array}
%$$
%This is extensionally equivalent to the choice of 1A vs 1B in $D^{\mathrm{Allais}}_1$. Assuming her decision theory is structural, in the sense that its recommendations don't depend on the content of the outcomes but just the list of credences of various utility outcomes, then she should also judge $\s_{\mathrm{Safe}}$ to be preferable to $\s_{\mathrm{Risky}}$. 
%
%That is, she should want to instruct her stockbroker to take the Safe option when facing $D^{\mathrm{Allais}}_{\mathrm{local}}$, and select a proxy who will pick the Safe course of action. 
%
%Now, however, suppose instead, that whilst she still has the same credence that she'll be offered $D^{\mathrm{Allais}}_{\mathrm{local}}$, she thinks that if it is not on offer, the alternative case is that she gets nothing. 
%Now, she is facing the following decision problem over which picking strategy to select. 
%$$
%\begin{array}{c|ccc}
%	\multirow{2}{*}{\text{Version 2}}	&\multicolumn{2}{c}{\text{choice offered}}&\text{choice not offered}\\
%	& \text{goes bust} &  \text{not bust}  \Bstrut \\\hline \Tstrut	p&  \sfrac{1}{100} &  \sfrac{10}{100} &  \sfrac{89}{100} \Bstrut \\\hline \hline\Tstrut 
%	\s_{\mathrm{Safe}} & \text{\pounds 1m}&\text{\pounds 1m}         &\text{\pounds 0}               \\
%	\s_{\mathrm{Risky}}& \text{\pounds 0m}&\text{\pounds 5m}& \text{\pounds 0}
%\end{array}
%$$
%This is now extensionally equivalent to the choice of 2A vs 2B in $D^{\mathrm{Allais}}_2$, and we have supposed that she preferred 2B over 2A, matching the observed preferences. In this scenario, then, she will evaluate the picking strategy $\s_{\mathrm{Risky}}$ to be preferable to $\s_{\mathrm{Safe}}$, even though, when faced with  $D^{\mathrm{Allais}}_{\mathrm{local}}$ herself, she prefers Safe.
%
%Given the choice of what to write as instructions for her stockbroker, she prefers to instruct them to act differently to how she would act were she facing the decision herself. Given the choice over which proxy to nominate, she thinks it is better to nominate one that she knows won't choose in the way she would were she in the situation herself. 
%Given the choice of whether she should tie herself to the mast, and pre-commit to a particular course of action, she is willing to pay money to get that rope.\todo{isn't this making it like the others???}
%
%If our agent, using her decision theory, endorses the Allais preferences and recommends Safe over Risky in $D^{\mathrm{Allais}}_{\mathrm{local}}$, then in Scenario 2, she will prefer to write down a picking strategy which does not match her own. 
%That is, her adopted decision theory recommends a picking strategy which is not compatible with its own recommendations. Despite the fact that it recommends picking Safe, it thinks it would be better to use a decision theory which recommends Risky in $D^{\mathrm{Allais}}_{\mathrm{local}}$.
%
%
%This is \emph{prima facie} bad feature of her decision theory. Your decision theory makes recommendations both about \emph{picking strategies} and which \emph{options} to choose in different decision problems. But these recommendations pull you in different directions. The picking strategy it recommends tells you to do one thing when faced with $D^{\mathrm{Allais}}_{\mathrm{local}}$, and the decision theory itself tells you to do another thing. There's an instability in the theory's recommendations. The oddity of the situation is akin to one that David \citet[56]{lewis1971iim} identified in a different context:
%\begin{quote}
%	It is as if Consumer Bulletin were to advise you that Consumer Reports was a best
%	buy whereas Consumer Bulletin itself was not acceptable; you could not possibly
%	trust Consumer Bulletin completely thereafter.
%\end{quote}
%
%%This is, \emph{prima facie}, a bad-making feature of a decision theory. 
%It is self-undermining, in the sense that in this particular scenario, with the particular precise probability distribution over the possible decision problems she might face ($11\%$ for $D^{\mathrm{Allais}}_{\mathrm{local}}$; $89\%$ for sure-\pounds0, a trivial decision problem), if she applies her decision theory to the question of which picking strategy to use, it rules out as impermissible, what she thinks she should do in that scenario.
%
%
%And there is no funny business going on here. Learning that you face decision problem $D^{\mathrm{Allais}}_{\mathrm{local}}$ does not, we are supposing, provide any information about whether the company will go bust. We assumed that the decision problem is independent of the state of the world. We are also assuming act-state independence: picking one option or another in $D^{\mathrm{Allais}}_{\mathrm{local}}$ does not tell you anything about which state of the world you're in.
%
%This was all based on the asumption not only that her decision theory endorsed the Allais preferences, but also that it recommended Safe over Risky in $D^{\mathrm{Allais}}_{\mathrm{local}}$. If instead she preferred Risky over Safe in $D^{\mathrm{Allais}}_{\mathrm{local}}$, however, then an analogous undermining feature would have arisen in version 1: if she thinks she'll face decision problems at $11\%$ for $D^{\mathrm{Allais}}_{\mathrm{local}}$; $89\%$ for sure-\pounds1m, then she prefers to write down a strategy which does not match her own.
%
%What if, however, she is indifferent between Risky over Safe in $D^{\mathrm{Allais}}_{\mathrm{local}}$, then both the picking strategies $\s_{\mathrm{Risky}}$ and $\s_{\mathrm{Safe}}$ are compatible with her preferences. In acting in the world, an agent does actually need to pick an option, even if her reasons for one or the other have run out. Decision theories often leave open various ways to pick. 
%Picking is a matter of settling on what to do, even if her reasons have run out, unlike \emph{choosing} ...\todo{talk about picking vs choosing here???} \citet{ullman1977}. 
%
%With this indifference, if she adopts the Allais preferences, then, whilst which picking strategy she deems optimal changes depending on version 1 or version 2, in neither case does she rule out all the picking strategies which are compatible with her recommendations.
%
%However, assuming that not only she endorses the Allais preferences, but is willing to pay a small price to select the one over the other, then indifference no longer offers a route out. For this argument we need to consider a different probability over possible decisions. 
%Suppose she thinks that she prefers $1A$ to $1B+\pounds 1$,
%and $2B$ to $2A+\pounds 1$. And suppose she thinks with $50\%$ credence that she'll be faced with the choice of $1A$ and $1B+\pounds 1$, and with 50\% credence she'll be faced with the choice of $2B$ and $2A+\pounds 1$. She is thus selecting amongst four possible strategies and her decision is:
%\[
%\begin{array}{r|ccc}
%	& \text{Ticket 1} & \text{Tickets 2--11} & \text{Tickets 12--100} \Bstrut \\\hline \Tstrut	p & \sfrac{1}{100} & \sfrac{10}{100} & \sfrac{89}{100} \\
%	\hline\hline
%	\s_{1A,2A^+}  & \pounds2\million+\pounds1   & \pounds2\million+\pounds1   & \pounds1\million+\pounds1   \\
%	\s_{1A,2B}    & \pounds1\million            & \pounds6\million            & \pounds1\million            \\
%	\s_{1B^+,2A^+}& \pounds1\million+\pounds2   & \pounds6\million+\pounds2   & \pounds1\million+\pounds2   \\
%	\s_{1B^+,2B}  & \pounds1              & \pounds10\million+\pounds1  & \pounds1\million+\pounds1  
%\end{array}
%\]
%
%Even though she prefers $1A$ and $2B$ in the local decisions, the strategy of picking these both is dominated by picking $1B^+$ and $2A^+$, and thus, any plausible decision theory will not deem the picking strategy $\s_{1A,2B}$ to be permissible. It is thus self-undermining decision theory.
%
%This shows that any decision theory which permits the sweetened Allais preferences is self-undermining. Assuming it permits the Allais preferences and is Archimadean, it will permit some sweetened Allais preferences. 
%
%Moreover, any theory which violates the Sure Thing Principle and is Archimadean will generate such a case. Similarly for vNM Independence Principle. 
%
%
%\todoinfo{still to be included: STP claim}
%
%}

%\subsection*{v5}



%{\color{violet}
%
Here are the four options over which the Allais preferences are defined. The payout of each depends on the outcome of a lottery with 100 tickets. 
%$$
%\begin{array}{r|cccc}
%	& \text{ticket 1} &\text{ticket 2-11}& \text{ticket 12-100}\\\hline \Tstrut
%	p & \sfrac{1}{100} & \sfrac{10}{100} & \sfrac{89}{100} \Bstrut\\\hline\hline\Tstrut 
%	\text{1A} & \text{\pounds 1m} & \text{\pounds 1m}  & \text{\pounds 1m} \\
%	\text{1B} & \text{\pounds 0m} & \text{\pounds 5m}  & \text{\pounds 1m}\Bstrut\\\hline\Tstrut 
%	
%		\text{2A} & \text{\pounds 1m} & \text{\pounds 1m}  & \text{\pounds 0m} \\
%		\text{2B} & \text{\pounds 0m} & \text{\pounds 5m}  & \text{\pounds 0m} 
%\end{array}
%$$
$$
\begin{array}{r|ccc}
	D^{\mathrm{Allais}}_1 & \text{ticket 1} &\text{ticket 2-11}& \text{ticket 12-100}\Bstrut \\\hline \Tstrut	p & \sfrac{1}{100} & \sfrac{10}{100} & \sfrac{89}{100} \Bstrut \\\hline \hline\Tstrut 
	\text{1A} & \text{\pounds 1m} & \text{\pounds 1m}  & \text{\pounds 1m} \\
	\text{1B} & \text{\pounds 0m} & \text{\pounds 5m}  & \text{\pounds 1m}
\end{array}
$$$$
\begin{array}{r|ccc}
	D^{\mathrm{Allais}}_2 & \text{ticket 1} &\text{ticket 2-11}& \text{ticket 12-100}\Bstrut \\\hline \Tstrut	p & \sfrac{1}{100} & \sfrac{10}{100} & \sfrac{89}{100} \Bstrut \\\hline \hline\Tstrut 
	\text{2A} & \text{\pounds 1m} & \text{\pounds 1m}  & \text{\pounds 0m} \\
	\text{2B} & \text{\pounds 0m} & \text{\pounds 5m}  & \text{\pounds 0m} 
\end{array}
$$
As Allais notes, many people prefer 1A to 1B in $D^{\mathrm{Allais}}_1$ and 2B to 2A in $D^{\mathrm{Allais}}_2$.
% $\text{1A} \succ \text{1B}$ and $\text{2A} \prec \text{2B}$. 
Let's suppose that our agent has a decision theory which endorses these preferences, given parameters such as her credences and utilities, and possibly also some representation of her attitudes to risk.

%A decision problem is given by a set of acts which are available in it. 
%A decision theory is an account of means-end reasoning which, when parameters such as credences and utilities are specified, specifies which options should be picked, or which shouldn't be pic...???

Now, consider instead a related decision problem, which we will call $D^{\mathrm{Allais}}_{\mathrm{local}}$. There are two actions available to the agent---Safe and Risky---whose outcomes depend on whether a particular company goes bust or not; for instance, they might be different stocks in which she can invest. Let's suppose the agent thinks the odds of this company going bust are $1:10$. 
$$
\begin{array}{r|cc}
	\text{Decision problem } D^{\mathrm{Allais}}_{\mathrm{local}} & \text{goes bust} &  \text{not bust} \Bstrut\\\hline \Tstrut
	p & \sfrac{1}{11} & \sfrac{10}{11}\Bstrut\\\hline\hline \Tstrut
	\text{Safe} &\text{\pounds 1m}&\text{\pounds 1m}                      \\
	\text{Risky} & \text{\pounds 0}&\text{\pounds 5m}
\end{array}
$$
%There are two actions that the agent could take: take a risky bet or the safe course of action. Let's say the outcome of the risky bet depends on whether this particular company goes bust. These actions might be, 
Perhaps her decision theory prefers Risky to Safe. 

We will now turn to a higher-order decision the agent might face.   She is unsure which decision problem she will face, and she must choose a strategy for which option to pick in each possible decision problem. Perhaps she is leaving instructions for what her stockbroker should do, unsure what will be on offer. Or perhaps she has to choose a proxy to act on her behalf, knowing what they'll pick in each decision problem, but unsure which decision problem they'll face. 
%As she is unavailable to make the decision at the later time. 


The form that these options have are what we call \emph{picking strategies}. 
A picking strategy is a function, $\s$, which selects one of the available options from each (relevant) decision problem. 
For example, a picking function will specify either Safe or Risky as its pick in $D^{\mathrm{Allais}}_{\mathrm{local}}$.

The choice between picking strategies is another kind of decision problem; this time, a higher-order decision problem. Our agent can make use of her decision theory to determine which picking strategy to choose, provided (i) she has credences over which decision problem she'll face, and (ii) for each picking strategy, each decision problem, and each possible state of the world, she assigns a utility to adopting a picking strategy should she face that decision problem at that state of the world. To specify the latter, we evaluate a picking strategy by its fruits; that is, its utility when faced with a decision problem at a possible state of the world is the utility, at that state of the world, of the option it selects when faced with that decision problem.

Suppose our agent knows she'll either face $D^{\mathrm{Allais}}_{\mathrm{local}}$ or she'll be given \pounds1m for sure. And suppose her credence that she'll face $D^{\mathrm{Allais}}_{\mathrm{local}}$ is $11\%$. She is deciding amongst various picking strategies. 
Here, the only relevant consideration in choosing amongst picking strategies is what they will pick when facing $D^{\mathrm{Allais}}_{\mathrm{local}}$. There are thus two options: $\s_{\mathrm{Safe}}$ or $\s_{\mathrm{Risky}}$, which pick Safe or Risky, respectively, in $D^{\mathrm{Allais}}_{\mathrm{local}}$. 
The decision among picking strategies thus amounts to this decision:
%	$$
%\begin{array}{c|ccc}
%	\multirow{2}{*}{\text{Version 1}}	&\multicolumn{2}{c}{\text{choice offered}}&\text{choice not offered}\\
%	& \text{goes bust} &  \text{not bust}  \\
%	\hline
%	p &  \sfrac{1}{11} \times \sfrac{11}{100} & \sfrac{10}{11}\times\sfrac{11}{100} & \sfrac{89}{100} \\
%	& = \sfrac{1}{100} & = \sfrac{10}{100} & = \sfrac{89}{100} \\
%	\hline
%	\hline
%	\s_{\mathrm{Safe}} & \text{\pounds 1m}&\text{\pounds 1m}         &\text{\pounds 1m}               \\
%	\s_{\mathrm{Risky}}& \text{\pounds 0m}&\text{\pounds 5m}& \text{\pounds 1m}
%\end{array}
%$$
%This is extensionally equivalent to the choice of 1A vs 1B in $D^{\mathrm{Allais}}_1$. Assuming her decision theory is structural, in the sense that its recommendations don't depend on the content of the outcomes but just the list of credences of various utility outcomes, then she should also judge $\s_{\mathrm{Safe}}$ to be preferable to $\s_{\mathrm{Risky}}$. 
%
%That is, she should want to instruct her stockbroker to take the Safe option when facing $D^{\mathrm{Allais}}_{\mathrm{local}}$, and select a proxy who will pick the Safe course of action. 
%
%Now, however, suppose instead, that whilst she still has the same credence that she'll be offered $D^{\mathrm{Allais}}_{\mathrm{local}}$, she thinks that if it is not on offer, the alternative case is that she gets nothing. 
%Now, she is facing the following decision problem over which picking strategy to select. 
	$$
\begin{array}{c|ccc}
	\multirow{2}{*}{\text{Version 1}}	&\multicolumn{2}{c}{\text{choice offered}}&\text{choice not offered}\\
	& \text{goes bust} &  \text{not bust}  \Bstrut\\\hline\Tstrut	
	p &  \sfrac{1}{11} \times \sfrac{11}{100} & \sfrac{10}{11}\times\sfrac{11}{100} & \sfrac{89}{100} \\
	& = \sfrac{1}{100} & = \sfrac{10}{100} & = \sfrac{89}{100}
		\Bstrut\\\hline\hline\Tstrut	
	\s_{\mathrm{Safe}} & \text{\pounds 1m}&\text{\pounds 1m}         &\text{\pounds 1m}               \\
	\s_{\mathrm{Risky}}& \text{\pounds 0m}&\text{\pounds 5m}& \text{\pounds 1m}
\end{array}
$$
But of course, this exactly mirrors the choice of 1A vs 1B in $D^{\mathrm{Allais}}_1$. And so, assuming her decision theory is structural, in the sense that its recommendations don't depend on the content of the outcomes but only on the list of credences of various utility outcomes, then she should also judge $\s_{\mathrm{Safe}}$ to be preferable to $\s_{\mathrm{Risky}}$, even though, when faced with  $D^{\mathrm{Allais}}_{\mathrm{local}}$ herself, she prefers Risky.

%This is now extensionally equivalent to the choice of 2A vs 2B in $D^{\mathrm{Allais}}_2$, and we have supposed that she preferred 2B over 2A, matching the observed preferences. In this scenario, then, she will evaluate the picking strategy $\s_{\mathrm{Risky}}$ to be preferable to $\s_{\mathrm{Safe}}$, even though, when faced with  $D^{\mathrm{Allais}}_{\mathrm{local}}$ herself, she prefers Safe.

Given the choice of what to write as instructions for her stockbroker, she prefers to instruct them to act differently from how she would act were she facing the decision herself. Given the choice over which proxy to nominate, she thinks it is better to nominate one she knows won't choose in the way she would were she in the situation herself. 
Given the choice whether she should tie herself to the mast and pre-commit to the particular picking strategy she prefers before she knows which decision problem she'll face, rather than leaving herself to choose after she comes to know, she reaches for that rope. %\todo{isn't this making it like the others??? RP: which others? CCM: I meant VoI or sequential choice. }\todo{C: pay money? We haven't shown that... it depends on the Archimadeanicity. }
 Her adopted decision theory requires her to pick a picking strategy that is not compatible with its own recommendations. 
%If our agent, using her decision theory, endorses the Allais preferences and recommends Risky over Safe in $D^{\mathrm{Allais}}_{\mathrm{local}}$, then her adopted decision theory recommends a picking strategy which is not compatible with its own recommendations. 
Despite the fact that her decision theory recommends picking Risky, it thinks it would be better to use a decision theory which recommends picking Safe.

%\begin{colored}{red}
	%\todo{I moved this para up here}
%There is no funny business going on here. Learning that you face decision problem $D^{\mathrm{Allais}}_{\mathrm{local}}$ does not, we are supposing, provide any information about whether the company will go bust. We assumed that the decision problem is independent of the state of the world. We are also assuming act-state independence: picking one option or another in $D^{\mathrm{Allais}}_{\mathrm{local}}$ does not tell you anything about which state of the world you're in.
%\end{colored}

This is a \emph{prima facie} bad feature of our agent's decision theory. Her decision theory makes recommendations both about what actions to perform when faced with different decision problems and which picking strategy is best. But these recommendations pull her in different directions. The decision theory itself tells you to do one thing when faced with the decision, but recommends using a picking strategy that something else. 
%The picking strategy it recommends tells her to do one thing when faced with $D^{\mathrm{Allais}}_{\mathrm{local}}$, and the decision theory itself tells her to do another thing. 
This is a conflict in the theory's recommendations. The oddity of the situation is akin to one that David \citet[56]{lewis1971iim} identified in a different context:
\begin{quote}
	It is as if Consumer Bulletin were to advise you that Consumer Reports was a best
	buy whereas Consumer Bulletin itself was not acceptable; you could not possibly
	trust Consumer Bulletin completely thereafter.
\end{quote}

%This is, \emph{prima facie}, a bad-making feature of a decision theory. 
The decision theory is self-undermining in the sense that there is some particular precise probability distribution over the possible decision problems she might face---it's $11\%$ likely she'll face $D^{\mathrm{Allais}}_{\mathrm{local}}$, and $89\%$ likely she'll get \pounds 1m for sure---where if she applies her decision theory to the question of which picking strategy to use, it rules out as impermissible its own recommended course of action. 




This was all based on the assumption not only that her decision theory endorses the Allais preferences, but also that it recommends Risky over Safe in $D^{\mathrm{Allais}}_{\mathrm{local}}$. If it instead recommends Safe over Risky in $D^{\mathrm{Allais}}_{\mathrm{local}}$, we can consider a different decision problem: Suppose that, whilst she still thinks that her credence that she'll be offered $D^{\mathrm{Allais}}_{\mathrm{local}}$ is $11\%$, she thinks that if she is not offered it, then she is given nothing. 
Now, she is facing the following decision problem over which picking strategy to select. 
$$
\begin{array}{c|ccc}
	\multirow{2}{*}{\text{Version 2}}	&\multicolumn{2}{c}{\text{choice offered}}&\text{choice not offered}\\
	& \text{goes bust} &  \text{not bust}  \Bstrut \\\hline \Tstrut	p&  \sfrac{1}{100} &  \sfrac{10}{100} &  \sfrac{89}{100} \Bstrut \\\hline \hline\Tstrut 
	\s_{\mathrm{Safe}} & \text{\pounds 1m}&\text{\pounds 1m}         &\text{\pounds 0}               \\
	\s_{\mathrm{Risky}}& \text{\pounds 0m}&\text{\pounds 5m}& \text{\pounds 0}
\end{array}
$$
This exactly mirrors the choice of 2A vs 2B in $D^{\mathrm{Allais}}_2$, and we have supposed that she holds the Allais preferences of 2B over 2A. In this scenario, then, assuming again that her decision theory is structural in the sense described above, she will evaluate the picking strategy $\s_{\mathrm{Risky}}$ to be preferable to $\s_{\mathrm{Safe}}$, even though, when faced with  $D^{\mathrm{Allais}}_{\mathrm{local}}$ herself, she prefers Safe. %\todo{this isn't actually ``extensional equivalent'' as it depends on the probabilities too!}

Thus, if her decision theory endorses the Allais preferences and is opinionated over what to choose in $D^{\mathrm{Allais}}_{\mathrm{local}}$ then it is undermining in the sense that there is some uncertainty over which decision problem she'll face where the decision theory rules its own way of picking as impermissible. 

What if, however, her decision theory has neither a strict preference for Safe over Risky or Risky over Safe in $D^{\mathrm{Allais}}_{\mathrm{local}}$. Then both ways of picking are compatible with her decision theory. Whilst which picking strategy she deems optimal changes depending on the amount she'll receive when not facing $D^{\mathrm{Allais}}_{\mathrm{local}}$, in neither case does she rule out all the picking strategies that are compatible with her recommendations---she just rules out one of them. Whilst her decision theory would then be undermining in some sense, it is much weaker than what we had previously, where the decision theory rules out as impermissible \textit{all} picking strategies compatible with its recommendations (there is only one).% \todo{what do we actually say about this?? EAdmiss?? RP: yes, this is covered below. And this is the point of the probabilistic picking strategies.}


%A decision theory often does leave some decisions unsettled. This might be because they are indifferent between various option or it might be because they consider them incomparable. In these cases, they say that our reasons for action do not determine a unique option. In the language of \citep{ullman1977}, such a decision theory leaves open various ways to pick, where picking is a matter of settling on what to do after your reasons for action have run out and a range of options have not been ruled out as impermissible.

However, with some additional assumptions we can modify the case to again show that the decision theory is self-undermining in the stronger sense. 
The decision theories that endorse the Allais preferences are usually motivated by avoidance of risk rather than considerations of ambiguity or imprecision. So they typically say that cases in which an agent doesn't have a strict preference either way between two options are those in which  she is indifferent between them; and, in those cases, any slight sweetening of one option is sufficient to make her strictly prefer  that. %\todo{is this the ``ordering principle''?}
So, in this decision, she will prefer Risky$^+$ to Safe:
$$
\begin{array}{r|cc}
 D^{\mathrm{Allais}}_{\mathrm{local}^+} & \text{goes bust} &  \text{not bust}  \Bstrut\\\hline
	p & \sfrac{1}{11} & \sfrac{10}{11}\Bstrut\\\hline\hline\Tstrut
	\text{Safe} &\text{\pounds 1m}&\text{\pounds 1m}                      \\
	\text{Risky$^+$} & \text{\pounds 1}&\text{\pounds 5m+\pounds 1}
\end{array}
$$ What's more, for some small enough sweetening, it is plausible that she will still prefer 1A to 1B$^+$:\footnote{This is an Archimedeanicity principle.}
$$
\begin{array}{r|cccc}
	& \text{ticket 1} &\text{ticket 2-11}& \text{ticket 12-100}\Bstrut\\\hline
	p & \sfrac{1}{100} & \sfrac{10}{100} & \sfrac{89}{100} \Bstrut\\\hline\hline\Tstrut
	\text{1A} & \text{\pounds 1m} & \text{\pounds 1m}  & \text{\pounds 1m} \\
	\text{1B$^+$} & \text{\pounds 1} & \text{\pounds 5m+\pounds1}  & \text{\pounds 1m}
\end{array}
$$
And so again, the decision theory deems it impermissible to pick in accordance with its own recommendations; instead it recommends using a different decision theory. 


Any failure of the Marschak's (\citeyear{marschak1950rb}) Independence Principle will generate a case where the decision theory is self-undermining.
This principle says that, if the decision theory deems action $a_1$ preferable to action $a_2$, then it deems a probabilistic mixture $\alpha a_1+(1-\alpha)b$ preferable to $\alpha a_2+(1-\alpha)b$. 
Such a mixture is often interpreted as the act of using a randomization device, such as the toss of a biased coin, to determine which action to perform. 
But it can also be interpreted as evaluating picking strategies if you're uncertain over which decision problem you'll face. With probability $\alpha$, you'll face the decision between action $a_1$ and action $a_2$; with probability $1-\alpha$, you'll face the decision with just one option, namely, action $b$. The picking strategies are determined by their pick of either $a_1$ or $a_2$, and they exactly mirror the mixed acts. So, if a decision theory gives rise to a failure of the Independence Principle in which it prefers $a_1$ over $a_2$, but $\alpha a_2+(1-\alpha)b$ over $\alpha a_2+(1-\alpha)b$, then it will prefer strategy $\s_{a_2}$, which picks $a_2$ over $a_1$, over strategy $\s_{a_1}$, which picks $a_1$ over $a_2$, and yet $s_{a_1}$ is the strategy that does what the decision theory demands. So, it is self-undermining.%
\footnote{
	In the case where we have $a_1\succ a_2$ and $\alpha a_1 +(1-\alpha)b\prec \alpha a_2 + (1-\alpha)b$, this is immediate. 
	If the reversal is merely weak, so that $a_1\succ a_2$ and $\alpha a_1 +(1-\alpha)b\preceq \alpha a_2 + (1-\alpha)b$, we appeal to an Ordering principle, to give $\alpha a_1 +(1-\alpha)b\sim \alpha a_2 + (1-\alpha)b$, and an Archimedeanicity principle to produce $a^+_2$ such that $a_1\succ a^+_2$ and $\alpha a_1 +(1-\alpha)b\prec \alpha a^+_2 + (1-\alpha)b$. 
}
%	When we merely have  $a_1\succeq a_2$ and $\alpha a_1 +(1-\alpha)b\prec \alpha a_2 + (1-\alpha)b$ we can make an argument similar to that above, making use of ordering and Archimadeanicity assumptions: when $a_1\succeq a_2$, for small enough price, $\epsilon$, still $\alpha (a_1-\epsilon) +(1-\alpha)b\prec \alpha a_2 + (1-\alpha)b$, but  }

These cases are formally related to cases of sequential incoherence for such decision theories \citep{hammond1988cfeu,machina1989}, but the formal motivation for our investigation was instead \citet{levinstein2017pgeu} who, following \citet{schervish2009psr}, also considers uncertainty over which decision problem we face, and offers evaluations on that basis. 
The aim of their investigation is to judge and compare credences rather than decision theories.
They hold fixed expected utility theory as the decision theory and instead use this uncertainty over which decision you'll face to evaluate credences by their guidance value, assuming what they guide you to do is in accordance with expected utility theory. 
%is to evaluate credences according to their expected guidance value in each state of the world, which differs from ours by both associated a picking function with credence functions in accordance with expected utility theory and then reduces it using expectations. 



%\todo{the original has been commented out below}
%}
%{\color{red}
	
%\subsection{Original}


%Here are the four gambles over which the Allais preferences are defined---for reasons that will become clear, we present them as if they are defined over four possible states of the world, $\omega_1, \ldots, \omega_4$:
%$$
%\begin{array}{r|cccc}
%	& \omega_1 & \omega_2 & \omega_3 & \omega_4 \Bstrut \\\hline \Tstrut	p & \sfrac{1}{100} & \sfrac{10}{100} & \sfrac{89}{200} & \sfrac{89}{200} \Bstrut \\\hline \hline\Tstrut 
%	\text{1A} & \text{\pounds 1m} & \text{\pounds 1m}  & \text{\pounds 1m} & \text{\pounds 1m}  \\
%	\text{1B} & \text{\pounds 0m} & \text{\pounds 5m}  & \text{\pounds 1m}& \text{\pounds 1m}  \\
%	\text{2A} & \text{\pounds 1m} & \text{\pounds 1m}  & \text{\pounds 0m}  & \text{\pounds 0m}  \\
%	\text{2B} & \text{\pounds 0m} & \text{\pounds 5m}  & \text{\pounds 0m}  & \text{\pounds 0m}  
%\end{array}
%$$
%And the preferences are these: $\text{1A} \succ \text{1B}$ and $\text{2A} \prec \text{2B}$. 

%Here are the four gambles over which the Allais preferences are defined---for reasons that will become clear, we present them as if they are defined over four possible states of the world, $\omega_1, \ldots, \omega_4$:
%$$
%\begin{array}{r|cccc}
%& \omega_1 & \omega_2 & \omega_3 & \omega_4 \Bstrut \\\hline \Tstrut p & \sfrac{1}{100} & %\sfrac{10}{100} & \sfrac{89}{200} & \sfrac{89}{200} \Bstrut \\\hline \hline\Tstrut 
%\text{1A} & \text{\pounds 1m} & \text{\pounds 1m}  & \text{\pounds 1m} & \text{\pounds 1m}  \\
%\text{1B} & \text{\pounds 0m} & \text{\pounds 5m}  & \text{\pounds 1m}& \text{\pounds 1m}  \\
%\text{2A} & \text{\pounds 1m} & \text{\pounds 1m}  & \text{\pounds 0m}  & \text{\pounds 0m}  \\
%\text{2B} & \text{\pounds 0m} & \text{\pounds 5m}  & \text{\pounds 0m}  & \text{\pounds 0m}  
%\end{array}
%$$
%And the preferences are these: $\text{1A} \succ \text{1B}$ and $\text{2A} \prec \text{2B}$. 

%\todo{Referee: names for these particular ones}
%Now, consider the following two decision problems, $D_1$ and $D_2$, where the acts available in them are defined over two states of the world, $\omega'_1, \omega'_2$:
%$$
%\begin{array}{r|cc}
%D_1 & \omega'_1 & \omega'_2  \Bstrut \\\hline \Tstrut p & \sfrac{1}{11} & \sfrac{10}{11} \Bstrut \\\hline \hline\Tstrut 
%\text{A} & \text{\pounds 1m} & \text{\pounds 1m}   \\
%\text{B} & \text{\pounds 0m} & \text{\pounds 5m} 
%\end{array}\hspace{20mm}
%\begin{array}{r|cc}
%D_2 & \omega'_1 & \omega'_2  \Bstrut \\\hline \Tstrut p & \sfrac{1}{2} & \sfrac{1}{2} \Bstrut \\\hline \hline\Tstrut 
%\text{C} & \text{\pounds 0m} & \text{\pounds 0m} 
%\end{array}
%$$
%Suppose first that, faced with $D_1$, your decision theory tells you to pick A over B, while faced with $D_2$, it tells you to pick the only available option, C. (We'll return to the case in which your decision theory tells you to pick B over A below.)

%Now suppose you are certain you'll face $D_1$ or $D_2$, but you're uncertain which. Your credence you'll face $D_1$ is $\sfrac{11}{100}$ and your credence you'll face $D_2$ is $\sfrac{89}{100}$. And, what's more, you think which decision you face is independent of what the world is like.

%A \emph{picking strategy} is a function $\s$ that takes a decision problem $D$, which is just a set of available acts, and returns one of those available acts $\s(D)$ from $D$. As \cite{ullman1977} emphasize, there is an important difference between \emph{picking} and \emph{choosing}. Choosing is a matter of settling on what to do in a decision problem for reasons grounded in your preferences. Picking on the other hand is a matter of settling on what to do even after your reasons have run out, either because you are indifferent between the options that you have not rejected or because you find them incomparable. Picking strategies fully settle what to do in every decision problem. We will understand picking inclusively in what follows. If you choose, then you pick, but not vice versa. That is, if you settle on an option for reasons grounded in your preferences, then you count as both choosing and picking that option. If you settle on an option not for preference-based reasons but simply because you must \emph{do something}, then you count as picking but not choosing that option.


%Just as we said above we'd judge decision theories by how good they are as means to our ends, let us first do that for picking strategies. So, the utility of a picking strategy in a decision problem is just the utility of the act it tells you to pick in that problem. %is just the utility of the act it requires you to choose. That is, we can specify the utility of $\s_1$ and $\s_2$ if we specify the decision problem you face and the state of the world.  
%To specify the utility of a picking strategy, $\s$, then, we need to specify both the decision problem that you face, $D$, and the state of the world, $\omega$. The strategy selects a unique option from $D$, $\s(D)$, and the world determines the utility of that option, $\s(D)(\omega)$. 

%Now return to our example. There are two picking strategies, $\s_1$ and $\s_2$, available to you when you consider facing either $D_1$ or $D_2$:
%$$
%\begin{array}{r|cc}
%& D_1 & D_2 \Bstrut \\\hline \Tstrut\s_1 & \text{A}& \text{C} \\
%\s_2 & \text{B}& \text{C} \\
%\end{array}
%$$
%If you face $D_1$ and the world is in state $\omega'_1$, then the utility of $\s_1$ is the utility of \pounds 1m. The reason: $\s_1$ picks A from $D_1$ and A gets you \pounds 1m at $\omega'_1$. More generally, the utility of $\s_1$ and $\s_2$ in any decision problem and world is given by the utility of the following outcomes:
%$$
%\begin{array}{r|cccc}
%& \omega'_1\ \&\ D_1 &  \omega'_2\ \&\ D_1 &  \omega'_1\ \&\ D_2 &  \omega'_2\ \&\ D_2 \Bstrut \\\hline \Tstrut P &  \sfrac{1}{11} \times \sfrac{11}{100} & \sfrac{10}{11}\times\sfrac{11}{100} & \sfrac{1}{2}\times\sfrac{89}{100} & \sfrac{1}{2}\times\sfrac{89}{100} \\
%& = \sfrac{1}{100} & = \sfrac{10}{100} & = \sfrac{89}{200} & = \sfrac{89}{200} \Bstrut \\\hline \hline\Tstrut 
%\s_1 & \text{\pounds 1m} & \text{\pounds 1m} & \text{\pounds 0m} & \text{\pounds 0m} \\
%\s_2 & \text{\pounds 0m} & \text{\pounds 5m} & \text{\pounds 0m} & \text{\pounds 0m} \\
%\end{array}
%$$
%But notice: the choice between $\s_1$ and $\s_2$ is extensionally equivalent to the choice between 2A and 2B in the Allais set up---once we equate $\omega_1$ with $\omega'_1\ \&\ D_1$, $\omega_2$ with $\omega'_2\ \&\ D_1$, and so on, it has the same pay-offs with the same probabilities. So, if you have the Allais preferences, and hence prefer 2B to 2A, then you prefer $\s_2$ to $\s_1$. But we specified that, when faced with $D_1$, your decision theory demands that you choose A over B. That is, it demands that you choose (and hence pick) what $\s_1$ picks and not what $\s_2$ picks. So, your decision theory makes two claims: First, if you're uncertain whether you'll face $D_1$ or $D_2$, you prefer to choose according to picking strategy $\s_2$ and consider it irrational to use $\s_1$. Second, when actually faced with $D_1$, you should pick as $\s_1$ does. In this sense, then, your decision theory is self-undermining. It judges the only picking strategy compatible with its demands to be {rationally impermissible}. Uncertain which of two decision problems you will face, it says that, when you face whichever you do, you should not choose as it demands.

%Now, we specified above that, faced with $D_1$, your decision theory demands you choose A over B. But what if it demands you choose B over A? In that case, we just replace $D_2$, the trivial decision problem that contains only C, which pays out \pounds 0m in either state of the world, with the trivial decision problem that contains only the act D, which pays out \pounds 1m in either state of the world. Then the choice between $\s_1$ and $\s_2$ is extensionally equivalent to the choice between 1A and 1B. So, by the Allais preferences, you'll prefer $\s_1$ to $\s_2$, but, faced with $D_1$, you'll prefer B to A, which is what $\s_2$ tells you to pick and what $\s_1$ tells you not to pick. So again the decision theory is self-undermining.

%And there is no funny business going on here. Learning that you face decision problem $D_1$ does not tell you anything about which ticket will win, for we assumed that the decision problem is independent of the state of the world. And picking one option or another in $D_1$ does not tell you anything about which state of the world you're in, for we assumed the acts are independent of the states of the world as well.

%So, the picking strategy your decision theory judges to be optimal guides you to choose in one way when faced with $D_1$, even though, when actually faced with decision $D_1$, your decision theory guides you to choose the other way. 

%Being self-undermining is \emph{prima facie} bad. Your decision theory makes recommendations both about \emph{picking strategies} and which \emph{options} to choose in different decision problems. But these recommendations pull you in different directions. The picking strategy it recommends tells you to do one thing when faced with $D_1$, and the decision theory itself tells you to do another thing. So there's an instability in the theory's recommendations. The oddity of the situation is akin to one that David \citet[56]{lewis1971iim} identified in a different context:
%\begin{quote}
%It is as if Consumer Bulletin were to advise you that Consumer Reports was a bestbuy whereas Consumer Bulletin itself was not acceptable; you could not possibly trust Consumer Bulletin completely thereafter.
%\end{quote}

%Any theory that deems the Allais preferences permissible has this \emph{prima facie} bad-making feature. It is self-undermining in the following sense: (1) there is some precise state of uncertainty you could have about which decision problem you'll face---uncertainty that is represented by a precise probability distribution over the possible decision problems; (2) if you are in that state and apply your decision theory to the question of which picking strategy to use, it rules out any compatible strategy, \emph{i.e.}, any strategy that always avoids picking options that are impermissible according to the original decision theory. %always picks options that are choiceworthy according to the original decision theory. 
%It demands that you use some picking strategy that is not compatible with it. 


%This isn't unique to the Allais preferences. Other failures of the Savage's Sure Thing Principle would generate such a way of being uncertain over which decision problem you'll face where the decision theory undermines its recommendations, at least when the failure generates a preference reversal. Similarly for von Neumann-Morgenstern's Independence Principle: if your decision theory deems action $a$ to be preferable to action $b$, but when evaluating an action which tosses a biased coin and selects $a$ (or $b$) if the coin lands Heads and $c$ if the coin lands Tails, the decision theory evaluates the $b$ version to be preferable, then similarly we can generate a way of being uncertain over which decision problem you'll be faced with so that the unique picking strategy which is compatible with the decision theory is itself impermissible according to the theory. 

%such that, if you have that uncertainty, and you then apply your decision theory to the question of which picking to use when you face whichever decision problem you in fact face, it says that none of the picking strategies compatible with it are rationally permissible; it demands you use some alternative picking strategy that is not compatible with it. 


%We will be able to generate such a challenge using any failure of von Neumann-Morgenstern independence principle or Savage's sure thing principle. 
%If your decision theory deems action $a$ to be preferable to $b$ but a certain probabilistic mixture of $b$ with $c$ to be preferable to the same mixture of $a$ with $c$, then supposing you're uncertain if you'll be faced with $D_1$ a choice between $a$ and $b$ and $D_2$ the trivial choice of $c$, with your credences matching the independence violation, then we have a case where the unique picking strategy compatible with the decision theory is deemed impermissible by the decision theory. 
%If your decision theory deems action $a$ preferable to $b$ but when there's only a certain probability $p$ that you get $a$ or $b$, and otherwise will get $c$, it deems the mixture with $b$ to be preferable to the mixture with $a$. This 


%
%\begin{quote}
%	\textbf{Independence } Suppose that, when faced with the decision problem $\{a, b\}$, in which $a$ and $b$ are the two available options, your decision theory declares only $a$ permissible. Then, for $0 < p < 1$, when faced with the decision problem $\{[p:a,(1-p):c], [p:a,(1-p):c]\}$, your decision theory should declare only $[p:a,(1-p):c]$ permissible.
%\end{quote}

%}

\subsection{Is it a problem to be self-undermining?}\label{sect:reu:phil-discussion}

There are at least two ways to argue that being self-undermining tells against a decision theory. We'll describe them and then consider some responses.

%{\color{cyan}
%	First: A decision theory categorises available acts into those that are rationally permissible for a particular individual and those that are rationally impermissible for them. Now suppose the decision theory is correct: that is, the acts it declares permissible are indeed exactly those that are permissible for the individual. But one of its declarations is that using it is itself impermissible---that's what makes it self-undermining. Now, how could it ever be rationally impermissible to use a decision theory that gives the correct verdicts about rational permissibility? Surely it couldn't! And if that's so, then the decision theory cannot be correct, and we have a contradiction.
%}
%
%{\color{violet}
%	First: Suppose a decision theory is correct: that is, the acts it declares impermissible are indeed exactly those that are in fact impermissible for the individual. If the decision theory is undermining, then one of its declarations is that picking strategies that are compatible with itself are itself impermissible.
%	Now, how could it ever be rationally impermissible to use a decision theory that gives the correct verdicts about rationality? Surely it couldn't! 
%	And if that's so, then the decision theory cannot be correct, and we have a contradiction.
%}

%{\color{violet}
%	First: if we suppose that a decision theory is in fact the true theory of rational decision making, i.e., that its judgements are the correct ones for that individual. But if one of its declarations is that it is impermissible to pick in any way that is compatible with its recommendations, then any way of acting in accordance with the decision theory is deemed impermissible by the decision theory. Having supposed that the decision theory is the true theory of rational decision making, it is thus impermissible. 
%	  then it is in fact impermissible to act in accordance with the given decision theory. But then the supposed decision theory simply cannot give the correct judgements. 
%	\todooldinfo{rewrite in imperssible language}
%}


%\todo{Maybe worth seeing if we can reword. RP: I actually liked this when I re-read it.}
%\begin{colored}{violet}
%\begin{colored}{red}
%	\todoinfo{I'm unhappy with this section. I'm not sure my rewriting is correct... }
%	
%First: Could a self-undermining decision theory be correct? 
%That is, could its verdicts match with what is actually impermissible for the agent. 
%If it is self-undermining, then one of its verdicts is that some alternative picking strategy is better than its own. 
%And thus it is in fact impermissible to pick in accordance with it. 
%
%This is assuming that that alternative picking strategy is available to the agent. 
%If the alternative picking strategy is so complex and computationally demanding that it lies beyond the agent's cognitive capacities to use reliably, then this is no bad mark against the self-undermining one. 
%Similarly, if in \emph{attempting to use} a given decision theory, it may misfire and result in even worse decisions, it may be permissible, or even required, to adopt the simpler decision theory. 
%However, we are assuming that we are not in this sort of case, and that it is within the agent's control to choose any picking strategy.
%
%\end{colored}


%	\todoinfo{RP: suggested rewrite }
	
First: Suppose a self-undermining decision theory is correct. That is, it deems impermissible exactly those options that are indeed impermissible. But, since it is self-undermining, it deems impermissible the option of picking in accordance with itself. And so it is indeed impermissible to pick in accordance with it, since it is correct. But surely it cannot be impermissible to pick in accordance with the true theory of rational choice. Therefore, the decision theory cannot be correct, which gives a reductio.

You might think that it could be impermissible to pick in accordance with the correct theory of rational choice, if for instance it is very costly to do so and there is a low cost alternative available that reasonably approximates the true theory, or if your attempt to pick in this way is likely to misfire, or if it is simply infeasible and so impossible for you to do it. But, when a theory is self-undermining, it is not for any of those reasons that it deems itself impermissible: it says it is impermissible even if it is cost-free to use it, and your attempt to use it always goes perfectly.

%Could a self-undermining decision theory be correct? 
%That is, could its verdicts match with what is actually impermissible for the agent. 
%If it is self-undermining, then one of its verdicts is that some alternative picking strategy is better than its own. 
%And thus it is in fact impermissible to pick in accordance with it. 

%This is assuming that that alternative picking strategy is available to the agent. 
%If the alternative picking strategy is so complex and computationally demanding that it lies beyond the agent's cognitive capacities to use reliably, then this is no bad mark against the self-undermining one. 
%Similarly, if in \emph{attempting to use} a given decision theory, it may misfire and result in even worse decisions, it may be permissible, or even required, to adopt the simpler decision theory. 
%However, we are assuming that we are not in this sort of case, and that it is within the agent's control to choose any picking strategy.




%
%A decision theory for which it is not correct, where it  for you to pick in accordance with might nonetheless be the best one to adopt if, for example, the alternative decision theories which give the correct verdicts are all so complex and computationally demanding that they lie beyond the agent's cognitive capacities to use reliably---not much good trying to use something that gives the right verdicts every time if you can never discover what verdicts it gives. But we have 
%
%\todo{Let's go back and double check these two paragraphs}A decision theory for which it is impermissible for you to pick in accordance with might nonetheless be a good one for you to \emph{adopt} if, for example, the alternative decision theories which give the correct verdicts are all so complex and computationally demanding that they lie beyond the agent's cognitive capacities to use reliably---not much good trying to use something that gives the right verdicts every time if you can never discover what verdicts it gives. And in attempting to use such a theory, you might be led further astray then adopting a simpler theory at the outset even if it does not actually correct. 
%%In attempting to follow its recommendations, it might lead you further astray than if you'd started with a simpler theory. 
%%But that is not the case we are considering here. It just needed to specify what to do when faced with $D^{\mathrm{Allais}}_{\mathrm{local}}$, certainly a theory that can be followed. 
%We have assumed that all possible picking strategies are available to the agent. We have assumed that it is within the agent's control to choose a picking strategy which is correct and never picks impermissible options. This is not beyond the agent's ken. And she can perfectly reliably implement this strategy. That is why we take the outcome of a picking strategy to be the outcome of whichever act it recommends.
%%\end{colored}
%
%\begin{colored}{red}
%{First: for any decision problem (set of available acts), $D$, a decision theory deems some subset of $D$ to be \emph{rejected} or \emph{rationally impermissible}. Now suppose the decision theory is correct: that is, the acts it declares impermissible are indeed impermissible for the individual. But one of its declarations is that picking strategies that never recommend impermissible acts are themselves impermissible---that's what makes it self-undermining. In that case, you might face a rational dilemma. That is, nature might thrust a sequence of decision problems on you where you rationally \emph{must} do something rationally impermissible. Suppose you face the choice of which picking strategy to use. If you choose a rationally impermissible picking strategy, you (obviously) do something impermissible in that decision problem. If you choose some other picking strategy, then there is some other decision problem where it recommends an impermissible act. If nature thrusts this decision problem on you, then implementing your picking strategy will lead you to pick an impermissible act. So you will have done something impermissible in this latter decision problem. This is a rational dilemma. And it is a particularly pernicious sort of rational dilemma, since it is not generated by any self-referentiality or act-state dependence. If there are no genuine rational dilemmas of this sort, then our initial assumption must be false: the decision theory simply cannot be correct.}
%
%Now, perhaps you might reply that it could be impermissible to use a decision theory that gives the correct verdicts if that decision theory were so complex and computationally demanding that it lay beyond the agent's cognitive capacities to use it reliably---not much good using something that gives the right verdicts every time if you can never discover what verdicts it gives. But that is not the case we are considering here. Indeed, we have assumed explicitly that, if I use a decision theory when I face a particular decision problem, I pick one of the acts it deems rationally permissible---that's why the outcome of a picking strategy is taken to be the outcome of whichever act it demands you choose.
%\end{colored}
%{\color{violet} Now, you might argue that the right decision theory to use is still one which results in }
%Now, it is possible that a good theory may not be the correct one. 
%Now, perhaps we shouldn't be looking for a correct theory, as perhaps they have some other flaws. For example, 
%{Now, you might (rightly) point out that correct theories might be flawed in some other way, and as a result, it may be no decisive mark against a self-undermining theory that it is not correct. For example,} 
%Perhaps this is not a decisive mark against a self-undermining theory. It could be impermissible to use any decision theory that gives the correct verdicts if, for example, those theories were so complex and computationally demanding that they lay beyond the agent's cognitive capacities to use reliably---not much good using something that gives the right verdicts every time if you can never discover what verdicts it gives. But that is not the case we are considering here. {Indeed, we have assumed that all possible picking strategies are available to the agent. So, in particular, it is within the agent's control to choose a picking strategy that never recommends impermissible acts. This is not beyond the agent's ken. And she can perfectly reliably implement this strategy. That is why we take the outcome of a picking strategy to be the outcome of whichever act it recommends.}
%\end{colored}


%{\todo{this needs fixing for above. But haven't we said it all above anyway? What's this section adding? RP: I'd cut the paragraph higher up where we say there's nothing funny going on. At that point, we're just introducing the idea and making the case it's odd prima facie. I think we leave the spelling out of how it's bad for here as well as deflecting the potential responses. C: yes, but I'm not sure exactly how to do that.}
Second: Relatedly, for someone who uses the decision theory, it gives contradictory advice at different points. Recall the case above in which you were initially uncertain whether you'd face $D^\mathrm{Allais}_\mathrm{local}$ or get \pounds 1m for sure, and your decision theory would choose Risky over Safe when faced with $D^\mathrm{Allais}_\mathrm{local}$ but would choose the picking strategy $\s_\mathrm{Safe}$ over $\s_\mathrm{Risky}$. Standing facing the decision problem $D^\mathrm{Allais}_\mathrm{local}$, you might ask yourself: my decision theory tells me to choose Safe and not to choose Risky, but it also tells me that, if I could have chosen how I would choose, it would have told me to choose Risky and not to choose Safe---which should I do?

If we again suppose that the self-undermining decision theory is correct, it leads to a rational dilemma, where one is rationally required to adopt a picking strategy which picks in an rationally impermissible way. 

%{\todo{this needs fixing for above. But haven't we said it all above anyway? What's this section adding? RP: I'd cut the paragraph higher up where we say there's nothing funny going on. At that point, we're just introducing the idea and making the case it's odd prima facie. I think we leave the spelling out of how it's bad for here as well as deflecting the potential responses. C: yes, but I'm not sure exactly how to do that.}
%	Second: Relatedly, for someone who uses the decision theory, it gives contradictory advice at different points.
%	Recall the case above in which you were initially uncertain whether you'd face $D^{\mathrm{Allais}}_{\mathrm{local}}$ or get a sure amount of money. Your decision theory then recommended, say, the picking strategy which selects Safe. But yet when you face the decision problem itself, it recommends Risky. Which of these perspectives is privileged? Standing facing the decision problem, you might ask yourself: my decision theory tells me to choose Safe rather than Risky, but it also tells me that, if I could have chosen how I would choose, it would have told me to choose B and not to choose A---which should I do?

%It's worth adding that, for those decision theories that permit the Allais preferences and also satisfy an Archimedeanicity postulate, they consider it rationally required of you, at the point when you're uncertain which decision problem you'll face, to pay money if it's possible to thereby to bind yourself to doing something other than what they will recommend when you actually face that decision. %\todo{C: we need to add Arch somewhere above!}.

These self-undermining decision theories would prefer to bind themselves to do something other than what they recommend when you actually face that decision.
Of course, we're used to that in cases of temptation---Ulysses should pay his sailors to bind him to the mast as their ship passes the Sirens---but that's because we think your utilities will change under the pressure of temptation or your probabilities will change in an irrational way or you won't choose rationally on the basis of your utilities and probabilities. Nothing like that is going on here.

We're also used to that in cases of act-state dependence. Causal decision theorists say that in Newcomb's problem you should take both boxes, but if you can pay to take a pill to turn yourself into a one-boxer before the prediction is made, then you should. But that's because choosing how to choose, in this case, causes you to face a better decision problem down the line. Nothing like that is going on here. And perhaps we think that, at least when choosing a picking strategy has no causal or evidential impact on which decision problems you will face or the value of the options in those problems, the correct theory of rational choice should not give rise to such dilemmas.


%In this section, we consider some responses to the objection we've outlined above. What might the defender of a risk-sensitive decision theory that permits Allais preferences say in response to the charge that their theory is self-undermining in the way we've described?

%\todooldinfo{Todo: Plan is for RP to make progress here.\\ Perhaps to base it on sec 1.2 of v14b, but I actually think I guess there are three things to discuss: (a) it's supposed to be universal (b) connection to diachronic etc. Sec 1.2 of v14b does a lot about it judging itself, which looks more like we need to do more discussion of strategy vs judging itself, which I think perhaps we should not get into the weeds of yet...? }

\subsection{Responses}

\subsubsection{Limit the decision theory's scope}

	Perhaps the defender of a self-undermining decision theory will say it was never their intention that their theory should be used for these higher-order decisions. They might say they are offering a theory of first-order rational choice; not a fully general theory that covers any sort of decision, including these higher-order decisions between picking strategies. 
	
But that can't be right, for these theories are presented by their proponents as universal decision theories---they are intended to cover any sort of decision, providing we can determine credences and utilities and any other parameters that must be fixed. In their descriptions, it is not specified that they are to be applied only to a certain sort of decision, such as decisions between first-order actions. They are intended to be what above we called structural: that is, their recommendations don't depend on the content of the outcomes, but only on the list of credences of various utility outcomes. And, as we saw in our treatment of the Allais decisions above, for any higher-order decision between picking strategies under uncertainty about the decision problem you'll face, there is a decision between ordinary first-order actions that exactly mirrors it. If the defender of a self-undermining decision theory were to respond in the way outlined, they'd have to deny that their decision theory is structural in this sense and they'd have to say why that is the case.
	
	

%Perhaps the defender of a self-undermining decision theory will say it was never their intention that their theory should be used for these higher-order decisions. They are offering a theory of first-order rational choice; not a fully general theory that covers any sort of decision, including these higher-order decisions between picking strategies. 
%But that can't be right, for these theories are presented by their proponents as universal decision theories. In their descriptions, it is not specified that they are to be applied only in specific cases. 
%%These arguments are truly formal in the sense that the content of the decisions in question is not relevant to our evaluation of their plausibility. If the theory is not supposed to apply to higher-order decisions as well as first-order decisions, the defender of the theory must explain why the axioms are true when they govern preferences between first-order acts, but not when they govern preferences between higher-order acts like picking strategies.
%\end{colored}


%\todooldinfo{Todo: select part of the buchak quote, from below. Or perhaps just don't bother.//!}
%{\color{cyan}
%	
%	\begin{quote}
%		an individual might be more risk-
%		avoidant when it comes to his health than when it comes to money.  \ldots So, says the criticism, an individual’s r-function should be
%		indexed to particular domains or stakes, and there need not be any specific relation-
%		ship between rhealth and rmoney, or between rlow stakes and rhigh stakes
%		.
%		
%		\ldots
%		
%		 in the end this debate should not take place at the level of which preferences seem
%		reasonable anyway: it should proceed via a discussion of whether the axioms that
%		underlie REU theory are rational requirements. 
%		
%		\ldots 
%		Finally, I might respond to the objector who wants to allow different
%		risk-attitudes in different domains by pointing out that some gambles will be hybrid
%		gambles, that might result in a health outcome but might result in a monetary out-
%		come—for example, the purchase of medical insurance—and the objector will have to
%		say how the agent values these.
%		
%		(\citet[p79-80]{buchak2014rr})
%	\end{quote}
%	
%	More content:
%	\begin{quote}
%		One might agree that ruling out risk
%		avoidance/inclination is the only thing EU theory gets wrong, but think that I have
%		overlooked an important fact: namely that rational individuals can have different
%		risk functions in different domains. For example, an individual might be more risk-
%		avoidant when it comes to his health than when it comes to money. Or he might have
%		different risk functions when the stakes are different: he might be more risk-avoidant
%		the higher the stakes are. So, says the criticism, an individual’s r-function should be
%		indexed to particular domains or stakes, and there need not be any specific relation-
%		ship between rhealth and rmoney, or between rlow stakes and rhigh stakes
%		. That we accept different
%		levels of risk in different situations is born out by empirical evidence: a study by
%		Rottenstreich and Hsee (2001) found that the shape of the weighting function in pros-
%		pect theory depends on the kind of decision being made. For example, even though
%		individuals preferred \$50 to a kiss with their favorite movie star, they tended to be
%		willing to pay more for a chance of the kiss than for an equivalent chance of \$50:
%		they were more risk-seeking with respect to the kiss. More generally, the weighting
%		function deviated more from linearity when the possible outcomes were more emo-
%		tionally laden.
%		
%		I do not have space to explore this possibility in detail, but there are a few ways
%		to respond to these suggestions\ldots I do grant that I am ruling
%		out certain preferences as irrational. For example, an REU maximizer cannot value a
%		gamble below its EU in large stakes and value a gamble above its EU in small stakes, if
%		the probabilities of the analogous outcomes are the same. So the second thing to say is
%		that in the end this debate should not take place at the level of which preferences seem
%		reasonable anyway: it should proceed via a discussion of whether the axioms that
%		underlie REU theory are rational requirements. I will present these in the next chapter,
%		but it is worth mentioning that the axiom that the proponent of this objection is likely
%		to challenge is Axiom (A1), the Ordering Axiom, which entails that all gambles are
%		comparable. If one thinks that risk-attitudes may be different in different domains,
%		one might be drawn to thinking that we cannot compare outcomes that fall within dif-
%		ferent domains; otherwise, it would seem odd to have different preference norms in
%		different domains. Finally, I might respond to the objector who wants to allow different
%		risk-attitudes in different domains by pointing out that some gambles will be hybrid
%		gambles, that might result in a health outcome but might result in a monetary out-
%		come—for example, the purchase of medical insurance—and the objector will have to
%		say how the agent values these.
%		(\citet[p79-80]{buchak2014rr})
%	\end{quote}
%}

%No! It's supposed to be universal!

%Their theories are supposed to be universal. Especially Buchak talks about this. So we should apply REU equally to the choice of how to choose as to the choice of what to do. But then it says something else is better. So we shouldn't apply REU universally? Or what? How to think about this? 

%\subsubsection{What does REU guide you to do?}




%How different is it to other cases of REU seeing that optimal strategies are different to optimal actions. And diachronic stuff, or sequential stuff etc?? 

%What should one actually do? Conflict!

%It deems itself rationally impermissible. That just, on the face of it, seems very bad!
%\begin{colored}{violet}
	
%\subsubsection{What is being judged}

%What we've used the decision theory to evaluate is picking functions. We then associated picking functions with the decision theory to draw the conclusion that the decision theory is self-undermining. 

%However, decision theories are only able to be associated with picking functions depending on further parameters -- 

%Decision theories typically specify certain parameters -- credences, utilities, and perhaps a risk-profile -- to determine a so-called choice function, which specifies for each decision problem, which actions from it are deemed impermissible. Once we have a choice function, we can specify picking functions that are compatible with it by just checking whether it picks an impermissible action.

%What we have then shown is that choice functions that have certain structure are undermining. 
%For example, endorse the Allais preferences and either are opinionated about the local decision, or a slight sweetening is sufficient to induce such a strict preference and that this is a small enough sweetening to leave the overall Allais preferences unaffected. 

%We have then said that this shows that the decision theory recommends using a different decision theory. But that is only the right diagnosis if we hold fixed the parameters of credences, utilities and risk-profile, assuming that they don't change once she knows which decision problem she'll be faced with. But alternatively one could hold fixed one's decision theory and make conclusions about the other parameters. 

%We can hold fixed Expected Utility Theory and use similar analysis to make judgements about credences. This is essentially done in the approach of Schervish and Levinstein, and one's credences must be probabilistic. 
%We might alternatively think that her credences can vary depending on which decision problem she is faced with, treating the decision and state as dependent. This is Brown's argument for updating credences by conditionalization, holding fixed Expected Utility Theory. 
%Good's Value of Information theorem holds fixed both Expected Utility Theory and conditionalization but considers whether the agent wants to gather or avoid the free evidence. 

%Similar analysis could be done by holding fixed a different decision theory, say Buchak's risk-weighted expected utility theory. 
%Showing that the agent sometimes wants to avoid the free evidence, by holding fixed the decision theory and updating by conditionalization \citep{buchak2017trbvi}.
%One might also consider holding fixed that she'll take the evidence but consider what credal update plan is such that the plan judged as optimal will lead to her making decisions in accordance with REU (holding fixed her risk function and utility function).\footnote{See CCM\&BS??}

%What this shows is that the target of the criticism of self-undermining choice functions depends on what parameters are held fixed.\todo{doesn't this all then underminine our conclusion that the decision theory is bad??!! RP: I don't think so. It could, of course, be taken to show that the credences or the way of updating is wrong, but we've plenty of other reasons for thinking the credences and the way of updating them is fine. You could certainly escape all this by introducing constraints on credences and alternative updating rules, but that would be very radical. }

%The same kind of argument has been used which instead hold fixed that she makes decisions in accordance with Expected Utility Theory and instead uses these results to judge her credences (Schervish/Levinstein). We could allow her credences to vary depending which decision she is faced with, treating the decision and state as dependent and then use this as an argumment evaluating credal update plans. This is essentially Brown's argument for updating credences by conditionalization by holding fixed EUT (see some considerations around it for REUT in REF).
%Someone WHO?? is considering varying utilities.
% Good's Value of Evidence cases instead hold fixed that she'll update by conditionalization and make a decision in accordance with expected utility theory, but judges whether she wants to gather the evidence or avoid it. 
% 
 


%\end{colored}


%\begin{colored}{gray}

%\subsubsection{Change the way of updating credences}
%	\todoinfo{CCM trying to condense...}
%	 \todo{v1 !!!}

	
%	We have assumed that your uncertainty about which decision problem you're faced with is probabilistically independent of he first-order state of the world, which is relevant for determining the payoffs of the actions in the problem. 
%	From this assumption, we concluded that when faced with the particular decision problem, say $D^*$, you'll use those same first-order credences to make your decision. 
%	This is justified on the basis of assuming that the agent updates by Bayesian conditionalisation, although the same feature arises from various other update methods such as Dempster-Shafer theory \cite[pp. 133-5]{weisberg2015uui}. It is however, an assumption that can be rejected. 
%	
%	\todo{some ref to Bernhard?}In such an undermining case, we have a situation where what the decision theory judges as the best strategy is different to what it recommends when you know which decision problem you'll be faced with. The option it recommends once faced with a particular decision problem, $D^*$ is different. Say that the overall strategy judged as optimal by the decision theory is $\s_{\text{Risky}}$ but that in $D^*$, the decision theory recommends the Safe option. 
%	This can be rationalised by the decision theory by instead saying that when she learns she's faced with this decision problem, she does not update by Bayesian conditionalisation but instead updates to some credence function which, using the specified decision theory, evaluates Safe to be preferable; for example she might become certain that the company will go bust, thus rationalising picking Safe. 
%	
%	One might question the rationale behind such an update method, but several arguments for Bayesian conditionalization rely on the assumption of expected utility theory \citep[sec7]{campbellmoore2020arae}. We might consider justifying a credal update method by its fruits in terms of guidance in decision making. One can argue for Bayesian conditionalization as it is the update method which you evaluate will lead to the highest utility if one updates in accordance with it and then chooses what to do in accordance with expected utility theory. This is essentially Brown's (\citeyear{brown1976ceu}) argument for conditionalization, which makes use of Good's (\citeyear{good1967pte}) Value of Information theorem. 
%	But if we replace the assumption of expected utility theory with alternative decision theories, say \citet{buchak2010irereg}, and apply the same argument, what the failures of the Value of Information theorem show, or the examples we have of self-undermining decision theories, is that  the theory evaluates a different decision theory or picking strategy to be adopted, or that it results in a different update method from Bayesian conditionalization. 
%	
%	Just like the evaluation of the decision theory itself, what we get, however, is a difference between a ``local'' evaluation and a ``global'' evaluation \citep{campbellmoore2022aurs}. The decision theory may judge that the best strategy for updating her credences is one which results in avoidance of the self-undermining phenomena, once she has actually learned her evidence, some alternative way of updating may look better, perhaps even conditionalization. 
%	As soon as we think she should update in accordance with this local evaluation which differs from the global one, then we are again in the situation of self-undermining decision theory. \todo{what do i mean}
%	
%	-----
%	\emph{delete below}
%	In this argument, we have essentially assumed Bayesian conditionalisation. 
%	We assumed that your probability over the higher-order states makes which decision you'll face probabilistically independent of the first-order state of the world. And we assumed that whichever decision problem you face, you will use those same first-order probabilities to make your decision. This assumption that updating on probabilistically independent information does not change your state of uncertainty is justified by Bayesian conditionalisation, as well as holding in various other update methods such as Dempster-Shafer theory \cite[pp. 133-5]{weisberg2015uui}. It is however, an assumption that can be rejected. 
%	
%	
%	A decision theory which evaluates some other picking strategy to be better than its own recommendations means that if you were to learn which decision problem you'll be faced with and then change your first order credences before deciding in accordance with the specified theory, y
%		
%	
%	Several standard arguments for conditionalization assume that rational agents maximise expected utility, rather than risk-weighted expected utility \citep[sec7]{campbellmoore2020arae}. When considering alternative decision theories, we might instead evaluate what the decision theory itself evaluates as the optimal credal update strategy. This could either be based on evaluating which update strategy is evaluated as leading to the best decisions (\citet{brown1976ceu}, making use of \citet{good1967pte} Value of Information), or by evaluating which is judged as leading to the most epistemic utility \citep{greaves2006jcc,campbellmoore2022aurs}. 
	
	


%}


%We argued that self-undermining decision theories result in a dilemma, offering conflicting advice about what to do when faced with a given decision, should you consult the optimal picking plan and follow its recommendations? Or should you apply the decision theory now you're facing the particular decision problem.

%\end{colored}




	\subsubsection{Change the way of updating credences}

There is another way the defender of these theories could argue against the charge of self-underminingness. They can note first that, by assuming decisions are probabilistically independent of states of the world, and assuming our credences in states of the world don't change when we learn which decision we face, we have essentially assumed Bayesian conditionalization. And then they can argue against conditionalization. As pointed out in \citet[16]{campbellmoore2020arae}, several standard arguments for conditionalization assume that rational agents maximise expected utility.

The picking strategy which the decision theory deems optimal is compatible with that very decision theory if instead we allow her credences to change when she learns which decision problem she faces, even though they are probabilistically independent. Instead of holding fixed her credences (assuming conditionalization), the defender of the decision theory might instead argue for an alternative credal update strategy: the one which results in the optimal picking strategy when coupled with risk-weighted expected utility theory \citep[see also][]{campbellmoore2022aurs,brown1976ceu}.

Whilst we acknowledge this is a possible way out of the criticism, it is a significant bullet to bite. 




%\begin{colored}{red}
%\todoinfo{ORIGINAL}
%Another way the defender of these theories could argue against our objection against self-undermining theories is to argue that we have presupposed Bayesian conditionalization, and then argue against that norm. 

%We have assumed conditionalization because, when evaluating the strategies, we have constructed a probability over the higher-order states of the world---which specify both the first-order state of the world and the decision problem you'll face---by taking probabilities for the first-order states, probabilities for the decision problems, and assuming the decision you face is independent of the first-order state of the world. To see this, consider the relationship between $D^\mathrm{Allais}_\mathrm{local}$ and $D^\mathrm{Allais}_1$ and $D^\mathrm{Allais}_2$ above.
%We then assumed that once you face whichever decision problem, you will use those same first-order probabilities to make your decision. 
%This step has made use of Bayesian conditionalization. 
%Perhaps, if you update your credences in some alternative way, what the decision theory recommends in each decision theory might correspond exactly with the optimal strategy.


%{ It is worth noting that many theories insist that updating on irrelevant information does not change your state of uncertainty, not just traditional Bayesianism. For example, Dempster-Shafer theory models evidential irrelevance and updating in a much different way from the Bayesian one (using Dempster’s Rule of Combination). Nonetheless, Dempster-Shafer theory also makes this prediction \cite[pp. 133-5]{weisberg2015uui}.}

%{ Firstly, we do not assume anything so strong. We do indeed assume that propositions about which decision you face are both causally and evidentially irrelevant to the first-order state of the world. We also assume that if you update on some bit of information that is irrelevant to the state of the world, then your views about the choiceworthiness of actions whose outcomes only depend on the first-order state of the world will not change. Bayesians model evidential dependence as probabilistic independence. And updating by conditionalizing has the feature in question: conditioning on some bit of information that is probabilistically independent of the state of the world does not change your probabilities over worlds; and assuming that your views about the choiceworthiness of actions supervene on the relevant probabilities and utilities (which we hold fixed), those views will not change either. But many other models of uncertainty, updating and choice have this property as well. For example, Dempster-Shafer theory models evidential independence and updating in a different way (using Dempster’s Rule of Combination), but nonetheless behaves in the way described above \cite[pp. 133-5]{weisberg2015uui}.}



%{ But put that to the side. As pointed out in \citet[sec7]{campbellmoore2020arae}, several standard arguments for conditionalization assume that rational agents maximise expected utility, rather than risk-weighted expected utility. Perhaps the argument we have made here can be turned into an argument against Bayesian conditionalization.}


%Whilst we don't know of any defenders of these theories taking this line of argument, as pointed out in \citet[sec7]{campbellmoore2020arae}, several standard arguments for conditionalization assume that rational agents maximise expected rather than risk-weighted expected utility. And in fact, the argument we have made here can be turned into an argument against Bayesian conditionalization. 

%We could judge a credal update method by the utility of the action it requires you to select (using one's preferred decision theory) in each decision problem. The credal update method which you evaluate to be optimal will exactly be one where picking in accordance with the decision theory using the updated credences is just the picking strategy that the decision theory evaluates as optimal. The example we have discussed implies that it won't always be conditionalization, because making a decision with the first-order probabilities is not evaluated as the optimal picking strategy, so the update cannot return the original first-order probabilities despite the higher-order probabilities encoding the assumption that they are independent. 

%This approach is closely related to Brown's (\citeyear{brown1976ceu}) argument for conditionalization as an update rule, which makes use of Good's (\citeyear{good1967pte}) Value of Information theorem. But the Value of Information Theorem fails for these decision theories \citep{wakker1988neuai,buchak2010irereg}: sometimes you think you'll make better decisions if you ignore the evidence (or don't update your credences). 
%The epistemic variant of this argument is from \citet{greaves2006jcc}, and \citet{campbellmoore2022aurs} consider how it applies to agents who use Buchak's (\citeyear{buchak2014rr}) risk-weighted decision theory. 

%However, as \citet{campbellmoore2022aurs} stress, whilst this might provide an argument that the optimal update strategy is this particular way, this does not mean that the risk-sensitive agent is rationally required to adopt such an update procedure, unless one has a principle linking previous evaluations of strategies to rational behaviour. And this is in general controversial, and doubly so in the case of risk-sensitive theories.

%In that paper, \citet{campbellmoore2022aurs} also consider ``local'' versions of the epistemic arguments for update procedures, following \citet{leitgeb2010ojb2}, showing that they require the risk-sensitive agent to nonetheless update by conditionalization. \Citet{campbellmoore2022aurs} argue that this is actually what gives the rational requirements on updating, and so conclude that conditionalization is rationally required (and thus, the Value of Information challenge cannot be avoided this way, cf., \citep{campbellmoore2020arae}). The analogous questions can be also asked for the practical utility versions: whilst we are unsure what this results in, it is unlikely that they result in the same recommendations as the optimal update plan.\footnote{It differs from the epistemic versions because we used an $r$-proper scoring rule, but this is not what we'd get if we just use pragmatic utility. } And thus, whilst the agent might evaluate the optimal update plan to be one which avoids the undermining we have identified, it is not the update method which we think that they should actually implement. 


%\end{colored}


%{\color{red}
%	
%	\bigskip -----
%
%
%ALTERNATIVE VERSION:
%
%
%
%Whilst we don't know of any defenders of these theories taking this line of argument, as pointed out in \citet[sec7]{campbellmoore2020arae}, several standard arguments for conditionalization assume that rational agents maximise expected rather than risk-weighted expected utility. And in fact, the argument we have made here can be turned into an argument against Bayesian conditionalization. 
%%As is familiar, such theories lead to cases where the agent will pay to avoid free evidence \citep{buchak2010irereg}, but such violations can immediately be turned into arguments against updating 
%
%\Citet{brown1976ceu} provides an argument for Bayesian conditionalization inspired by Good's \citeyear{good1967pte} value of information principle. Good's principle shows that you will always do better if you take into account the available evidence before making your decision. Or equivalently, that if you make a decision in accordance with your credences updated by conditionalization, then you expect that you'll do better than making them instead using your prior credences. Brown moreover notes that we can judge various ways of updating your credences by the utility of the action they guide you to make, and it turns out that conditionalization will always be best. 
%
%But this argument will fail for the defender of risk-weighted decision theory, or any theory accommodating the Allais preferences or violating the sure thing principle. Any failure of the Value of Information principle, as we have for these theories \citep{buchak2010irereg,wakker1988neuai}, can be seen as cases where making the decision using one's prior credences is evaluated as better than making it after updating by conditionalization, or put another way, that updating your credences by staying put is preferable to updating them by conditionalization. So the argument for updating by conditionalization fails, some other update rule is better. 
%
%\Citet{campbellmoore2022aurs} make this point and investigate how the arguments apply for update rules, focusing not on practical utility but on maximising epistemic utility, or accuracy. We can apply analogous investigation in the case of practical utilities. An extension of the argument of Brown, or in the epistemic case, \citet{greaves2006jcc} would be to evaluate various update strategies and adopt the update strategy which you risk-weightedly expect to lead you to the best decisions, if you then use them to make a decision in accordance with risk-weighted expected decision theory. We could apply an analogous argument here: you have $P$ a probability measure over $\Omega\times\D$; you should plan to update your credences when faced with the various decision problems, $D$, so that when you then make a decision using those new credences (in accordance with risk-weighted expected utility theory), an optimal strategy will be recommended. This update must not be conditionalization, but there is some way of updating your credences to satisfy this desiderata: if $\s$ is the optimal picking strategy, then for each $D$, adopt the credences such that using them in your decision theory tells you to pick $\s(D)$. 
%
%\Citet{campbellmoore2022aurs} investigate what such an update looks like in the epistemic case, and the same could be done in the practical case. 
%
%However, there remains the question of whether this is a good argument for the rational requirement to update her credences in accordance with the proposed update rule. The alternative update rule might be the optimal strategy, but why think one should implement optimal update strategies. This is exactly the sort of thing that will fail for such theories \citep[discussion in ][section 4.2]{campbellmoore2022aurs}. 
%
%}

%
%
%\bigskip 
%--------
%
%
%
%
%Here is one way to argue for a method of credal updating: you provide an update plan, i.e., numerical values you will adopt as 
%
%\Citet{campbellmoore2020arae} investigate, there are various ways to apply arguments for rational update methods
%
%
%
%
%Any theory that accommodates the Allais preferences, or more generally, fails the Sure Thing Principle, is liable to have a case where what 
%
%
%
%
%
%
% As we presented the higher-order decision between strategies $\s_1$ and $\s_2$, you determine the probabilities over the higher-order states of the world---which specify both the decision problem you'll face and the first-order state of the world---by taking probabilities for the first-order states, probabilities for the decision problems, and assuming the decision you face is independent of the first-order state of the world. 
% And then, once you face whichever decision problem you do face, you use those same probabilities for the first-order states to make your decision. Now, that is clearly the right thing to do if you update your probabilities by standard Bayesian conditionalizing. 
% That is, once you know which decision problem you face, you simply conditionalize on that information to give your new probabilities, and because the decision problems and the worlds are independent, learning what decision problem you face doesn't change your credences about the world. 
% 
% One way to avoid this conclusion and the dilemma it poses is to argue against Bayesian conditionalization. 
% 
% 
% 
% 
%The problem with that assumption is that many decision theories that permit the Allais preferences don't think you should plan to update by conditionalizing on new evidence. Indeed, the cases we're discussing demonstrate that.
%
%
%
%
%
%
%$$
%\begin{array}{r|cccc}
%	& \omega'_1\ \&\ D_1 &  \omega'_2\ \&\ D_1 &  \omega'_1\ \&\ D_2 &  \omega'_2\ \&\ D_2 \\
%	\hline
%	P &  \sfrac{1}{11} \times \sfrac{11}{100} & \sfrac{10}{11}\times\sfrac{11}{100} & \sfrac{1}{2}\times\sfrac{89}{100} & \sfrac{1}{2}\times\sfrac{89}{100} \\
%\end{array}
%$$
%
%And we use the decision theory to evaluate the optimal picking strategy. We then noticed that it differs from what the decision theory recommends when faced with $D_1$, as calculated using $p$. 
%
%The defender of these decision theories might point out that this has made use of the assumption that you are updating by conditionalization. 
%
%
%
%To judge the recommendations of the decision theory, we applied the decision theory at the higher-level taking account of one's uncertainty not only over the state of the world but also over what decision she'll be faced with. 
%
%We assumed that these are independent. However, it is Bayesian conditionalisation which allows us to go from the assumption that they are independeent.  
%
%	
%In the example we gave, we assumed that which decision theory the agent will be faced with is independent of what the world was like.  
%
%One way that the defender of such decision theories may respond to our challenge is to reject our use of conditionalization. 
%
%Whilst conditionalization didn't explicitly 
%
%
%
%
%
%
%
%
%We presented this as offering contradictory advice at the point at which you face the first-order decision. Should you decide in accordance with what the optimal plan tells you to do, or should you apply the decision theory in this case?
%
%
%
%
%
%
%
%As is familiar,  theories which exhibit the Allais preferences will sometimes recommend avoiding free evidence, and even paying to avoid evidence \citep{buchak2010irereg}. Such arguments can be seen as 
%
%
%\Citet[sec.7]{campbellmoore2020arae} note that the 

%}




%
%
%
%{\color{red} This was RPs. To be deleted???
%
%
%
%
%In response to the second argument against self-undermining decision theories from above---the argument that they give rise to irresolvable dilemmas for the agent who uses them---a defender might say that the dilemma is, in fact, easily resolvable: You should do what your decision theory tells you to do at the point at which you face the decision. After all, at that point, you have more evidence, for you know which decision problem you'll face; and the Principle of Total Evidence tells us to choose using the more informed credences.
%
%The problem with that response is that the standard decision-theoretic justification of this version of the Principle of Total Evidence---which originates with Janina \citet{hosiasson1931wdw} and Frank \citet{ramsey1990wvk}, and is noted by \citet{savage1954fs}---doesn't hold for theories that permit the Allais preferences. It is well-known that these theories will sometimes require you to pay not to receive certain evidence; or, if you can't help but receive it, they'll prefer you to choose using the credences you had before learning it  \citep{buchak2010irereg}.
%
%So that response doesn't work, but it does suggest an alternative response that might work better. As we presented the higher-order decision between strategies $\s_1$ and $\s_2$, you determine the probabilities over the higher-order states of the world---which specify both the decision problem you'll face and the first-order state of the world---by taking probabilities for the first-order states, probabilities for the decision problems, and assuming the decision you face is independent of the first-order state of the world. And then, once you face whichever decision problem you do face, you use those same probabilities for the first-order states to make your decision. Now, that is clearly the right thing to do if you update your probabilities by standard Bayesian conditionalizing. That is, once you know which decision problem you face, you simply conditionalize on that information to give your new probabilities, and because the decision problems and the worlds are independent, learning what decision problem you face doesn't change your credences about the world. 
%The problem with that assumption is that many decision theories that permit the Allais preferences don't think you should plan to update by conditionalizing on new evidence. Indeed, the cases we're discussing demonstrate that.
%
%Suppose you make a plan: if I learn I face decision problem $D_1$, I'll adopt these posteriors; if I learn I face $D_2$, I'll adopt those posteriors. And suppose you take the utility of this plan at one of the higher-order states of the world to be the utility of whichever act you'll choose using your decision theory and the posterior credences you'll have if you learn the evidence that's true at that state and update as your plan says you should. Then the plan that looks best from your situation of uncertainty about which decision problem you'll face is one that leads to posteriors that will lead you to choose in line with strategy $\s_1$, since that's the strategy you prefer from that vantage point.
%
%So it might look as if we have a response to the self-undermining challenge: it is based on an account of credal updating that the user of the Allais-permitting decision theory rejects. The problem is that all we've shown is that these decision theories say you shouldn't \emph{plan} to conditionalize; not that you shouldn't conditionalize. \citet{campbellmoore2022aurs} note a similar problem arises when you evaluate an updating plan not by the utility of the posteriors to which it gives rise, but by something like the accuracy of those posteriors. And they argue that, in that context, risk-weighted expected utility theory indeed tells you to plan to update other than by conditionalizing, indeed, that this immediately follows from the avoidance of evidence. They nonetheless argue that one should actually conditionalize when the evidence comes in. And so any defender of a self-undermining decision theory who wishes to use the response outlined here must say why that isn't true for their decision theory. For if it turns out that, once you learn what decision problem you actually face, you should in fact update by conditionalizing, even though you would have planned not to had you planned before the uncertainty was resolved, then the self-undermining worry remains.
%
%}


\subsubsection{Uncertainty about decisions}\label{sect:reu:other mu}
%\todooldinfo{The writing/wording needs improving here, but I am proposing that it is at least a good working draft of it and not thinking that big changes need making.}

In our argument that Allais-permitting decision theories are self-undermining, we used the preferences they permit over the Allais gambles to construct a \emph{particular} way that you might be uncertain about what decisions you'll face and showed that, \emph{in that case}, you judge some alternative picking strategy to be preferable. 
%{\color{violet}Or, more generally, we noted that one could use any particular failure of the Sure Thing Principle or the Independence Principle to generate a particular such challenge. }



Moreover, the particular way of being uncertain over decisions you'll be faced with was a rather odd one. We specified that the credence you'll face $D^{\mathrm{Allais}}_{\mathrm{local}}$ is $\sfrac{1}{11}$ and your credence that you'll get the constant amount is $\sfrac{89}{100}$, and we chose the constant specifically to demonstrate the undermining feature. 
	
	Of course this might be the situation you're facing, where you happen to have these credences over the possible decisions. It might be just unfortunate coincidence, or it could be specifically constructed this way by a nefarious opponent who has set you up: they're going to toss a biased coin to determine what to offer you at the specified probabilities, having chosen these numbers specifically to demonstrate the inconsistency in your judgements. 
	
	However, typically one's uncertainty over which decision you'll face is spread over a wide class of possible decision problems---how many decision problems are you fully certain you won't face? If your particular uncertainty is not one that generates underminingness, and so, relative to that uncertainty, your decision theory judges its own picking strategies to be optimal, is it really so problematic that, were your uncertainty different in some specific way, your decision theory would be undermining?
	
	


%\begin{colored}{red}ORIGINAL:
%	%	But these are only generating a particular way of being uncertain over decisions under which the strategy undermines its own recommendations. 
%Moreover, the particular way of being uncertain over decisions you'll be faced with was a rather odd one. We specified that the credence you'll face $D_1$ is $\sfrac{1}{11}$ and your credence that you'll face $D_2$ is $\sfrac{89}{100}$. 
%%More generally, any strict failure of the Sure Thing Principle or Independence Axiom would generate such an example.
%%\todoold{RP: I had a go at changing: will this work?}can be used to generate such a self-undermining example: if your decision theory leads you to strictly prefer act $a$ to act $b$, but also strictly prefer the mixed act that gives you probability $p$ of getting act $b$ and probability $1-p$ of getting act $c$ to the mixed act that gives you probability $p$ of getting act $b$ and probability $1-p$ of getting act $c$, then we can immediately see that the decision theory is self-undermining. 
%We could motivate this uncertainty if, for example, you believe you are facing a nefarious opponent who has set you up: they're going to toss a biased coin then offer you $D_1$ or $D_2$ at the specified probabilities, having chosen these number specifically to demonstrate your inconsistent judgements. 
%
%But this is not how we're usually uncertain over what decisions we'll face. 
%What does this argument show about someone who is uncertain about what decision problems she'll face in an alternative, and more normal, way?\todo{CCM: why is it abnormal? Feels like it can be motivated to me... like in the doctor case. }
%{\color{violet} For example, a spread over a much wider range of possible decisions. }
%
%\end{colored}

This is analogous to a certain standard response to the Dutch book arguments: perhaps you just think it's unlikely you'll ever face such a nefarious bookie. A common response is to argue that the mere existence of a Dutch book already shows you are irrational because it shows your preferences are inconsistent in a particular way---they judge the same decision differently when it is presented in different way, perhaps.\footnote{Cf. \citep{armendt1993db,mahtani2014db}.} %The set-up in which a bookie approaches you and offers a string of bets merely dramatizes this inconsistency. 
{The set-up in which an opposing Gambler approaches you, buys and sells bets that you deem fair, and thereby saddles you with a sure loss merely dramatizes this inconsistency.} The argument doesn't assume you'll ever actually meet such a person. We might argue similarly that the mere existence of self-underminingness for some way of being uncertain about what decision you'll face is already a challenge to the decision theory. Perhaps it shows that it is inconsistent in the same way the Dutch book argument shows non-probabilistic credences are inconsistent.

In the case of the Dutch book arguments, \Citet[Sec 6.2]{pettigrew2020dutch} argues the mere existence of a set of bets you'll accept individually that, taken together, lead to sure loss isn't sufficient to show you are  irrational. Instead, he asks what happens if you are uncertain about which decisions you'll face. Drawing on the results from Mark \citet{schervish1989gm} and Ben \citet{levinstein2017pgeu} that we mentioned above, he shows that, for very  many natural ways of being uncertain about the decisions you'll face, if you have non-probabilistic credences and face whatever decision you'll face with those credences, there are alternative probabilistic credences you might have had instead that guide your choices better.








%
%
%\todooldinfo{Can we include }
%
%We would like to be able to offer an alternative and more general argument which would apply to a whole host of ways of being uncertain about which decision problem you'll be faced with. 
%
%
%\Citet{pettigrew2020dutch} instead agrees that the mere existence isn't sufficient to show irrationality. Poor performance in a particular situation is not usually a reason to abandon a tool, since it might compensate by performing better in other situations. He instead develops a more general argument that probabilistic credences are better guides to action. We could similarly try to develop a more general  result applying to a whole host of ways of being uncertain about what decision you'll be faced with. 
%
%
%
%
%
%
%However, this is just a particular, unusual situation to be in. And poor performance in a particular situation is not usually a reason to abandon a tool, since it might compensate by performing well in other situations. Something similar may apply here. 
%
%
%
%
%In our argument that Allais-permitting decision theories are self-undermining, we used the preferences they permit over the Allais gambles to construct a \emph{particular} way that you might be uncertain about what decisions you'll face and showed that, \emph{in that case}, you judge some alternative picking strategy to be preferable. But the defender of such a theory might reply that this shows only that the theory has these troubling consequences for agents who are uncertain in that way. For all we've shown, the theory might be entirely unproblematic when you are uncertain in other ways about the decision problem you'll face. Perhaps, according to your uncertainty, the theory is self-recommending.
%
%{\color{violet}
%Moreover, the particular way of being uncertain required for the example was a particular constructed case using the Allais preferences, specifying that the credence you'll face $D_1$ is $\sfrac{1}{11}$ and your credence that you'll face $D_2$ is $\sfrac{89}{100}$. These would be the right credences to have in a particular scenario, where a neferious opponent sets you up with this problem: she'll offer you $D_1$ or $D_2$ at the specified probabilities, having chosen these number specifically to demonstrate your inconsistent judgements. However, this is just a particular, unusual situation to be in. And poor performance in a particular situation is not usually a reason to abandon a tool, since it might compensate by performing well in other situations. Something similar may apply here. 
%}
%{\color{red}
%This response is analogous to one offered against the Dutch book arguments: perhaps you just think it's unlikely that you'll ever face such a neferious bookie. A common response to this is to argue that the mere existence of such a Dutch Book exhibits an irrationality, although \citet{pettigrew2020dba} instead bolsters the argument by showing that quite generally non-probabilistic credence functions have alternatives which are guaranteed to act as a better guide to action than your current credences.
%
%We could similarly try to bolster our objection by showing a more general result. 
%}

%{\color{red}In response to this, we could try to bolster our objection by showing a more general result. }
We might here similarly try to bolster our objection by showing a more general result which would apply to a whole host of natural ways of being uncertain over which decision problem you'll face. 
Of course, we would have a stronger objection if we could show that for \emph{any} way of being uncertain over the decision problems you face, the theory is self-undermining. In fact, we'll never get something as general as that: after all, if your probability distribution places all of its probability on a single decision problem, then it will think of itself as permissible---and indeed, it will think of anything that disagrees with it as impermissible. But we might hope to be able to show that it is self-undermining for a much broader range of distributions over the possible decision theories than we currently have, thus arguing that, for any `plausible' way of being uncertain over possible decisions, the theory is still undermining. 

%If a defender of REU tries to apply this response, there's pressure on them to say why one should be uncertain over decision problems win a way that's compatible with being self-recommending. For example, if they could show that REU is self-recommending when you think that all possible decision problems are possible; if your measure of them requires almost everywhere decisiveness\todoold{what's the name we'll use later?}, then we think that this would be an acceptable response. 

We don't have any general results in this area, but we do have some suggestive particular cases for a particular Allais-permitting theory. This is John Quiggin's (\citeyear{quiggin1982tau,quiggin1993geut}) rank-dependent utility theory, which is formulated for exogenous, objective probabilities, and Lara Buchak's (\citeyear{buchak2014rr}) risk-weighted expected utility theory, which is a formally equivalent theory formulated for endogenous, subjective probabilities.

To give your \emph{risk-weighted expected utility} for an act $a$, defined over the states in $\Omega$, we need a probability function $p$ over $\Omega$, and a risk function $r : [0, 1] \rightarrow [0, 1]$, which takes a probability and skews it---we assume $r$ is continuous, strictly increasing, and $r(0)= 0$ and $r(1) = 1$. Now, suppose $a$ is an act, and let $\U(a)$ be the random variable that gives the utility of $a$ at a given state. 
If $\Omega$ is finite, the risk-weighted expected utility of $a$ can be written as follows:\footnote{This is not Buchak's favoured formulation; instead it's closer to the usual formulation of rank dependent expected utility theory; see, for example \citep[ch.6]{wakker2010prospect}.  See also sec.6.9 for the continuous case, although note that Buchak's theory does not make use of a distinction between gains and losses \citep[see][p59]{buchak2014rr}. }%\todoold{double check ref}
%Then, if $\Omega$ is finite, the expected utility of $a$ can be written as follows:
%$$
%\Exp_p[\U(a)] = \sum_{u \in \Set{\U(a)(\omega)\given \omega \in \Omega}} (p(\U(a) \geq u) - p(\U(a) > u))\times u
%$$
%Applying the risk function to the probabilities in this formulation gives us the risk-weighted expected utility of $a$:
$$
\RExp_{p, r}[\U(a)] = \sum_{x \in \Set{\U(a)(\omega)\given \omega \in \Omega}} (r(p(\U(a) \geq x)) - r(p(\U(a) > x)))\times x
$$
And, more generally, if the utilities are bounded below by $l$ and above by $h$,
%$$
%\Exp_p[\U(a)] = \int^h_{l} p(\U(a) > u)\, du
%$$
%and
$$
\RExp_p[\U(a)] = \int^h_{l} r(p(\U(a) > x))\, dx
$$
Then risk-weighted expected utility theory tells you to maximize risk-weighted expected utility.


%To give your \emph{risk-weighted expected utility} for an act $a$, defined over the states in $\Omega$, we need a probability function $p$ over $\Omega$, and a risk function $r : [0, 1] \rightarrow [0, 1]$, which takes a probability and skews it---we assume $R$ is continuous, strictly increasing, and $r(0)= 0$ and $r(1) = 1$. Now, suppose $a$ is an act, and let $\U(a)$ be the random variable that gives the utility of $a$ at a given state. Then, if $\Omega$ is finite, the expected utility of $a$ can be written as follows:
%$$
%\Exp_p[\U(a)] = \sum_{u \in \Set{\U(a)(\omega)\given \omega \in \Omega}} (p(\U(a) \geq u) - p(\U(a) > u))\times u
%$$
%Applying the risk function to the probabilities in this formulation gives us the risk-weighted expected utility of $a$:
%$$
%\RExp_{p, r}[\U(a)] = \sum_{u \in \Set{\U(a)(\omega)\given \omega \in \Omega}} (r(p(\U(a) \geq u)) - r(p(\U(a) > u)))\times u
%$$
%And, more generally, if the utilities are bounded below by $l$ and above by $h$,
%$$
%\Exp_p[\U(a)] = \int^h_{l} p(\U(a) > u)\, du
%$$
%and
%$$
%\RExp_p[\U(a)] = \int^h_{l} r(p(\U(a) > u))\, du
%$$
%Then risk-weighted expected utility theory tells you to maximize risk-weighted expected utility.

%\todooldinfo{Todo: does Lara give this definition for the infinite case? I learned it from Kenny E.}


Now, suppose:
\begin{enumerate}[label={\normalfont (i)}]
\item there are just two first-order possibilities $\omega_1$ and $\omega_2$,
\item your credence function is $p$, with $p(\omega_1) = 0.1, 0.2, \ldots, 0.8$, or $0.9$ and $p(\omega_2) = 1-p(\omega_1)$;
\item your risk function is a power function $r_k(x) = x^k$, with $k = 0.5$, $0.6$, $\ldots$, $0.8$, $0.9$, $1.1$, $1.2$, $\ldots$, $1.9$, or $2$;
\item you know you'll face a choice between just two acts, but you don't know which two acts, and you place a measure $\mu$ over the possible decision problems that takes the utilities of the two acts at the two possibilities to be independent of one another and all distributed according to a beta distribution $\mathrm{Beta}(\alpha, \beta)$ with $\alpha = 1, 2, 3, 4$, or $5$ and $\beta = 1, 2, 3, 4$, or $5$.\end{enumerate}
Then, let $\s$ be any picking strategy compatible with REU when coupled with $p$ and $r_k$. Then there is an alternative picking strategy $\s^*$ such that REU with credences given by $p$ and $\mu$ and risk function $r_k$ strictly prefers $\s^*$ to $\s$. What's more, $\s^*$ is not compatible with REU with $p$ and $r_k$. And indeed, it's possible to find $\s^*$ so that it is compatible with REU with $p$ and $r_{k^*}$ for some $k^* \neq k$. That is, $\s^*$ is a picking strategy compatible with REU coupled with a different risk-averse risk function. So, uncertain which decision they'll face, someone using REU with this risk function would prefer that, when the uncertainty is resolved and they face a particular decision, they use REU with a slightly different risk function.\footnote{See the Mathematica notebook here for the tools to carry out these calculations [link to notebook from journal page as supplementary material].}%\todooldinfo{link to mathematica}
%\todo{we'll need to remember to do that.}

%Second, suppose $0<k<1$. So your risk function $r_k(x) = x^k$ is risk-seeking. And now let $\s$ be any picking strategy compatible with REU with $p$ and $r_k$. Then there is an alternative picking strategy $\s^*$ such that REU with credences given by $p$ and $\mu$ and risk function $r_k$ strictly prefers $\s^*$ to $\s$. What's more, $\s^*$ is not compatible with REU with $p$ and $r_k$. And indeed, it's possible to find $\s^*$ so that it is compatible with REU with $p$ and $r_{k'}$, for some $k < k'$. That is, $\s^*$ is a picking strategy compatible with REU coupled with a less risk-seeking risk function. So, uncertain which decision they'll face, someone using REU and this risk function would prefer that, when the uncertainty is resolved and they face a particular decision, they use REU with a slightly less risk-inclined risk function.


%We have suggestive initial results for REU, but nothing more at this stage. Suppose there are just two states of the world. You have credence 0.3 in the first and 0.7 in the second. And your risk function is a power function $R(p) = p^k$ for some $k> 0$. Suppose your utilities are bounded and so the possible utility pay-offs of the different possible options lies in some range $[a, b]$. Suppose you know you'll face a binary decision---that is, a choice between just two alternatives. We might write such a decision problem as $(u_1, u_2; v_1, v_2)$, where $u_1$ is the utility of the first option at the first state of the world, and so on. And suppose we take the different values $u_1, u_2, v_1, v_2$ to be independent of one another and all distributed according to the same distribution. Then: if that distribution is the uniform distribution or any number of other beta distributions, then, for a range of $k > 1$, which make your risk function $R_k$ risk-averse, then there is another alternative, less risk-averse decision theory---in fact, REU with $R_{k'}$ for $k' < k$---that REU with $R_k$ would prefer to make the decision when it becomes clear which you'll face. And, for a range of $k < 1$, which make your risk function risk-seeking, then there is an alternative, less risk-seeking decision theory---in fact, REU with $R_k$ for $k < k'$---that REU with $R_k$ would prefer to make the decision. We list some of these results in the Appendix.




\section{Expected Utility Theory}\label{sect:eut}
In this section, we reassure ourselves that Savage-style expected utility theory is self-recommending; that is, if we assume act-state independence, expected utility theory endorses itself. We will need to be more detailed about the framework in order to present our result. 


 \emph{States } $\Omega$ is the set of possible states of the world. We'll assume there are only finitely many.

\emph{Uncertainty } The agent's uncertain beliefs about the world are represented by a single probability function $p$ over $\Omega$. 

\emph{Acts }
$\A$ is a non-empty set. It is the set of all possible acts. 



 \emph{Utilities } $\U$ is the agent's utility function. It takes each act $a$ in $\A$ and state $\omega$ in $\Omega$ and returns a utility value $\U(a)(\omega)\in\Re$. We will assume that utilities are bounded above and below. That is, there are $l,h\in\Re$ such that for all acts, $a\in\A$, $l\leq \U(a)(\omega)\leq h$.%
 \footnote{We will also assume that $\U(\A)$ is a Borel set in $\Re^\Omega\cong\Re^n$.}%\todo{I added our assumption... but then shouldn't we do so for s and nu etc???}
 %, and without loss of generality, for each act $a \in \A$ and state $\omega\in\Omega$, $0 \leq a(\omega) \leq 1$. We write $\A$ for the set of possible acts. \todoold{CCM: I still think we should have U and a separated. At least we *need* to do something like that to make sense of applying EU to strategies! since we need to specify the utility of a strategy..??}%An act is a function $a$ that specifies an outcome in each state $a(s)$. A utility function specifies the utility of that outcome $U(a(s))$.  %\todoold{should utilities be separated??}
%An act is a function $a$ that takes each state $s_i$ returns a utility $a(s_i)$, where $0 \leq a(s_i) \leq 1$. This needn't include all functions from $\S$ to $[0, 1]$, for we might take only certain acts to be possible.
%Note that we are essentially here holding the utility function fixed, for our purposes. 

\emph{Decision problems } A decision problem $D$ specifies a non-empty finite set of acts: the acts that are available in that decision problem. The set of all relevant decision problems is $\D$. %\todo{should we add ``re;evant''?}

(In fact, we could relax the assumption that $D$ specifies a finite set of acts and instead assume that the set of acts it specifies is compact relative to the utility function, that is, $\{\U(a)\given a \in D\}$ is a compact subset of $[l,h]^\Omega$. But we will continue to assume that decision problems are finite for ease of presentation.)

%That is, $\emptyset \neq D \subseteq \A$. %For example, you might be choosing whether to take an umbrella or not. 
%$\D$ is a set of decision problems. A decision problem $D$ is a set of acts. That is, $D \subseteq \A$. Again, this needn't include all subsets of $\A$, for we might take only certain decision problems to be possible.

%\emph{Choice function } A choice function, $\c$, specifies a non-empty subset of each decision problem, so that $\emptyset \neq \c(D) \subseteq D$, for each $D$ in $\D$. We might understand $\c(D)$ as the set of acts in $D$ that the choice function deems permissible or choiceworthy, or rather, those that it does not deem to be bad, or rejects. \todoold{should we add back in: ``Examples are $\EU_p$, $\REU_p^r$, $\EAd_\IP$ and $\Maximin_\IP$, as defined throughout the parper. ``}


{
\emph{Choice function } A choice function, $\c$, specifies a non-empty subset of each decision problem, so that $\emptyset \neq \c(D) \subseteq D$, for each $D$ in $\D$. If $a$ is \emph{not} in $\c(D)$ then $\c$ deems $a$ impermissible in $D$. Some authors go further and say that any $a$ in $\c(D)$ is rationally \emph{permissible} \citep[e.g.,][]{moss2015tse}. But others do not. They instead say that, if $a$ is in $\c(D)$, then $a$ is not deemed impermissible, but unless $a$ is the only act in $\c(D)$, it does not follow that $a$ is permissible or positively evaluated in any way \citep[e.g.,][]{debock2019iar}.}

%{ \emph{Choice function } A choice function, $\c$, specifies a non-empty subset of each decision problem, so that $\emptyset \neq \c(D) \subseteq D$, for each $D$ in $\D$. We will understand $\c(D)$ as the set of acts in $D$ that the choice function does not \emph{reject} or deem \emph{rationally impermissible to choose}. If $\c(D)$ contains only a single act, then that act is uniquely \emph{choiceworthy} or \emph{rationally permissible} in $\D$. But \emph{being rejected} is not the dual of \emph{being permissible}. Rather, we think of being rejected or impermissible in $D$ as a negative status. Similarly, we think of being choiceworthy or permissible in $D$ as a positive status. It is possible for an act to lack either status (not possible if the two notions are duals). More on this in sections 3 and 4.}






%So it is not the case that an option is rejected/impermissible just in case it is not positively permissible. This allows us to maintain rational permissibility---a positive status---agglomerates in the sense that if it is permissible to pick $a$ in $D_1$ and it is permissible to pick $b$ in $D_2$, then their conjunction is permissible, \emph{i.e.}, it is permissible to both pick $a$ in $D_1$ and $b$ in $D_2$




%But if $\c(D)$ contains many acts, that does \emph{not} imply that they are all equally choiceworthy, nor that they are all rationally permissible. Not rejected/impermissible in $D$ is a strictly weaker status than choiceworthy/permissible in $D$. Compare: in volleyball, it is not impermissible for any front row player on the serving team to stand with their hands up, even if they are bunched together. But it \emph{is} impermissible for \emph{all} front row players to stand with their hands up in that case---that is illegal screening. This would be a puzzle if not impermissible and permissible were equivalent. If it is positively permissible for \emph{any} front row player on the serving team to stand with their hands up, then it must be positively permissible for \emph{all} of them to do so.

%that were so, then it would be permissible for }




%this may either reflect the fact that all acts in $\D$ are equally choiceworthy and hence rationally permissible, or the fact that they are \emph{incomparable}. In the latter case, whether or not an act in $\c(D)$ is rationally permissible...}





\emph{Picking strategy } As above, a picking strategy, $\s$, specifies an act from each decision problem, so that $\s(D)\in D$, for each $D$ in $\D$. The set of all picking strategies is $\S$.\footnote{In fact, we restrict attention to the picking strategies that are measurable in the sense defined in \cref{sect:appendix:measure}.}

A picking strategy picks for a choice function $\c$ if it never picks an option that $\c$ deems impermissible. That is: 
\begin{definition}\label{def:picks for}
	A picking strategy $\s$ \emph{picks for a choice function} $\c$, if for all decision problems, $D$, $\s(D) \in \c(D)$.
\end{definition}
%Such a picking strategy will never select an option which $\c$ deems impermissible. 

%\item\emph{Choice function} A choice function 
%\end{itemize}

Given a probability function $p$ defined over $\Omega$, the expected utility of an action $a$, by the lights of $p$, is given by \begin{equation}
	\Exp_p [\U(a)]:=\sum_{\omega\in\Omega}p(\omega)\U(a)(\omega)
\end{equation}
If one has (probabilistic) credences given by $p$, expected utility theory says that one should choose an act in $D$ that maximises $\Exp_p[\U(a)]$.\footnote{The version we present here is of the sort described by \citet{savage1954fs}, in which it is assumed that the acts are independent of the states of the world. This assumption is dropped in the evidential decision theory of \citet{jeffrey1965lod} and the causal decision theory of \citet{stalnaker1972ldl, gibbard1978ctk, joyce1999fcdt}.} That is, we define the choice function to which expected utility theory gives rise when coupled with probability function $p$ as follows:

\begin{definition}[Expected Utility Theory ($\EU_p$)]\label{def:EU}
	\[\EU_p(D):=\left \{a\in D\given \text{ for all $a'\in D$, }\Exp_p[\U(a)]\geq \Exp_p[\U(a')]\right \}\]
\end{definition}
%\todooldinfo{In nu stuff I am using ``picks for'' terminology. Should that be used throughout??}
%\todooldinfo{should we introduce ``choice funciton'' here??}
%$\EU_p$ is an example of a so-called choice function. 
%\begin{itemize}
%	\item A \emph{Choice function}, $C$, specifies for each decision which acts are choiceworthy, or perhaps not rejected, that is $C:\D\to\A$ such that $C(D)\subseteq D$ and $C(D)\neq\emptyset$.
%	\item A strategy $\s$ is a $C$ strategy iff $\s(D)\in C(D)$ for each $D$. 
%\end{itemize}

%That is, $\s$ is an $\EU_p$ picking strategy iff $\s(D)$ is an action in $D$ which maximises $\Exp_p(a)$. In fact, there can be multiple $\EU_p$ strategies when there are different options which both maximise expected utility.\todoold{does this need more discussion?}

So a picking strategy $\s$ picks for $\EU_p$ iff $\s(D)$ maximizes expected utility by the lights of $p$.
Since we have assumed that each $D$ is finite, or compact, $\Exp_p[\U(a)]$ obtains its maximum in $D$; so $\EU_p(D)\neq\emptyset$. 

Now we want to judge the expected utility of a picking strategy itself---we want to ask whether the picking strategies that always pick an act that maximizes expected utility from any decision problem themselves maximize expected utility when you're uncertain which decision problem you'll face. This requires us to fix not only $p$, which gives your credences over $\Omega$, but also your credences over the decision problems you might face, given by some probability measure $\mu$ over $\D$. We will assume these are independent. %So we can separate your credence that you'll be faced with decision $D$ and that the world is thus-or-so, $\omega$, into a probability measure $\mu$ over $\D$ and a probability measure $p$ over $\Omega$. 
{So your credences over the joint space, $\Omega\times\D$, are given by the product measure $p\times\mu$. That is, your credence you are in world $\omega$ and will face a decision problem in the (measurable) set of decision problems $E$ is given by $(p\times\mu)(\omega,E)=p(\omega)\times\mu(E)$.} 
We will moreover always assume that $\mu$ is countably additive. 


We can now simply apply our notion of expected utility with the credences over $\Omega\times\D$ given by %$p\times \mu$. 
{$p\times\mu$.} We judge a picking strategy by the utility of the acts it picks, and so we define $\U(\s)(\omega,D):=\U(\s(D))(\omega)$. We can then apply our definition of expected utility and get that any picking strategy that picks for $\EU_p$ maximizes expected utility by the lights of %$p\times \mu$. 
{ $p\times\mu$.}
\begin{proposition}\label{thm:eu-self-rec}
	For any $p$, $\mu$, if $\s$ picks for $\EU_p$, then, for any picking strategy $\s'$ in $\S$,
	$$\Exp_{p\times\mu}[\U(\s)]\geq\Exp_{p\times\mu}[\U(\s')].$$
	That is, if $\s$ picks for $\EU_p$, then $\s\in\EU_{p\times\mu}(\Strategies)$. 
	\end{proposition}
(Recall: 
%$\s\in\EU_{p\times \mu}$ is the choice function to which $\EU$ gives rise when coupled with \todo{I don't think we've defined $\EU$ by itself... what's going on here!}%$p\times \mu$. 
%{ $p\times\mu$}, and 
$\Strategies$ is the set of picking strategies. $\EU_{p\times \mu}(\Strategies)$ is the set of those picking strategies that maximize expected utility by the lights of %$p\times \mu$. 
{$p\times\mu$}, as in \cref{def:EU}.) This is proved in \Cref{sect:EU-appendix}.


This shows that expected utility theory is not self-undermining in the way the Allais-permitting decision theories considered in the previous section are self-undermining. Expected utility picking strategies are themselves maximisers of expected utility. 

What's more, they are the only picking strategies which maximise expected utility. Or at least, the picking strategies which maximise expected utility are those that look like an $\EU_p$ strategy from $\mu$'s perspective. %For example, if $\mu$ is certain you won't be faced with the decision problem $D$, then it doesn't matter whether the strategy chooses in an expected utility way for $D$. 

\begin{definition}\label{def:mu surely picks for}
If $\c$ is a choice function and $\s$ is a picking strategy, then $\s$ \emph{$\mu$-surely picks for $\c$} iff $\mu\{D \in \D \given \s(D)\in \c(D)\}=1$
\end{definition}
%That is, $\mu$ is certain that, for each decision problem $D$, $\s$ picks an act from $D$ that lies in $\c(D)$.
{That is, $\s$ $\mu$-surely picks for $\c$ just in case $\mu$ is certain you'll face a decision problem where what $\s$ picks is compatible with $\c$, \emph{i.e.}, $\s(D)\in\c(D)$. That is, $\mu$ is sure that $\s$ does not pick an option that $\c$ rejects. }
%{ That is, $\s$ $\mu$-surely picks for $\c$ just in case you are certain (probability 1 according to $\mu$) that you will face a decision problem $D$ where $s$ picks an option from the choice set $\c(D)$ (\emph{i.e.} a non-rejected option).}

\begin{proposition}\label{thm:eu-uniquely-optimal}
	For any $p$ and $\mu$, if $\s$ $\mu$-surely picks for $\EU_p$, while $\s'$ does not, then $$\Exp_{p\times\mu}[\U(\s)] > \Exp_{p\times\mu}[\U(\s')].$$
	
	So, if $\s$ does not $\mu$-surely pick for $\EU_p$, then $\s\notin\EU_{p\times\mu}(\Strategies)$. 
\end{proposition}

This is proved in \Cref{sect:EU-appendix}. We thus have that $\s \in \EU_{p\times \mu}(\Strategies)$ iff $\s$ $\mu$-surely picks for $\EU_p$. 

It is worth noting that the reasoning that delivers these results only holds when we have assumed that the state of the world is independent of the act chosen, i.e., where we are using Savage's (\citeyear{savage1954fs}) version of expected utility theory, in which the states of the world are independent of the acts chosen. %It is a further question whether the causal or evidential versions of expected utility theory are self-undermining in the current sense. We leave that for future work.%\footnote{In his discussion of evidential and causal decision theory, from which we borrow his use of the terminology `self-recommending', Brian \citet{skyrms1982cdt} gives a similar sort of argument against both of those rival theories. He imagines that you know the sequence of decisions that you will face, and you ask your decision theory whether it would recommend committing to using itself as the theory with which you face those decisions. And he notes that there are sequences for which causal decision theory would not recommend itself, and there are sequences for which evidential decision theory would not recommend itself. This is analogous to the money-pump arguments we mentioned earlier, since it shows that there is some sequence of choices such that causal decision theory does not permit you to use causal decision theory to make them, and there is some sequence of choices such that evidential decision theory does not permit you to use evidential decision theory to make them. But it is still an open question whether, when there is uncertainty about the decision you'll make, one of these theories would not permit you to use itself when making whatever decision you face.}

% \todooldinfo{Not clear whether we need this big footnote.}

%As well as assuming act-state independence, we've also assumed decision-state independence: that is, we've assumed that, from the point of view of your credences over $\Omega \times \D$, the decision you face and the state of the world are independent of one another. We've done this because this is the assumption we made in the case of the Allais- or risk-permitting theories above and we'll make again for the Ellsberg- or ambiguity-permitting theories below. But, in fact, analogues of \Cref{thm:eu-self-rec,thm:eu-uniquely-optimal} hold even if we don't assume this. If we assume that, when the uncertainty about the decision you face is resolved, and you face that decision, you face it using expected utility theory with the credences you obtain from your credences over $\Omega \times \D$ by updating on the decision problem you face, then the picking strategy that results maximizes expected utility from the point of view of your credences over $\Omega \times \D$.


\subsection{Decision-State Dependence}\label{sect:decdep}

As well as assuming act-state independence, we've also assumed decision-state independence: that is, we've assumed that, from the point of view of your credences over $\Omega \times \D$, the decision you face and the state of the world are independent of one another, given by $b=p\times\mu$. But, in fact, analogues of \Cref{thm:eu-self-rec,thm:eu-uniquely-optimal} hold even if we don't assume this. 

In any decision problem, we must bring one's probability $b$ up to speed on the problem that you face (by conditionalizing on that information), and then use expected utility theory with this updated credence function to determine what to select.\footnote{The details of this are developed in \cref{sect:appendix:decdep}.}
%The strategies which are in $\EU_b(\S)$ are those that select according to expected utility theory, using the probability function over $\Omega$ which is generated by conditionalising on knowing which decision problem it is that you're facing, assuming that this is well-defined. 
%If we assume that, when the uncertainty about the decision you face is resolved, and you face a particular decision problem, you will use expected utility theory with the credences you obtain by updating on the decision problem you face, then the picking strategy that results maximizes expected utility from the point of view of your credences over $\Omega \times \D$.


\begin{definition}\label{def:cond}
	If $b$ is a probability over $\Omega\times \D$, we specify a choice function 
	$\EU_{b(\cdot|-)}$ given by $\EU_{b(\cdot|-)}(D)=\EU_{b(\cdot|D)}(D)$, when this is well-defined. That is, $$\EU_{b(\cdot|-)}(D):=\left \{a\in D\given \text{for all $a'\in D$, }\Exp_{b(\cdot|D)}[\U(a)]\geq \Exp_{b(\cdot|D)}[\U(a')]\right \}.$$%\todo{Should this ``that is'' go into footnote or be deleted?}
%	 that is, $a\in\EU_{b(\cdot|-)}(D)$ iff $\Exp_{b(\cdot|D)}[\U(a)]

$b_\Decs$ is the marginal probability measure on $\Decs$ generated by $b$, that is $b_\D(E)=b(\Omega\times E)$ for measurable $E\subseteq\Decs$.%\todo{measurable?}

We say that %$\s$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$ iff $b\{\seq{\omega,D}\given\omega\in\Omega,\, \s(D)\in\EU_{B(\cdot|D)}(D)\}=1$; that is the marginal $b_\D\{D\given \s(D)\in\EU_{B(\cdot|D)}(D) \}=1$. 
a picking strategy, $\s$, \emph{$b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$} iff \[b_\Decs\{D\given \s(D)\in EU_{b(\cdot|-)}(D)\}=1\]
\end{definition}
We assume throughout that $b$ is countably additive. When $b$ has the form $p\times\mu$, then $b_\Decs$ is just $\mu$ and, for every $D$, $b(\cdot|D)$ is just $p$. These are thus generalisations of our original notions of the choice function $\EU_p$ and a strategy $\s$ $\mu$-surely picking for $\EU_p$. 

We can then show the more general version of \cref{thm:eu-self-rec,thm:eu-uniquely-optimal}:
\begin{proposition}\label{thm:eu-dep}
	$\s\in\EU_b(\Strategies)$ iff $\s$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$.
\end{proposition}
This is proved in \Cref{sect:EU-appendix}.


%It is also important that we assumed that you think that the decision you'll face is independent of the state of the world. It's clear that these results will fail without this assumption. Suppose you might face the decision whether or not to take a bet on whether it is raining or not; if you do, you maximize expected utility by taking the bet; but suppose I arrange things so that you face that decision only if it isn't raining. Then of course the best picking strategy will tell you to not to take the bet. More generally, if you might face a decision problem, and your decision theory recommends an act that does not dominate another available one, i.e., when there is some state in which the other one is better, then if you're only going to face that decision problem in that possibility, then, while uncertain which decision problem you'll face, your decision theory will prefer a picking strategy that picks the other act. 
%If you're only going to face $D_1$ in world $\omega_1$ and $D_2$ in $\omega_2$, 
% \todooldinfo{check and improve the wording there}






\section{Decision theories for imprecise credences}

There is another range of decision theories that diverge from expected utility theories: those theories that accommodate ambiguity and imprecision. In the decision theories considered so far, we represent an individual as assigning precise credences to the various states of the world. But some think we do better to model individuals as having imprecise credences instead \citep{walley1991srip, bradley2016ip}. There are many ways to do this, but one of the most well-known represents an individual's doxastic state not by a single credence function, which assigns to each state of the world a single numerical measure of their confidence in that state, but by a set of such functions. We call this set your \emph{credal set}. It is a set $\IP$ of probability measures over the states of the world, $\Omega$.\footnote{{It is standard in the imprecise probability literature to reserve the term ``credal set'' for convex sets of probability measures. We do not assume convexity here.}}


Many decision theories have been proposed for an agent whose uncertain beliefs are represented in this way. We discuss three prominent ones: $\Gamma$-Maximin, E-Admissibility and Maximality. %\todoold{that ok?}
%E-Admissibility says that an act is permissible if it maximizes expected utility by the lights of at least one member of your credal set. \todoold{reference?} $\Gamma$-Maximin is more restrictive than E-Admissibility: it tells you how to choose amongst the options that E-Admissibility deems permissible. Maximality is more permissive than E-Admissibility: it will only rule out an action if there's an alternative which is better according to every member of your credal set. 



\subsection{$\Gamma$-maximin}\label{sect:gamma}
%Some decision theories go beyond E-Admissibility and permit only some subset of the E-Admissible acts. Any such theory will be susceptible to the same self-undermining concerns that we saw affecting E-admissibility above: there will be strategies that pick for the choice function given by that theory that the theory itself deems impermissible. The situation may in fact be worse for such theories because for E-Admissibility there are guaranteed to be some strategies that pick for E-Admissibility that E-Admissibility also permits: strategies that successfully coordinate across decisions. But for more restrictive theories these coordinated strategies may be ruled out by the theory, and we might have the result that all the strategies that pick for the theory's choice function are deemed impermissible by the theory. 

%A prominent example of a theory that is more restrictive than E-Admissibility is $\Gamma$-Maximin. 

To illustrate $\Gamma$-Maximin, consider an example that is often used to motivate it, namely, the Ellsberg paradox \citep{ellsberg1961rasa}:

\label{sect:Ellsberg}
\begin{quote}
 An urn contains 90 balls. You know that 30 of them are red, and the remaining 60 are black and yellow, but you don’t know how many are black and how many are yellow. I am about to draw a ball from the urn.
\end{quote}
If the states of the world are \emph{Red} (I draw a red ball), \emph{Black} (I draw black), and \emph{Yellow} (I draw yellow), you might naturally take your credal set to be $$\IP = \Set{p \given p(\emph{Red}) = \sfrac{1}{3}\ \&\ p(\emph{Black})+p(\emph{Yellow}) = \sfrac{2}{3}}.$$
Now consider the following two possible decision problems, $D^{\mathrm{Ellsberg}}_1$ and $D^{\mathrm{Ellsberg}}_2$:
$$
\begin{array}{r|ccc}
D^{\mathrm{Ellsberg}}_1 & \emph{Red} & \emph{Black} &\emph{Yellow} \Bstrut \\\hline \Tstrut\IP & \sfrac{1}{3} & x&\sfrac{2}{3}-x %\multicolumn{2}{c}{\sfrac{2}{3}}
\Bstrut \\\hline \hline\Tstrut 
\text{1E} & \text{\pounds 10} & \text{\pounds 0}  & \text{\pounds 0} \\
\text{1F} & \text{\pounds 1} & \text{\pounds 11}  & \text{\pounds 1} 
\end{array}
\hspace{10mm}
\begin{array}{r|ccc}
D^{\mathrm{Ellsberg}}_2 & \emph{Red} & \emph{Black} &\emph{Yellow} \Bstrut \\\hline \Tstrut\IP & \sfrac{1}{3} &x&\sfrac{2}{3}-x % \multicolumn{2}{c}{\sfrac{2}{3}}
\Bstrut \\\hline \hline\Tstrut 
\text{2E} & \text{\pounds 11} & \text{\pounds 1}  & \text{\pounds 11} \\
\text{2F} & \text{\pounds 0} & \text{\pounds 10}  & \text{\pounds 10} 
\end{array}
$$
Faced with these decisions, people often report the Ellsberg preferences: they will choose 1E from $D^{\mathrm{Ellsberg}}_1$, and 2F from $D^{\mathrm{Ellsberg}}_2$.\footnote{In fact, we have added a small constant to the usual versions of 1F and 2E, reflecting the fact that people strictly prefer the usual version of 1E over the usual version of 1F, and so are willing to pay a penalty for making that choice; we've taken that penalty to be \pounds 1, but our point remains however small you make it.} And indeed that is exactly what $\Gamma$-Maximin demands. It says that, faced with a particular decision problem, you should pick one of the acts whose minimum expected utility by the lights of the probability functions in $\IP$ is maximal: in $D^{\mathrm{Ellsberg}}_1$, 1E uniquely maximizes minimum expected utility; and in $D^{\mathrm{Ellsberg}}_2$, 2F does that.

\begin{definition}[$\Gamma$-Maximin$_\IP$ ($\Maximin_\IP$) ]
$$
\Maximin_\IP(D) = \left \{ a \in D \mid (\forall a' \in D)\left [\min_{p \in \IP} \Exp_p[\U(a')] \leq \min_{p \in \IP} \Exp_p[\U(a)] \right ] \right \}
$$
(This should only be applied when these minima exist, e.g., when $\IP$ is a closed set.)
\end{definition}

So $\s$ picks for $\Maximin_\IP$ iff for every $D\in\D$, $\s(D)\in\Maximin_\IP(D)$. In this case, the only picking strategy that picks for $\Maximin_\IP$ picks 1E from $D^{\mathrm{Ellsberg}}_1$ and 2F from $D^{\mathrm{Ellsberg}}_2$. We call this strategy $\s_{\mathrm{Ellsberg}}$; the strategy corresponding to the Ellsberg preferences. Such a strategy is incompatible with expected utility theory: it does not pick for $\EU_p$ for any probability $p$.\footnote{\label{ftnte:Ellsberg not EU}This is because, to have $\Exp_p[\U(\text{1E)}]\geq \Exp_p[\U(\text{1F)}]$, it must be that $x\leq \sfrac{7}{30}$; and, to have  $\Exp_p[\U(\text{2F)}]\geq \Exp_p[\U(\text{2E)}]$, it must be that $x\geq \sfrac{13}{30}$; and these are jointly incompatible. } Indeed, this fact accounts for Ellsberg's use of the case: like Allais, he wished to provide an example of intuitively rational preferences that could not be captured by expected utility theory. 

Now we will use the theory itself to judge picking strategies. To do this, we need to describe the agent's uncertainty not only over what the world is like, but also over which decision problem she'll face. 
Suppose you have precise probabilities over what decision you'll face, and you think it's $50\%$ likely you'll face $D^{\mathrm{Ellsberg}}_1$ and $50\%$ likely you'll face $D^{\mathrm{Ellsberg}}_2$. 
So, we represent your uncertainty as a set, $\IB$, of (higher-order) probabilities over both $\Omega$ and $\D$, each of which makes the state of the world independent of the decision you'll face. 
%So we are considering $\IB=\{p\times \mu^*\given p\in\IP\}$, 
{That is, your credal set is $\IB=\{p\times\mu^* \given p\in\IP\}$, where $\mu^*$ is this probability over $\D$, and $\IP$ is the credal set as described in the Ellsberg case.}

Observe, then, that (i) $\Exp_{\mu^*}[\U(\s_{\text{1E,2F}})(\omega)]=5$ for each $\omega$ in $\Set{\emph{Red}, \emph{Black}, \emph{Yellow}}$, but (ii) $\Exp_{\mu^*}[\U(\s_{\text{1F,2E}})(\omega)]=6$ for each $\omega$ in $\Set{\emph{Red}, \emph{Black}, \emph{Yellow}}$. So, for any $p$ with $p\times \mu^*\in \IB$,  $\EU_{p\times\mu^*}\U(\s_{\text{1E,2F}})=5$ and  $\EU_{p\times\mu^*}\U(\s_{\text{1F,2E}})=6$. And so $\s_{\mathrm{Ellsberg}}=\s_{\text{1E,2F}}\notin\Maximin_{\IB}(\S)$. 


	This example is closely related to another phenomenon: Dutch book type challenges or paradoxes of sequential choice, which can be constructed against agents on the basis of such examples \citep{seidenfeld2004contrast,elga2010sp}. \todo{Shouldn't it be a ref to Seidenfel;s other one??}
	For instance, we might consider how the agent will choose in $D^{\mathrm{Ellsberg}}_1$ and $D^{\mathrm{Ellsberg}}_2$, individually, and then combine these choices and observe that the result is dominated---1F-and-2E dominates 1E-and-2F. One response is simply to reject the package principle. However, there is another version of the examples in which they are presented diachronically: first evaluate $D^{\mathrm{Ellsberg}}_1$, then $D^{\mathrm{Ellsberg}}_2$. And again we can note that 1F-then-2E dominates 1E-then-2F. And we can note that $\Gamma$-Maximin would still have you choose 2E when faced with $D^{\mathrm{Ellsberg}}_2$, even if you know you've already chosen 1F when faced with $D^{\mathrm{Ellsberg}}_1$. But some will deny that sure loss as a result of decisions at different times indicates irrationality.
		What this example highlights is the close connection between the analysis of this paper and existing challenges and discussions for these theories. Any such Dutch book or sequential choice challenge can be seen as a particular instance where one is unsure which decision problem you'll face, taking them each as equally likely, and evaluating strategies. However, it is a slightly different philosophical question.%\todo{...}

%However, such examples can always be used to construct instances of undermining evaluations of strategies. Suppose $D^{\mathrm{Ellsberg}}_1, \ldots, D_k$ is a sequence of decision problems and your decision theory demands you pick $a_i$ from $D_i$; but suppose further than, if you were to pick $b_i$ from $D_i$ you'd be better off for sure: that is, the total utility of $a_1$-and-\ldots-and-$a_k$ is less than the total utility of $b_1$-and-\ldots-and-$b_k$  at every state of the world. Then, if you are equally confident you'll face each of $D^{\mathrm{Ellsberg}}_1, \ldots, D_n$, then, at each world, the expected utility of a strategy that picks $a_i$ when faced with $D_i$ is less than the expected utility of a strategy that picks $b_i$ when faced with $D_i$. 


%
%Now we will use the theory itself to judge picking strategies. To do this, we need to describe the agents uncertainty not only over what the world is like, but also which decision problem she'll be faced with. 
%We will still assume that you take which decision problem you're faced with to be independent of the state of the world, so we will represent your uncertainty with a set, $\IB$, of pairs of probabilities $p\times \mu$ where $p$ is a probability function over $\Omega$ and $\mu$ is a probability function over $\D$.
%Then we can ask, from the point of view of $\IB$, and using $\Gamma$-Maximin as our decision theory, whether the Ellsberg picking strategy $\s_{\mathrm{Ellsberg}}$ is permissible. That is, is $\s_{\mathrm{Ellsberg}}$ in $\Maximin_B(\S)$, where $\Maximin_B$ is the choice function to which $\Gamma$-Maximin gives rise when it is coupled with the credal set $\IB$ over $\Omega \times \D$, and $\Strategies$ is the set of possible picking strategies? 
%
%Suppose $\IB$ is such that for any $p\times \mu\in \IB$, $p\in\IP$, i.e., $p(\emph{Red}) = \sfrac{1}{3}\ \&\ p(\emph{Black})+p(\emph{Yellow}) = \sfrac{2}{3}$; 
%and $\mu$ assigns positive credence to facing both $D^{\mathrm{Ellsberg}}_1$ and $D^{\mathrm{Ellsberg}}_2$. 
%Then the answer is no, $\s_{\mathrm{Ellsberg}}\notin\Maximin_B(\S)$. 
%To see this, we use the fact that $\Gamma$-Maximin is a more restrictive decision theory than E-Admissibility, so that any $\Gamma$-Maximin strategy must be optimal according to some probability in $\IB$ \todoold{add ref!!}. That is, there must be some $p\times \mu\in \IB$ for which $\s$ maximises $\EU_{p\times\mu}[\U(\s)]$; but as we saw from \cref{thm:eu-uniquely-optimal}, the only such strategies are those which $\mu$-surely pick for $\EU_p$ for some $p\times \mu\in \IB$. But, so long as $\mu$ gave non-zero credence to each of $D^{\mathrm{Ellsberg}}_1$ and $D^{\mathrm{Ellsberg}}_2$, then $\s_{\mathrm{Ellsberg}}$ also does not $\mu$-surely pick for any $\EU_p$ with $p\in\IP$. \todoold{check this, and maybe prove it}
%
%So, at least in the Ellsberg case, where we are uncertain whether we'll face $D^{\mathrm{Ellsberg}}_1$ or $D^{\mathrm{Ellsberg}}_2$, $\Gamma$-Maximin is self-undermining. The only picking strategy that picks for that decision theory with $\IP$---namely, $\s_{\mathrm{Ellsberg}}$---is not permitted by that decision theory with $\IB$.


{
%\subsubsection{Uncertainty about decisions}
\label{sect:gamma:other mu}

Moreover, there is a further question of particular interest in our analysis which goes beyond showing the existence of cases of uncertainty for which the decision theory is undermining, as the Ellsberg case does, or using any instance of the sequential choice or Dutch Book challenges. As discussed in \cref{sect:reu:other mu}, we want a general result that says, for a wide class of ways of being uncertain about what decision you'll face, $\Gamma$-Maximin is undermining. We provide such a result in \cref{sect:nu:Max}.
% The example we have illustrated with the Ellsberg case, or more generally pointed to using any existing Dutch book or sequential choice challenge, merely gives some way of being uncertain over which decision problem you'll be faced with where $\Gamma$-Maximin undermines its own recommendations. 
%So far, we have only shown that in this particular way of being uncertain about what decisions you'll face, $\Gamma$-Maximin is self-undermining, declaring the only strategy that picks for it impermissible. As in our discussion in \cref{sect:reu:other mu}, we would like to be able to improve on the results by giving a more general result, which says that, for a wide class of ways of being uncertain, $\Gamma$-Maximin is similarly undermining. 

%We are able to provide suchgeneral result for a wide class of ways of being uncertain over which decision problem you'll be faced with, although not for all. We will discuss the details of this in . 

%\todooldinfo{check the link to the general stuff!!}

%Of course, if one's credal set is precise, then $\Gamma$-Maximin is just $\EU_p$, and we get self-recommendation. So the result will only hold when the credal set is imprecise. One also needs to have uncertainty about which decision problem you'll be faced with otherwise there's no
}
%\todooldinfo{work needs doing!}

%We can then calculate which acts maximize expected utility by the lights of a probability function in $\IP$ (\cref{tab:Ellsberg EU recommendations}).

%\begin{table}[ht]
%	\[
%	\begin{array}{lcc}
%		\toprule
%		\text{Constraint on } p(\emph{Yellow}) & \EU_p(D^{\mathrm{Ellsberg}}_1) & \EU_p(D^{\mathrm{Ellsberg}}_2) \\
%		\midrule
%		p(\emph{Yellow}) < \tfrac{7}{30} & \{1B'\} & \{2B\} \\[1mm]
%		p(\emph{Yellow}) = \tfrac{7}{30} & \{1B'\} & \{2A,\,2B\} \\[1mm]
%		\tfrac{7}{30} < p(\emph{Yellow}) < \tfrac{13}{30} & \{1B'\} & \{2A\} \\[1mm]
%		p(\emph{Yellow}) = \tfrac{13}{30} & \{1A,\,1B'\} & \{2A'\} \\[1mm]
%		p(\emph{Yellow}) > \tfrac{13}{30} & \{1A\} & \{2A'\} \\
%		\bottomrule
%	\end{array}
%	\]
%\caption{EU\(_p\) recommendations for decisions \(D^{\mathrm{Ellsberg}}_1\) and \(D^{\mathrm{Ellsberg}}_2\).\label{tab:Ellsberg EU recommendations}}

%\end{table}

%So, faced with $D^{\mathrm{Ellsberg}}_1$, either 1A or 1B is E-Admissible; and faced with $D^{\mathrm{Ellsberg}}_2$, either 2A or 2B is E-Admissible. And so any picking strategy picks for E-Admissibility in this case. However, the strategy that picks $1A$ from $D^{\mathrm{Ellsberg}}_1$ and $2B$ from $D^{\mathrm{Ellsberg}}_2$ picks for E-Admissibility, but it does not maximize expected utility by the lights of any $\langle p, \mu \rangle$ in $\IB$. That is, it is not in $\EAd_\IB(\S)$. 

%There are, however, strategies that pick for E-Admissibility and that E-Admissibility deems permissible: that is, $\s$ %picks for $\EAd_\IP$, and $\s$ is in $\EAd_\IB(\S)$. For example, the strategy that picks $1A$ from $D^{\mathrm{Ellsberg}}_1$ and $2A$ from $D^{\mathrm{Ellsberg}}_2$. 

%So E-admissibility deems some of its strategies permissible and others not. In fact, for every E-Admissible act in a fixed decision $D$, there is an E-Admissibility strategy which is E-Admissible and which selects that option in $D$. What might be ruled out, however, is certain combinations. For the strategy to be E-Admissible, it requires coordination across the various decision problems. 






%\begin{definition}[$\Gamma$-Maximin$_\IP$ ($\Maximin_\IP$) ] 
%$$
%\Maximin_\IP(D) = \left \{ a \in D \mid (\forall a' \in D)\left [\min_{p \in \IP} \Exp_p[\U(a)'] \leq \min_{p \in \IP} \Exp_p[\U(a)] \right ] \right \}
%$$
%(This should only be applied when these minima exist, e.g., when $\IP$ is a closed convex set.)\todoold{closed? closed and convex?}
%\end{definition}
%In the Ellsberg case as described above, this requires one to select $1A$ in $D^{\mathrm{Ellsberg}}_1$ and $2B$ in $D^{\mathrm{Ellsberg}}_2$; that is the only strategy recommended by $\Maximin_\IP$ is one that is not E-Admissible. It is thus also not itself acceptable according to Maximin. That is, there is a unique $\Maximin_\IP$ strategy $\s$, and this is not in $\Maximin_{\IB}(\S)$. Maximin undermines its own recommendations, evaluating its unique picking strategy to be impermissible. 

%\todooldinfo{Do we have a general result saying that for any $\mu$, Gamma-Maximin undermines all the compatible strategies?? RP: my sense is we can't get this, because there will be some string of decision problems whose $\min_{p \in P}$ is given by a single p in P.}

\subsection{E-Admissibility and Maximality}\label{sect:e-admiss}\label{sect:Max}

%Two alternative decision theories are E-Admissibility and Maximality. When coupled with a credal set $\IP$, E-Admissibility rejects an act $a$ from a decision problem $D$ when, for any $p$ in $\IP$, there is some $a'$ in $D$ that $p$ expects to do better than $a$, while Maximality rejects an act $a$ from $D$ when there is some $a'$ in $D$ that every $p$ in $\IP$ expects to do better than $a$. %that the E-Admissible acts, that is, those that are evaluated as optimal according to at least one probability function in the credal set, $\IP$. Maximality with $\IP$ permits That is:	%\todoold{move between options and actions??? }

{ Two alternative decision theories are E-Admissibility and Maximality. When coupled with a credal set $\IP$, E-Admissibility rejects an act $a$ from a decision problem $D$ when, for any $p$ in $\IP$, there is some $a'$ in $D$ that $p$ expects to do better than $a$. In that case, each $p$ in $\IP$ considers \emph{some} other option to be better than $a$, even though there may be no \emph{single} option they all agree to be better. In constrast, Maximality rejects an act $a$ from $D$ when there is some $a'$ in $D$ that every $p$ in $\IP$ considers better than $a$, \emph{i.e.}, when all $p$ in $\IP$ agree on a \emph{single} option that they expect to be better than $a$. If an act is rejected according to Maximality, then it is also rejected according to E-Admissibility, but not vice versa.}

\begin{definition}\label{def:ead}
 $$\EAd_\IP(D) = \Set{a \in D \given (\exists p \in \IP)(\forall a' \in D)(\Exp_p[\U(a)]\geq\Exp_p[\U(a')])}$$
 
 	 $\s$ picks for $\EAd_\IP$ iff for every $D\in\D$, $\s(D)\in\EAd_\IP(D)$. 	
 \end{definition}

	 Note that	$a\in\EAd_\IP(D)$ iff there is some $p\in\IP$ such that $a\in\EU_p(D)$.  
Thus, any picking strategy $\s$ that picks for $\EU_p$, for some $p\in\IP$, also picks for $\EAd_\IP$.
	
	\begin{definition}
	$$\Maximality_\IP(D) = \Set{a \in D \given (\forall a'\in D)(\exists p\in\IP)(\Exp_p[\U(a)] \geq\Exp_p[\U(a')])}$$
	
		 $\s$ picks for $\Maximality_\IP$ iff for every $D\in\D$, $\s(D)\in\Maximality_\IP(D)$.
\end{definition}




We  treat E-Admissibility first. 
%\begin{colored}{violet}
	
\subsubsection{E-Admissibility}

 
We want to consider how E-Admissibility judges picking strategies.  
This depends on your uncertainty over which decision problem you'll face as well as your uncertainty about the state of the world. 
We represent your uncertainty over $\Omega \times \D$ with a credal set, $\IB$, given by a set of probability functions, $b$, over $\Omega\times \D$. 

We can simply apply our notion of E-Admissibility with the credal set $\IB$ to determine which picking strategies are E-Admissible. 
%	$\s\in\EAd_\IB(\S)$ iff there is some $b\in\IB$ such that for all $\s'\in\S$, $\Exp_b(\s)\geq\Exp_b(\s')$.
 $$\EAd_\IB(\S)=\Set{\s\in\S\given  (\exists b \in \IB)(\forall \s' \in \S)(\Exp_b[\U(\s)]\geq\Exp_b[\U(\s')])}$$
That is, $\s\in\EAd_\IB(\S)$ iff there is some $b\in\IB$ such that $\s\in\EU_b(\S)$. 
%\todo{we could explciitly have a lemma to say how EAd relates to EU both for acts and strategies. Makes the thm trivial then... As in appendix, but of course simpler}
%	We thus have
%\begin{lemma}
%	$a\in\EAd_\IP(D)$ iff there is some $p\in\IP$ such that $a\in\EU_p(D)$.  
%	Thus, any $\s$ which picks for $\EU_p$ for some $p\in\IP$ also picks for $\EAd_\IP$.
%	
%	$\s\in\EAd_\IB(\S)$ iff there is some $b\in\IB$ such that $\s\in\EU_b(\S)$. 
%\end{lemma}


By \cref{thm:eu-self-rec}, for any $b\in\IB$ that has the form $p\times\mu$, if $\s$ picks for $\EU_p$ then it is in $\EU_{b}(\S)$, and thus, is in $\EAd_\IB(\S)$. Also, when $p\in\IP$, any $\s$ that picks for $\EU_p$ also picks for $\EAd_\IP$. We thus typically have some strategy which both picks for $\EAd_\IP$ and is in $\EAd_\IB$, unlike for $\Gamma$-Maximin. 
 \begin{proposition}\label{thm:ead-existence[indep]}
	If $p\in\IP$ and $p\times\mu\in\IB$, then any picking strategy $\s$ that picks for $\EU_p$ both picks for $\EAd_\IP$ and is in $\EAd_\IB(\S)$. 
	
	If there exists some $p$ and $\mu$ with $p\in\IP$ and $p\times\mu\in\IB$, then there are picking strategies that pick for $\EAd_\IP$ and are in $\EAd_\IB(\S)$. 
	
	If, for every $p\in\IP$, there is some $\mu$ such that $p\times\mu\in\IB$, then for every $D\in\Decs$ and $a\in\EAd_\IP(D)$, there is some $\s$ such that $\s(D)=a$ and $\s\in\EAd_\IB(\S)$. 
\end{proposition}

This is proved in \Cref{sect:EAd-EU-appendix}.

%\begin{colored}{red}
	

% {\color{orange}an set $\IB$ of probabilities over $\Omega\times\D$, each taking $\Omega$ and $\D$ to be probabilistically independent. This is a very strong notion of independence, called Strong Independence. We make use of it 
% }
 %Then we can ask, from the point of view of $\IB$, and using E-Admissibility as our decision theory, whether a picking strategy that picks for $\EAd_\IP$ is permissible. And it turns out that, unlike for $\Gamma$-Maximin, there always is such a strategy. Indeed, if you simply take $p$ from $\IP$, and take a picking strategy $\s$ that picks for $\EU_p$, then $\s$ also picks for $\EAd_\IP$, and $\s$ is E-Admissible, as evaluated by $\IB$---that is, $\s$ is in $\EAd_\IB(\Strategies)$; at least if there is some $b=p\times\mu\in\IB$. The following is a corollary of \Cref{thm:eu-self-rec,thm:eu-uniquely-optimal}:
% \begin{proposition}\label{thm:ead-existence[indep]}
% 		If there is some $p\times \mu\in \IB$ such that $\s$ $\mu$-surely picks for $\EU_p$, then $\s\in\EAd_\IB(\Strategies)$. 
 		
% 		Thus, if there is some $p\in\IP$ with some $\mu$ such that $p\times\mu\in\IB$, then there is some $\s$ which picks for $\EAd_\IP$ and is in  $\EAd_\IB(\Strategies)$. 
% \end{proposition}
%\end{colored}
 
 There are a number of conditions that guarantee the existence of some $p\times\mu\in\IB$ for any $p\in\IP$, and thus ensure that every E-Admissible action in a decision problem is part of a picking strategy that is E-Admissible.
 For example, suppose you have no views whatsoever about which decisions you will face,  nor about the evidential value of information about which decisions you will face. 
 In that case, your credal set $\IB$ over $\Omega\times\D$ is given by the \emph{natural extension} of $\IP$ to this space, which is the largest (least informative) set of probabilities that extend the probabilities in $\IP$ to $\Omega \times \D$. 
 This is sufficient to guarantee that for every $p\in\IP$ there is some $\mu$ on $\D$ such that $p\times\mu\in \IB$.
 

 
Alternatively, suppose you have a bit of information both about the world and which decision problem you will face. Your uncertainty about the world is given by the credal set $\IP$ over $\Omega$. Your uncertainty about the which decision you will face is given by the credal set $\ID$ over $\D$. Suppose also that you treat information about which decisions you will face as \emph{irrelevant} to which state of the world you are in. 

In the precise setting, irrelevance is a univocal, symmetric notion: for any joint distribution $b$ over $\Omega \times \D$, $\D$ is \emph{stochastically independent} of (and hence irrelevant to) $\Omega$ according to $b$ just in case $b(\omega\in A\given D\in E)=b(\omega\in A)$ whenever $b(D\in E)>0$.\footnote{For any $A\subseteq\Omega$, $\omega\in A:=\left\{\left<\omega,D\right>\in\Omega\times\D\given \omega\in A\right\}$. Likewise, for any $E\subseteq\D$, $D\in E:=\left\{\left<\omega,D\right>\in\Omega\times\D\given D\in E\right\}$.}
\todooldinfo{ftnte defining marginal again. Check consistency throughtou paper. } 
But in the imprecise setting, irrelevance fractures into a variety of distinct, not necessarily symmetric notions.\footnote{A short survey of independence notions for imprecise probability: complete independence for sets of probabilities (\cite{seidenfeld2007ci,cozman2012}); independence in selection for lower previsions (\cite{campos1995}); strong independence for lower previsions and sets of desirable gambles (\cite{cooman:2012:indnatexdesirs}); epistemic independence (value and subset) for sets of desirable gambles (\cite{Moral2005b}); epistemic h-independence for lower previsions and credal sets (\cite{debock2015:phdthesis}); S-independence for choice functions (\cite{debock2021:S-independence}).}

Consider a case where $\IP$ and $\ID$ are closed and convex and you treat $\D$ as \emph{epistemically irrelevant} to $\Omega$, in the sense of \cite{walley1991srip}. This means roughly that learning information about which decision problem you face does not change your maximum buy price for any ``worldly'' gamble, \emph{i.e.}, any gamble whose payout depends only on $\Omega$. Suppose that $\IP$, $\ID$ and this judgment of epistemic irrelevance jointly capture the totality of your views. In that case, your credal set $\IB$ over $\Omega \times \D$ is given by the \emph{irrelevant natural extension}  \citep[see][Thm 13]{cooman2012}. %\todo{shouldn't it be `see'??}.
This is the largest (least informative) set $\IB$ of probabilities $b$ over $\Omega \times \D$ that marginalize to $\IP$ and $\ID$ and satisfy the following inequality constraints: for any gamble $g:\Omega\rightarrow\mathbb{R}$ and any $B\subseteq\D$ with $b(D\in B)>0$
\[
\inf\left\{\Exp_p[g]\given p\in\IP\right\}\leq\Exp_b[g^+]\leq\sup\left\{\Exp_p[g]\given p\in\IP\right\}
\]
and
\[
\inf\left\{\Exp_p[g]\given p\in\IP\right\}\leq\Exp_b[g^+\given D\in B]\leq\sup\left\{\Exp_p[g]\given p\in\IP\right\},
\]
where $g^+:\Omega\times\D\rightarrow\mathbb{R}$ is the ``cylindrical extension'' of $g$ defined by $g^+(\omega,D)=g(\omega)$ for all $\omega\in\Omega$ and $D\in\D$. As many authors have noted, individual probabilities $b$ in the irrelevant natural extension $\IB$ will not in general treat $\D$ as irrelevant to $\Omega$ (\emph{cf.} \cite[pp. 96-7]{debock2019iar}). Nonetheless, $\IB$ itself will do so, in the sense described above. Moreover, $\IB$ will contain any $b$ that treats $\D$ as stochastically independent of $\Omega$. This is sufficient to guarantee that the condition of \cref{thm:ead-existence[indep]} holds.

Rather than treating $\D$ as epistemically irrelevant to $\Omega$, you might treat $\D$ and $\Omega$ as \emph{completely independent}, in the sense of \cite{seidenfeld2007ci,cozman2012}, \emph{i.e.}, $\D$ and $\Omega$ are stochastically independent according to every $b\in\IB$. This is a more stringent notion of irrelevance than epistemic irrelevance (and is also symmetric). If $\IP$ and $\ID$ capture your opinions about $\Omega$ and $\D$, respectively, you judge $\D$ and $\Omega$ as completely independent, and nothing more (this captures the totality of your views), then your credal set $\IB$ over $\Omega \times \D$ is the largest (least informative) set $\IB$ of probabilities $b$ over $\Omega \times \D$ that marginalize to $\IP$ and $\ID$ and satisfies complete independence, \emph{i.e.}, $\IB=\left\{p\times\mu\given p\in\IP, \mu\in\ID\right\}$. This is also sufficient to guarantee that the condition of \cref{thm:ead-existence[indep]} holds.



%\footnote{More carefully, we suppose that $\IB$ is a set of probability measures $b$ over $\Omega\times\D$ which are absolutely continuous with respect to $u\times\lambda$, where $u$ is the uniform distribution on $\Omega$ and $\lambda$ is the restriction of the Lebesgue measure to $\D$. Let $f^b:\Omega\times\D\rightarrow\mathbb{R}_{\geq0}$ be a Radon-Nikodym derivative (or density) of $b$, so that for any measurable $A\subseteq\Omega\times\D$
%\[
%b(A)=\sum_{\omega\in\Omega}\int_{A_\omega} f^b(\omega,D) \frac{1}{|\Omega|}\diff\lambda(D)
%\]
%where, for any $\omega\in\Omega$, $A_\omega:=\left\{\left<\omega^*,D^*\right>\in A\given \omega=\omega^*\right\}$. To say that $\IB$ marginalizes to $\IP$ is just to say that \[
%\IP=\left\{\int_\D f^b(\cdot,D) \frac{1}{|\Omega|}\diff\lambda(D)\given b\in\IB\right\}
%\]
%}
 
 
%{\color{olive}\begin{proposition}\label{thm:ead-suff}
%	If $\s$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$ for some $b\in \IB$ then $\s\in\EAd_\IB(\Strategies)$. 
%	
%	Thus, there is some $\s$ which picks for $\EAd_{\IB(\cdot|-)}$ and which is in $\EAd_\IB(\S)$. 
%%	
%%	Thus, if there is some $p\in\IP$ with some $p\times\mu\in \IB$, then there is some $\s$, namely any $\s$ which picks for $\EU_p$, which picks for $\EAd_\IP$ and which is in $\EAd_\IB(\Strategies)$. 
% %		Suppose $\IB\restriction \Omega=\IP$ and making $\Omega$ and $\D$ independent.}
%		%If $p\in\IP$ with some $p\times \mu\in \IB$ and $\s$ picks for $\EU_p$, then $\s$ picks for $\EAd_\IP$ and $\s$ is in $\EAd_\IB(\S)$. 
%%		If $\s$ $\mu$-surely picks for $\EU_p$ for some $p\times\mu\in \IB$, then $\s$ is in $\EAd_\IB(\S)$.
%%		
%%		Suppose $p$ is in $\IP$ with some $p\times\mu\in \IB$. Then if $\s$ picks for $\EU_p()
%%		 then $\s$ picks for $\EAd_\IP$ and 
%%{	If $p\in\IP$ with some $p\times \mu\in \IB$ and $\s$ picks for $\EU_p$, then $\s$ picks for $\EAd_\IP$ and $\s$ is in $\EAd_\IB(\S)$. }
%%If $\s$ picks for $\EU_p$, for some $p\times \mu\in \IB$, then $\s$ picks for $\EAd_\IP$ and $\s$ is in $\EAd_\IB(\Strategies)$.\todooldinfo{Now I've fiddled with the independence, we can't quite say this!!! And same for Max }
%%\todooldinfo{is this a good way to write the thm?}
%\todooldinfo{JK: Observe that $p\times\mu$ is in the natural extension of $\IP$. So there is some joint distribution consistent with $\IP$ relative to which $\s$ picks for $\EAd_\IP$.}
%\end{proposition}
%}
The upshot is that E-Admissibility is not self-undermining in the same way that $\Gamma$-Maximin is self-undermining. So long as $\IP$ and $\IB$ are appropriately related, then there are strategies that pick for it that it does not deem impermissible.


Do we obtain a converse to \cref{thm:ead-existence[indep]}?  Are these the only E-Admissible strategies? 
A strategy is E-Admissible iff there is some $b\in\IB$ which expects it to be optimal.
We might hope to be able to apply \cref{thm:eu-uniquely-optimal} to get that it is only these strategies that are E-Admissible. For this, we need to assume that every $b$ in $\IB$ has the form $p\times\mu$, i.e., that you treat $\D$ as completely irrelevant to $\Omega$:

%{\color{red} It is worth emphasising, though, that the strength of your irrelevance judgments (whether you make a judgment of epistemic irrelevance or complete independence, for example) makes a big difference to which strategies are permissible by the lights of E-Admissibility. If you treat $\D$ as completely irrelevant to $\Omega$, then we can use \cref{thm:eu-self-rec,thm:eu-uniquely-optimal} to get the following: 

\begin{proposition}\label{thm:ead-equiv[indep]} 	Suppose $\IB$ makes $\Omega$ and $\Decs$ completely independent (so every $b\in\IB$ has the form $p\times\mu$.)
	
	Then, $\s\in\EAd_\IB(\Strategies)$ iff there is some $p\times \mu\in\IB$ such that $\s$ $\mu$-surely picks for $\EU_p$. 
%	If $\s$ does not $\mu$-surely pick for $\EU_p$, for any $p\times \mu\in \IB$, then $\s$ is not in $\EAd_\IB(\Strategies)$.
\end{proposition}

This is proved in \Cref{sect:EAd-EU-appendix}.

So the rather strong judgment of complete independence has rather strong implications for your views about picking strategies. The only strategies that are permissible by the lights of E-Admissibility in this case are ones that pick for expected utility theory, \emph{i.e.}, always pick options that maximize $p$-expected utility, for some $p\times \mu\in\IB$.



\begin{comment}
{\color{violet}
In fact, these are pretty much the only strategies that are permissible by the lights of E-Admissibility when coupled with $\IB$. Immediate from the definition of E-Admissibility, we have that a strategy is in $\EAd_\IB(\S)$ just if it is in $\EU_B(\S)$ for some $B\in\IB$. We can thus make use of \cref{thm:eu-self-rec,thm:eu-uniquely-optimal} to get the following, which applies when we have a strong independence. (In \cref{sect:EAd-dep} we will describe how this assumption can be dropped, but we first analyse it under this assumption.) 

\begin{proposition}\label{thm:ead-equiv[indep]}Suppose every $b\in\IB$ has the form $p\times\mu$.
	
	Then, $\s\in\EAd_\IB(\Strategies)$ iff $\s$ $\mu$-surely picks for $\EU_p$ for some $p\times \mu\in\IB$. 
%	If $\s$ does not $\mu$-surely pick for $\EU_p$, for any $p\times \mu\in \IB$, then $\s$ is not in $\EAd_\IB(\Strategies)$.
\end{proposition}}
\end{comment}



For example, in the Ellsberg case (\cref{sect:Ellsberg}), $\EAd_\IP(D^{\mathrm{Ellsberg}}_1)=\{\text{1E,1F}\}$ and $\EAd_\IP(D^{\mathrm{Ellsberg}}_2)=\{\text{2E,2F}\}$; so every strategy picks for $\EAd_\IP$. 
However, the $\s_{\text{1E,2F}}$ strategy, which is the empirically observed strategy, does not pick for any $\EU_p$: it is not rationalisable by expected utility theory.\footnote{See \cref{ftnte:Ellsberg not EU}.} 
If every $b\in\IB$ has the form $p\times\mu$ with each $\mu$ giving positive probability to facing both of the decisions in the Ellsberg case, then $\s_{\text{1E,2F}}$ also does not $\mu$-surely pick for $\EU_p$ for any $p\times\mu\in\IB$; and thus, it is not in $\EAd_\IB(\S)$, despite picking for $\EAd_\IP$. 
However, there are some strategies which pick for $\EAd_\IP$ and are in $\EAd_\IB(\S)$, namely any strategy for which there is some $p\times\mu\in\IB$ which $\mu$-surely picks for $\EU_p$, for example $\s_{\text{1E,2E}}$. 
%\todo{minor rewrite this little bit above. Reread. Huge changes below.}


%\begin{colored}{violet}
	
There are often picking strategies $\s$ that pick for $\EAd_\IP$---for each decision problem $D$, they pick an action from $\EAd_\IP(D)$---but which are rejected by $\EAd_\IB$---that is, they do not lie in $\EAd_\IB(\Strategies)$. 
This occurs when, for each decision problem $D$, there is some probability function $p\in\IP$ such that $\s(D)\in\EU_p(D)$, but where different probability functions rationalise $\s$ in different decision problems, and there is no $(p,\mu)\in\IB$ such that $\s$ $\mu$-surely picks for $\EU_p$. 

This will entail that, for every $(p,\mu)\in\IB$, $\EAd_\IP$ is not $\mu$-surely a restriction of $\EU_p$, i.e., $\mu(\{D\given \EAd_\IP(D)\setminus\EU_p(D)\neq\emptyset\})>0$. Once we move to \emph{probabilistic} picking strategies below, it will turn out that this condition is also sufficient to ensure that no regular probabilistic picking strategy $\mu$-surely picks for $\EU_p$. However, it is not sufficient to show the existence of the deterministic picking strategies here. To do that, we require that each $\mu$ recognises the requirement to coordinate. 

We can give some sufficient conditions for the existence of strategies that pick for $\EAd_\IP$ but are rejected by $\EAd_\IB$: 
\begin{proposition}\label{thm:ead-existsimpermissible[indep]}

Suppose $\IB$ makes $\Omega$ and $\Decs$ completely independent (so every $b\in\IB$ has the form $p\times\mu$.)

Suppose there is a selection of pairwise disjoint events $E_q\subseteq\Decs$, one for each $q\in\IP$ (some of which may be empty), such that for all $p\times\mu\in\IB$, 
\[
\mu\left(\bigcup_{q\in\IP}\{D\in E_q\given \EU_p(D)\cap\EU_q(D)=\emptyset\}\right)>0
\]

Then there is $\s$ which picks for $\EAd_\IP$ but which is not in $\EAd_\IB(\S)$. 
\end{proposition}
This is proved in \Cref{sect:appendix:eadundermining}.

In certain cases, such as the Ellsberg ones, we  can straightforwardly verify that this sufficient condition holds. 
We can also show it holds under some plenitude conditions: if each $\mu$ assigns strictly positive measure to every collection of take-it-or-leave-it decisions generated by a non-empty open subset of $\A$, that is, $\mu(\{\{a,0\}\given a\in V\})>0$, for $V$ a non-empty open subset of $\A$; or if each $\mu$ assigns strictly positive measure to every non-empty open set of decisions. In such cases, we can select two disjoint $E_1,E_2$ such that for any $p\neq q$, and for $i = 1, 2$, $\mu(\{D\in E_i \mid \EU_p(D)\cap \EU_q(D)=\emptyset\})>0$. Then by selecting any distinct $q^*_1,q^*_2$ from $\IP$, we can see that the conditions of \cref{thm:ead-existence[indep]} hold. We discuss these in \cref{sect:appendix:eadundermining}.

%\end{colored}


%{\color{red}E-Admissibility rejects some picking strategies which are compatible with its own choice set. But in every decision problem you're faced with, those acts which are E-Admissible are exactly those that arise from E-Admissible picking strategies. What this reveals is that...}
%{\color{blue}
%	E-Admissibility rejects some picking strategies which are compatible with its own choice set. But in every decision problem you're faced with, those acts which are E-Admissible are exactly those that arise from E-Admissible picking strategies, unlike in \cref{sect:reu:phil-discussion}, although E-Admissible picking strategies require coordinating across the decision problems so that they could arise as expected utility strategies for some probability in one's credal set. 
%	This feels a bit like Consumer Bulletin advising you that it is fine to hire a personal shopper who invariably comes back with Consumer Bulletin best buys, but only if they are \emph{guaranteed} to pick Consumer Bulletin best buys that are also Consumer Reports best buys. This is not quite self-undermining, but close, you might think.
%}

%\begin{colored}{red}
%	 E-Admissibility rejects some picking strategies which are compatible with its own choice set. %\todo{this is repeating statement above the propn... is that ok?}
%  \Cref{thm:ead-equiv[indep]} (and the more general \cref{thm:ead-equiv[dep]}) shows that E-Admissible picking strategies require coordinating across the decision problems so that they could arise as expected utility strategies for some probability in one's credal set. Still, in every decision problem you're faced with, those acts which are E-Admissible are exactly those that arise from E-Admissible picking strategies, unlike in \cref{sect:reu:phil-discussion}.

%\end{colored}


Does this make E-Admissibility self-undermining? Not exactly. But it does mean that, by her own lights, an E-Admissibility decision-maker must pick from her choice set \emph{as if} her credal set represented some true, precise probability which she is simply not in a position to identify. This is close to what \cite{levi99} referred to as \emph{imprecise} rather than \emph{indeterminate} probabilities. And it may not sit well with contemporary proponents of E-Admissibility.



%One might see this result as a problem for E-Admissibility. If every $b$ in $\IB$ agrees that a given picking strategy could \emph{possibly} saddle you with an E-Admissibile but non-$\EU$ option in \emph{some} decision problem or other, then E-Admissibility will reject that strategy. The only picking strategies it does not reject are ones that are certain, according to some $b$ in $\IB$, to yield an $\EU$ option in every decision problem. 
%	This feels a bit like Consumer Bulletin advising you that it is fine to hire a personal shopper who invariably comes back with Consumer Bulletin best buys, but only if they are \emph{guaranteed} to pick Consumer Bulletin best buys that are also Consumer Reports best buys. This is not quite self-undermining, but close, you might think.
	
	
	On the other hand, one might not see this as a concern for E-Admissibility. %Firstly, as \cref{thm:ead-equiv[dep]} makes clear, there are many picking strategies that E-Admissibility does not reject. In the Consumer Bulletin analogy, it is as if there are many other magazines that your personal shopper could cross-reference, not just Consumer Reports. Secondly, and more to the point, 
%{\color{red}What all of this shows, one might think, is just that E-Admissibility sees value in coordinating how you resolve incomparability.}
%{\color{violet}
It just shows that E-Admissibility sees value in coordinating how you resolve incomparability.
Take a simple example.
	
	\label{eg:coord}
	$$
	\begin{array}{r|cc}
		D^{\mathrm{coord}}_1 & X & \neg X  \Bstrut \\\hline \Tstrut		p & x & 1-x \Bstrut \\\hline \hline\Tstrut 
		B & \text{\pounds 10} & \text{\pounds 10}   \\
		1C & \text{\pounds 0} & \text{\pounds 20} 
	\end{array}\hspace{20mm}
	\begin{array}{r|cc}
		D^{\mathrm{coord}}_2 & X & \neg X  \Bstrut \\\hline \Tstrut		p & x & 1-x \Bstrut \\\hline \hline\Tstrut 
		B & \text{\pounds 10} & \text{\pounds 10}   \\
		2C & \text{\pounds 20} & \text{\pounds 0} 
	\end{array}
	$$
	
	Any $\EU$-maximizer will coordinate their choices in $D^{\mathrm{coord}}_1$ and $D^{\mathrm{coord}}_2$ in the following sense: assuming their utility is linear in $\pounds$s, they will choose $B$ (reject $1C$) in $D^{\mathrm{coord}}_1$ just in case they choose $2C$ (reject $B$) in $D^{\mathrm{coord}}_2$; likewise, they will choose $1C$ (reject $B$) in $D^{\mathrm{coord}}_1$ just in case they choose $B$ (reject $2C$) in $D^{\mathrm{coord}}_2$. 
% \todoold{unless $p=0.5$!!!}	
	
	Suppose $\IP = \{p_1, p_2\}$, where $p_1$ expects $B$ to be strictly better than $1C$, while $p_2$ expects $B$ to be strictly worse than $2C$. In that case, $\EAd_\IP(D^{\mathrm{coord}}_1)=\{B,1C\}$ and $\EAd_\IP(D^{\mathrm{coord}}_2)=\{B,2C\}$. You find both options in both options \emph{incomparable}, \emph{i.e.}, not rejected but also not indifferent, or equally good. Just as each of $p_1$ and $p_2$ coordinates their choices in $D^{\mathrm{coord}}_1$ and $D^{\mathrm{coord}}_2$, so too does E-Admissibility, advising you to coordinate how you resolve incomparability in a picking strategy. You ought to pick $B$ in $D^{\mathrm{coord}}_1$ just in case you pick $2C$ in $D^{\mathrm{coord}}_2$. Likewise, you ought to pick $1C$ in $D^{\mathrm{coord}}_1$ just in case you pick $B$ in $D^{\mathrm{coord}}_2$. 

	
	
	Now, you might doubt that there is \emph{really} any value in this sort of ``modal coordination.'' (Recall, you will actually only face one of $D^{\mathrm{coord}}_1$ or $D^{\mathrm{coord}}_2$. You are not coordinating across time.) But the fact that E-Admissibility \emph{sees} value in coordinating how you resolve incomparability does not render it self-undermining.
	
%	You might also be perplexed by the sheer quantity of strategies that pick for E-Admissibility but are nonetheless rejected by E-Admissibility. Here it is important to remember that picking for E-Admissibility is simply a matter of being guaranteed to select options that are \emph{not rejected} by E-Admissibility. The utility of an option, $\U(a)$, is a gamble on $\Omega$. The utility of picking strategy, in contrast, $\U(\s)$, is a gamble on $\Omega\times\D$---a larger, refined sample space. Reasons for rejection that are not visible at one scale, or level of resolution, might nonetheless become apparent at others. The fact that E-Admissibility identifies some reasons for rejection at the scale of picking strategies---reasons grounded in the (putative) value of coordination---does not conflict in any way with more pervasive non-rejection at the scale of actions or options, nor is it altogether surprising. 

Moreover, while E-Admissibility's lust for coordination does require decision-makers to \emph{pick as if} their probabilities were imprecise rather than indeterminate, in Levi's sense, this does not mean that they \emph{actually are} imprecise rather than indeterminate. Their credal set need not \emph{actually} represent some true, precise probability which they are unable to identify. This is reflected in their rejection judgments. They often find options genuinely incomparable---not rejected, but not indifferent. No agent with precise probabilities would do so. They are committed to \emph{picking as if} they have some true, precise probability because they value coordination in resolving incomparability.

The utility of an action, $\U(a)$, is a gamble on $\Omega$. The utility of picking strategy, in contrast, $\U(\s)$, is a gamble on $\Omega\times\D$---a larger, refined sample space. Reasons for rejection that apply to one scale, or level of resolution, might not apply at others. E-Admissibility identifies some reasons for rejection at the scale of picking strategies---reasons grounded in the (putative) value of coordination---that are not reasons for rejection at the scale of actions or options. 


%{\color{blue}E-Admissibility rejects some picking strategies which are compatible with its own choice set. But in every decision problem you're faced with, those acts which are E-Admissible are exactly those those that arise from E-Admissible picking strategies, unlike in \cref{sect:reu:phil-discussion}, although E-Admissible picking strategies require coordinating across the decision problems so that they could arise as expected utility strategies for some probability in one's credal set. }

%{\color{blue}What these show is that for a strategy to be evaluated as E-Admissible it requires coordination across different decision problems. For example, in the coord case, is fine for one's strategy to pick either act in $D^{\mathrm{coord}}_1$ so long as it picks the corresponding act in $D^{\mathrm{coord}}_2$. It does not permit arbitrary picking strategies which are compatible with 
%If one takes E-Admissibility as a choice function which actively deems any act to be permissible, then it is not clear how such coordination can be imposed. But 
%}
%The role of the picking strategies 
%Does this result in any conflicting guidance at the point of decision making, paralleling that of \cref{sect:reu:phil-discussion}? No, because any E-Admissible act is one that arises from an E-Admissible strategy.\
%However, if being E-Admissib
%
%It is not, however, clear how the coordination is to be imposed. If I'm actually facing a decision problem $D$, any E-Admissible act is not rejected, although were I to be facing an alternative $D'$ I should plan to pick correspondingly. Decision theory doesn't usually talk about this ``were I to be facing another decision problem''. 
%
%This can be seen as a justification for why we shouldn't deem acts that are not rejected to be actively permissible, as that seems to judge 
%If decision theories are understood simply as specifications of which acts are permissible in various decision problems, it is not clear how this coordination can be encoded. What does E-Admissibility deem permissible to pick in these decision problems? In the Ellsberg case, neither act is impermissible in $D^{\mathrm{Ellsberg}}_1$, so long as one would pick the corresponding act in $D^{\mathrm{Ellsberg}}_2$. This requires some additional structure in the decs
% unlike in the closely related, for example, paradoxes of sequential choice where one's selections can restrict future 
%It is fine to select either act when faced with $D^{\mathrm{Ellsberg}}_1$ so long as, were one to be faced with $D^{\mathrm{Ellsberg}}_2$ one would pick the corresponding action. This is not a way that decision theories are usually presented. Instead it is simply given as a specification of which options are impermissible in each decision problem, i.e., given by a choice function. What this shows us is that the decision theory has to encode more information. 
%Since we are evaluating strategies as a means of evaluating the decision theory, we might then ask how the decision theory encodes this requirement to coordinate, as they are usually presented simply as giving guidance in the individual decision problems. To build on this idea, we will change to using the decision theory to evaluate not the picking strategies but to evaluate the decision theory itself. 
\todooldinfo{sort out here!!!! I }

	\subsubsection{Maximality}
%\begin{colored}
%	{violet}
	We can also apply the notion of Maximality to determine which picking strategies are Maximal: 
	$$\Maximality_\IB(\S)=\Set{\s\in\S\given (\forall \s'\in\S)(\exists b\in\IB)(\Exp_b[\U(\s)]\geq\Exp_b[\U(\s')])}$$
%\end{colored}
	
Since Maximality is a more permissive decision theory than E-Admissibility, \cref{thm:ead-existence[indep]} entails:


%\begin{colored}{red}
%	 \begin{proposition}\label{thm:max-suff}
%	If $\s$ picks for $\EU_p$ for some $p\times \mu\in \IB$ with $p\in\IP$, then $\s$ picks for $\Maximality_\IP$ and $\s$ is in $\Maximality_\IB(\Strategies)$.
%	
%	If $\s$ picks for $\EU_{b(\cdot|-)}$ for some $b\in\IB$, then $\s$ picks for $\Maximality_{\IB(\cdot|-)}$ and $\s\in \Maximality_\IB(\Strategies)$. 
	%and is not in $\EAd_\IB(\Strategies)$.
%\end{proposition}
%\end{colored}

%\begin{colored}{violet}
	 \begin{proposition}\label{thm:max-suff}
	If $p\in\IP$ and $p\times\mu\in\IB$ then any $\s$ which picks for $\EU_p$ both picks for $\Maximality_\IP$ and is in $\Maximality_\IB(\S)$. 
	
	If there exists some $p$ and $\mu$ with $p\in\IP$ and $p\times\mu\in\IB$, then there are some strategies which pick for $\Maximality_\IP$ and are in $\Maximality_\IB(\S)$. 
\end{proposition}

%\end{colored}
\begin{comment}
Since Maximality is a more permissive decision theory than E-Admissibility, \cref{thm:ead-equiv[indep]} entails:



\begin{proposition}\label{thm:max-suff}
	If $\s$ picks for $\EU_p$, for some $p$ in $\IP$ with some $p\times \mu\in \IB$, then $\s$ picks for $\Maximality_\IP$ and $\s$ is in $\Maximality_\IB(\Strategies)$.
%	
%	If $\s$ picks for $\EU_{b(\cdot|-)}$ for some $b\in\IB$, then $\s$ picks for $\Maximality_{\IB(\cdot|-)}$ and $\s\in \Maximality_\IB(\Strategies)$. 
	%and is not in $\EAd_\IB(\Strategies)$.
\end{proposition}
This is proved in \Cref{sect:maximality-appendix}.
%Here, we extended maximality to apply to dependence in the analogous way: conditionalise the probabilities on which decision problem you're faced with. 
\end{comment}

And so, like E-Admissibility, Maximality is not self-undermining in the way that $\Gamma$-Maximin is self-undermining. There are always strategies that pick for it that it does not deem impermissible, %\begin{colored}{violet}
	at least as long as such $p\in\IP$ and $p\times\mu\in\IB$ exist.
%\end{colored}

Unlike for E-Admissibility, we do not get the converse result (even under the assumption of complete independence). There can sometimes be some strategies which are not ruled out by Maximality but which nonetheless do not pick for any $\EU_p$. This is because a strategy is only ruled out as impermissible if there's a \emph{single} alternative which is preferable according to \emph{every} $b\in \IB$. 
This happens, for example, in the Ellsberg case if one's probability over which decision problem you think you'll face is sufficiently imprecise or if it's precise and pretty confident about which one you will face. 
%, as when $\mu$ does assign high enough confidence to facing $D^{\mathrm{Ellsberg}}_1$, then it evaluates any strategy as permissible. 

If, however, you think it's precise and equally likely that you'll face each of $D^{\mathrm{Ellsberg}}_1$ and $D^{\mathrm{Ellsberg}}_2$, so your credal set is given by $\IB=\{p\times\mu^*\given p\in\IP\}$, where $\mu^*(D^{\mathrm{Ellsberg}}_1)=\mu^*(D^{\mathrm{Ellsberg}}_2)=0.5$, then as we observed in \cref{sect:gamma}, $\Exp_{\mu^*}[\U(\s_{\text{1E,2F}})(\omega)]=5$ for each $\omega$ and $\Exp_{\mu^*}[\U(\s_{\text{2E,1F}})(\omega)]=6$; so then for every probability $p$, $\Exp_{p\times\mu^*}[\U(\s_{\text{1E,2F}})]=5$ and $\Exp_{p\times\mu^*}[\U(\s_{\text{2E,1F}})]=6$, so  $\s_{\text{1E,2F}}\notin\Maximality_\IB(\Strategies)$. 

We will be able to show that, if your credences over which decision problem you'll face are precise, and also have a further property---they ``require almost everywhere decisiveness''\footnote{The example using the Ellsberg case does not have this property, which requires many decision problems to be possible. If, for example, we had selected $\mu^*(D^{\mathrm{Ellsberg}}_1)=0.1$, then one can check that no strategies are ruled out by Maximality.}---then %we can show that 
the only strategies that Maximality does not rule as impermissible are the expected utility strategies. We will discuss this and give the details in \cref{sect:nu:Max}, but we first note that our results so far hold in a more general setting, one where we allow for decision-state dependence. 

%We will be able to nonetheless get results for this case if we assume that you happen to be precise about which decision problem you'll be faced with, and this measure over the decisions has a particular property (requiring almost everywhere decisiveness); which we will discuss this in \cref{sect:nu:Max}.



	\subsubsection{Decision-State Dependence}\label{sect:EAd-dep}
To avoid the various independence assumptions we employed in \cref{sect:e-admiss}, we  now generalize some of our earlier results to cover the case in which we don't assume the decision problem you face is independent of the state of the world you're in,  as we did in the precise setting in \cref{sect:decdep}. To do this, in any decision problem, we must bring $\IB$ up to speed on the problem that you face (by updating on that information via pointwise conditionalization), and then use the updated credal set to determine which options to reject. 
\todoold{We already talked about this earlier! }
%\todo{Do we need to say it's pintwise conditionalizaiton?}

%To avoid the strong independence we can present version of this result using the credal state over $\Omega\times\D$ which might allow for dependence. To do this, one must first conditionalise the probabilities by the decision problem you're faced with, and then select amongst the available ones. 

%\begin{colored}{violet}


\begin{definition}
	$$\EAd_{\IB(\cdot|-)}(D) = \Set{a \in D \given (\exists b \in \IB)(\forall a' \in D)(\Exp_{b(\cdot|D)}[\U(a)]\geq\Exp_{b(\cdot|D)}[\U(a')])}
	$$
	$\s$ picks for $\EAd_{\IB(\cdot|-)}$ iff, for all $D\in\Decs$, $\s(D)\in\EAd_{\IB(\cdot|-)}(D)$.
	\end{definition}
	That is, $a\in\EAd_{\IB(\cdot|-)}(D)$ iff there is some $b\in\IB$ such that $a\in\EU_{b(\cdot|-)}(D)$. 
	
	Also $\s\in\EAd_\IB(\Strategies)$ iff there is some $b\in\IB$ such that $\s\in\EU_b(\Strategies)$. 
	We thus have, as a consequence of \cref{thm:eu-dep}: 
	\begin{proposition}\label{thm:ead-equiv[dep]}
		$\s\in\EAd_\IB(\Strategies)$ iff for some $b$ in $\IB$, $\s$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$.
	\end{proposition}
	And so:
	 \begin{proposition}\label{thm:ead-existence[dep]}
	 	If $b\in\IB$ and $\s$ picks for $\EU_{b(\cdot|-)}$, then $\s$ both picks for $\EAd_{\IB(\cdot|-)}$ and is in $\EAd_{\IB(\cdot|-)}$.
		
			 	
	 	There thus always exists some strategies which pick for $\EAd_\IP$ and are in $\EAd_{\IB(\cdot|-)}$. 
		
		For every $D\in\Decs$ and $a\in\EAd_{\IB(\cdot|-)}(D)$, there is some $\s$ such that $\s(D)=a$ and $\s\in\EAd_\IB(\S)$. 
	\end{proposition}
	These are both proved in \Cref{sect:EAd-EU-appendix}.


	Whilst some of its picking strategies are not ruled out, often some will be ruled out. 
%\end{colored}


		
\begin{proposition}\label{thm:ead-existsimpermissible[dep]}
Suppose there is a selection of pairwise disjoint events $E_{b'}\subseteq\Decs$, one for each $b'\in\IB$ (some of which may be empty), such that for all $b\in\IB$, $$b_\Decs\left(\bigcup_{b'\in\IB}\{D\in E_{b'}\given \EU_{b(\cdot|-)}(D)\cap \EU_{b'(\cdot|-)}(D)=\emptyset\}\right)>0.$$

Then there is $\s$ that picks for $\EAd_{\IB(\cdot|-)}$ but which is not in $\EAd_{\IB}(\S)$.


\end{proposition}
This is proved in \Cref{sect:appendix:eadundermining}.



\begin{colored}{blue}
\Cref{thm:ead-existsimpermissible[dep]} provides one example of a ``richness condition'' on the class of $b_\Decs$ that guarantees that they assign positive probability to a ``sufficiently inclusive'' set of decision problems that we can find a strategy $\s$ that picks for $\EAd_{\IB(\cdot|-)}$ but which is not in $\EAd_{\IB}(\S)$. But it is by no means the only one. For example, let $\c$ be any choice function (\textit{e.g.}, $\EAd_{\IB(\cdot|-)}, \Maximality_{\IB(\cdot|-)}$, etc.). Suppose that for any $b\in\IB$, $b_\Decs$ assigns positive probability to the set of decisions where $\c$ leaves open options that $b$ rejects, \textit{i.e.} $b_\Decs(U_b)>0$ where $U_b:=\bigl\{D\in\Decs\given \c(D)\not \subseteq\EU_{b(\cdot|-)}(D)\bigr\}$. Suppose further that there is some measurable property of decision problems; and each $b_\Decs$ sees a ``sufficiently inclusive'' subset of $U_b$ that it thinks $\c(D)$'s property-value %varies widely enough as you traverse $U_b$ that it 
will end up falling in any open interval somewhere on $U_b$. More carefully, suppose there is some measurable statistic $r:\Decs\rightarrow[0,1)$, and that for any $b\in\IB$ and any open interval $I\subset[0,1)$, $b_\Decs\bigl(\,D\in U_b\given r(\c(D))\in I \bigr)>0$. This ``richness condition'' also guarantees that we can find a strategy $\s$ that picks for $\c$ but does not $b_\Decs$-surely pick for $\EU_{b(\cdot|-)}$ for any $b\in\IB$. By \cref{thm:ead-equiv[dep]}, then, $\s$ is not in $\EAd_\IB(\Strategies)$.
 



\begin{proposition}\label{thm:seed-suff-impermissible-strat}
Suppose that for any $b\in\IB$, $b_\Decs(U_b)>0$ where 
\[
U_b:=\bigl\{D\in\Decs\given \c(D)\not \subseteq\EU_{b(\cdot|-)}(D)\bigr\}.
\] 
Suppose further that there is some measurable statistic $r:\Decs\rightarrow[0,1)$ such that for any $b\in\IB$ and any open interval $I\subset[0,1)$, 
\[
b_\Decs\bigl(\,D\in U_b\given r(\c(D))\in I \bigr)>0.
\]
Then there is $\s$ which picks for $\c$ but for no $b\in\IB$ does it $b_\Decs$-surely pick for $\EU_{b(\cdot|-)}$.

\end{proposition}
This is proved in \Cref{sect:appendix:eadundermining}.

As an immediate corollary of \cref{thm:ead-equiv[dep]} and \cref{thm:seed-suff-impermissible-strat} we have:

\begin{corollary}\label{thm:seed-suff-eadimpermissible-strat}
Suppose that for any $b\in\IB$, $b_\Decs(U_b)>0$ where 
\[
U_b:=\bigl\{D\in\Decs\given \EAd_{\IB(\cdot|-)}(D)\not \subseteq\EU_{b(\cdot|-)}(D)\bigr\}.
\] 
Suppose further that there is some measurable statistic $r:\Decs\rightarrow[0,1)$ such that for any $b\in\IB$ and any open interval $I\subset[0,1)$, 
\[
b_\Decs\bigl(\,D\in U_b\given r(\EAd_{\IB(\cdot|-)}(D))\in I \bigr)>0.
\]
Then there is $\s$ which picks for $\EAd_{\IB(\cdot|-)}$ but which is not in $\EAd_{\IB}(\S)$.
\end{corollary}
\end{colored}








For Maximality, we can define: 
\begin{definition}
	$$\Maximality_{\IB(\cdot|-)}(D) = \Set{a \in D \given (\forall a' \in D)(\exists p\in\IP)(\Exp_{b(\cdot|D)}[\U(a)]\geq\Exp_{b(\cdot|D)}[\U(a')])}
	$$\end{definition}
	Since $\s\in\EAd_\IB(\S)$ implies $\s\in\Maximality_\IB(\S)$, we obtain, as a consequence of \cref{thm:ead-equiv[dep]}:
	\begin{proposition}\label{thm:max-suff[dep]}
	If for some $b$ in $\IB$, $\s$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$, then $\s\in\Maximality_\IB(\Strategies)$. 
\end{proposition}This is proved in \Cref{sect:maximality-appendix}. And thus, there is always some $\s$ which picks for $\Maximality_{\IB(\cdot|-)}$ which is itself not rejected according to $\Maximality_\IB(\Strategies)$. However, again, we do not have %the converse result 
an analogue of \cref{thm:ead-equiv[dep]} unless we impose additional particular restrictions on $\IB$ (\cref{sect:nu:Max}).





%{\color{red} DELETE???
%
%
%
%However, the analogous follow-up result requires some further assumptions. In particular, we need to assume that your credence over which decision{\color{orange} you'll be faced with is given by a single, \emph{precise} probability, $\mu^*$. That is, where $\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$. }And we place a further condition on $\mu^*$:
%\begin{definition}\label{def:suff spread}
%	$\mu^*$ \emph{requires almost everywhere decisiveness} iff for all probabilities $p$,$$\mu^*\Set{D\given \EU_p(D)\text{ is a singleton}}=1.$$ 
%\end{definition}
%That is, for each probability function $p$, $\mu^*$ is certain that you'll face a decision problem in which only one act maximizes expected utility. That is, the set of decision problems in which there are ties for expected utility has measure 0.
%%Just considering a single proposition, this will hold, for example, if you might be faced with various decision problems indexed by $t\in[0,1]$: are you willing to pay $\$t$ for a bet paying out $\$1$ if $p$ and $\$0$ if $\neg p$, where $\mu^*$ is a measure assigning strictly positive weight to every non-degenerate interval $[x,y]$. 
%%Suppose you have any coherent rejection function over $\Omega$. 
%
%%Wald gives us a very strong result linking being Bayes to be 
%
%Then we have the following result.
%\begin{proposition}\label{thm:max-nec}
%If $\mu^*$ requires almost everywhere decisiveness and countably additive, and $\s$ does not $\mu^*$-surely pick for $\EU_p$, for some $p$ in $\IP$, then $\s$ is not in $\Maximality_\IB(\Strategies)$.
%\end{proposition}
%This follows from a version of Wald's Complete Class Theorem, which shows that, if $\s$ does not $\mu^*$-surely pick for $\EU_p$, for some $p$ in $\IP$, then there is an alternative strategy $\s^*$ such that $\EU_{p\times\mu^*}[\U(\s)] < \EU_{p\times\mu^*}[\U(\s^*)]$, for each $p$ in $\IP$.
%}
%This will (somehow) result in a conflict with the notion of being a coherent rejection function, at least one which satisfies (a), (b) and (c). 


%\begin{corollary}
%	If $\s$ is not $\mu^*$-surely an $\EU_p$ strategy for any $p\in\IP$ then $\s\notin \Maximality_{\IP\times \{\mu^*\}}(\S)$.\todoold{is this legitimate way to write it??}
%\end{corollary}

%\todooldinfo{Qu for JK: can we get a version written for rejn fns generally instead of the credal set kind of version. }
%
%
%\todooldinfo{Do we have condition under which some Max strategies disagrees with EUp? }

%This is again similar to the case as for E-Admissibility: some Maximality strategies are Maximal (in particular, all the $\EU_p$ ones), whilst some are not (all the others). The difference to our discussion of E-Admissibility was the stronger assumption that we needed: that $\mu$ was in fact precise. 


%\subsection{The restriction to precise $\mu$}\label{sect:maximality:imprecise mu}

%Recall \cref{sect:reu:other mu} where we discussed how problematic our results were, since they only showed undermining given particular $\mu$. Something similar is happening here: we have only shown that they theory is undermining on particular ways of being uncertain over which decision she'll be faced with, in particular that she has precise probabilities, and they are uncertain over a whole range of decisions. This is a wide range of uncertainty and so we find the fact that it is undermining in these cases to be a worry. Of course the imprecise probability defender can say that she doesn't have precise probabilities over what decisions she'll be faced with, but nonetheless we feel it is a worry. 

%\todooldinfo{RP needs to look at this. How does the argument ehre differ from the REU one? }


\section{The utility of using a decision theory}\label{sect:nu}


%\todooldinfo{Both RP and JK to check this section [black]! I think I've got a proposal here, but would like to know if you think it's ok! I think the development of the options is right....?}
%\todooldinfo{I'm still actually unsure if this stuff should go underneath the maximality part. If so, they should all be subsections of a single IP section, not the way I've got here. That might make more sense anyway...}


%\begin{colored}{red}\todoold{get in there somewhere!}
%	The E-Admissibility challenge is very fundamental when viewed this way: however you evaluate $\U(C,D,\omega)$, each $p$ thinks it'd be best to be $\EU_p$, so must be $\EU_p$!
%\end{colored}

%
%\begin{colored}{red}
%	In this paper so far, we have asked how a decision theory evaluates the picking strategies that are compatible with what the theory recommends for each decision. But there are other things we could be doing within this topic to determine whether a decision theory undermines itself. 
%	
%	If our decision theory gives $C(D)$ containing various options, what should one do? 
%	
%	\begin{enumerate}
%		\item Evaluate the utility of the choice function itself. It should be guided by the idea of its value being what it leads you to. We should specify a numerical value for $\U(C,D,\omega)$, ensuring its between $\U(a,\omega)=a(\omega)$ for all $a\in C(D)$. 
%		\begin{itemize}
%			\item Clearly if $\U(C,D,\omega):=\sup\{a(\omega)\given a\in C(D)\}$ then it is indeed valuable to be imprecise. In fact, then one should be maximally imprecise in all decisions, $C(D)=D$. 
%			\item CAN WE MOTIVATE THE NU VERSION THIS WAY???\todooldinfo{???}
%		\end{itemize} 
%		\item 
%		\item We restricted attention to deterministic picking strategies, picking a unique action for each decision. Some indeterministic, or probabilistic, picking strategies could be considered. These randomise over the various options that are not ruled out. 
%		\item You can select a choice function $C$, as a free choice, but then the question is how valuable that is for you, what will that lead you to choose? you might simply have uncertain opinions about what you'll pick if you're using choice function $C$. You could be precise
%	\end{enumerate}
%\end{colored}
%
%
%
%\begin{colored}{red}
%	In this paper so far, we have asked how a decision theory evaluates the picking strategies that are compatible with what the theory recommends for each decision. This was supposed to be motivated by asking whether the decision theory undermines its own recommendations.
%	
%	
%But our original question was whether the decision theories undermine themselves, which would involve evaluating the recommendations of the decision theory themselves rather than any particular picking function compatible with those recommendations.
%A closely related original question was whether the decision theory thinks that some other decision theory will lead the agent to better get to her goals of love/money/utility, which would require us to 
%
%
%But our original question was whether the decision theory undermines itself. Perhaps we should try to apply the decision theory to itself rather than picking strategies compatible with its recommendations. 
%
%
%\end{colored}


Up to this point, we have asked how a decision theory evaluates the picking strategies that pick for the choice function to which that decision theory gives rise. This is one way to answer the question whether the decision theory undermines its own recommendations, and we've seen that Allais-permitting decision theories fare poorly, as does $\Gamma$-Maximin both of which rule out as impermissible the strategy which they require; while E-Admissibility and Maximality fare better, as some compatible strategies are evaluated as acceptable (although not all). \todoold{check that}

However, other approaches are available too. We are interested in judging a decision theory as a means to your ends, and we have been using the proposed decision theory itself to do the judging, for it is, after all, a theory of which means to your ends are rational. Judging picking strategies that pick for the choice function that a decision theory produces furnishes us with a straightforward approach to this question, because they determine what the outcomes are: given a decision problem and a state of the world, the utility of a picking strategy is the utility, at that state of the world, of the act it picks from the decision problem. Since a decision theory doesn't always give definitive guidance on which act to pick when faced with a decision, we considered various strategies compatible with its recommendations; in our terminology, the strategies that pick for it. 
%But all of the decision theories we've been considering, but especially E-Admissibility and Maximality, don't always tell you exactly what you should do when faced with a decision; instead they rule out various options as impermissible, and often leave more than one remaining. As a result, there are many different picking strategies that pick for them. 
How else might we evaluate what a decision theory will lead you to do when there are various strategies %\todo{should it be 'strategies'?}
it leaves open?

We propose that you might have a precise probability over the acts the decision theory deems permissible---what we'll call a probabilistic picking strategy---and you might take the utility of this probabilistic picking strategy at a state of the world to be its expected utility at that world. There are two reasons you might think this is the right way to evaluate a decision theory: 

Firstly, you might think that, once your decision theory gives you its choice set, you will pick by applying some randomisation method, such as tossing a coin or rolling a die. Perhaps you think we are freely selecting amongst various randomisation methods as well as the choice functions to which your decision theory gives rise, or perhaps you think that, when selecting a choice function, it simply comes with a specified randomisation method. %This approach gives some pretty concrete guidance about how to turn a collection of available acts into a selection of what to do.% \todooldinfo{More about randomisation discussion??}


Secondly, you might think that, once your decision theory gives its choice set, you don't know what happens next, except that, in the end, you do in fact pick a particular act from that set. We then want to represent your uncertainty about how you'll end up picking when you've adopted a particular decision theory whose choice set is not a singleton. And it might just be that your uncertainty over how you'll pick is best represented by a precise probability. (In \cref{sect:IPpicking}, we will extend this to the case where your uncertainty over how you'll pick is imprecise.)

%In either of these, what we have is for each choice function $C$ and decision $D$, a probability function $\n^C_D$ over $C(D)$, the options from $D$ which are not ruled out by $C$ in this decision problem. We can then consider $\U(C,D,\omega)=\Exp_{\n^C_D} a(\omega)$. 

%\todoold{I'd like your judgements on whether these are the things you were thinking of here.}

Before discussing some alternatives, we will now show that under either of these ways of thinking about judging the outcomes of adopting a decision theory, all our previous claims carry over, and in fact in some cases even get worse since the strategies that align with expected utility theory arise from extremal picking strategies which we might want to rule out under this way of thinking. 


%Either way, what we formally have, is, for each decision problem $D$ and picking strategy $C$, some probability $\n$ over the options which are not ruled out by $C$. Then we have $\U(C,D,\omega)$ as $\Exp_{\n^C_D}[\U(a,D,\omega)]$; which we think of as your expected utility of having adopted the choice function $C$. 




\subsection{Probabilistic picking strategies}


We begin by extending our definitions:
\begin{definition}\label{def:nu stuff}\ 
	\begin{itemize}
		%\item %A \emph{choice function}, $C$, specifies for each decision which acts are choiceworthy, or perhaps not rejected, that is $C:\D\to\A$ such that $C(D)\subseteq D$ and $C(D)\neq\emptyset$. Examples are $\EU_p$, $\REU_p^r$, $\EAd_\IP$ and $\Maximin_\IP$, as defined throughout the parper. 
%		\item A  \emph{(deterministic) $C$ picking strategy} specifies an action compatible with $C$ for each $D$, that is where $\s(D)\in C(D)$
		\item %\todoold{name??? ``picking strategy''? ``probabilistic picking strategy''? ``picking expectation''}
		A \emph{probabilistic picking strategy} $\n$, specifies, for each decision problem, $D\in\D$, a probability function $\n_D$ over $D$, i.e., over the acts available in the decision problem $D$.
		% $\n$ is a function from $\D$ to probability functions over $\A$ which 
		\item For a choice function $\c$,  $\n$ \emph{picks for $\c$} iff for all $D\in\D$,  $\n_D(\c(D))=1$, i.e., it is certain that what it picks will be compatible with $C$'s recommendations.
		\item For a choice function $\c$, $\n$ \emph{$\mu$-surely picks for $\c$}, if $\mu\{D\given \n_D(\c(D))=1\}=1$.
 	\end{itemize}
\end{definition}
Observe that in the special case where $\n$ is extremal---that is, when for every $D$ it assigns all its probabilistic weight to an individual member of $D$---then we recover our original notion of a picking strategy. We will call these the \emph{deterministic} picking strategies. 

We add a further definition: 
\begin{definition}
%{\color{red}For a choice function $\c$,  \emph{$\n$ is regular for $\c$}, if, for each $D$ in $\D$: $\n_D(a) > 0$ iff $a \in \c(D)$.}
%{\color{violet}
For a choice function $\c$,  \emph{$\n$ is regular for $\c$}, if it picks for $\c$ and for every $D\in\D$ and $a\in\c(D)$, $\n_D(a)>0$. %\todo{not sure if it was quantifier order, but I fould old defn hard to read. }}
\end{definition}


%We will apply the choice function to evaluate strategies, or more generally, $\n$ too. \todooldinfo{JK to help!! is there a systematic thing to say about extending. See the Max section...???}

For a deterministic picking strategy, $\s$, we simply took its utility to be the utility of the act it requires you to pick: given a state of the world $\omega$ and a decision problem $D$, $\U(\s)(\omega,D):=\U(\s(D))(\omega)$, the utility of the act $\s(D)$ at $\omega$. For $\n$, we take its utility to be the \emph{expected} utility of the act it lead you to pick: given a state of the world $\omega$ and a decision problem $D$, $$\U(\n)(\omega,D):=\sum_{a \in D} \n_D(a)\U(a)(\omega).$$
\begin{comment}
\begin{colored}{violet}
	If we are allowing $D$ to be infinite (although compact), we should in fact take an integral, $\U(\n)(\omega,D):=\int_{a \in D} \U(a)(\omega)\,\n_D(\diff a).$\todoold{should we explicitly talk about finitely additive integrals?}
%	All our results merely require that $\n$ is finitely additive so in fact, we should be taking a Daniell integral, REFS.  $\U(\n)(\omega,D):=\int_{a \in D} \U(a)(\omega)\,\n_D(\diff a).$
\end{colored}
\end{comment}
% = \Exp_{\n_D}[\U(\omega)].$$ %We then have
%$$\EU_{p\times\mu}[\U(\n)]=\EU_{p\times\mu}\Exp_{\n_D}[\U(\omega)]$$%\todooldinfo{I'm not sure about the right notation}


We have thus far been assuming that decision problems $D$ are non-empty finite sets of acts. If we were to allow $D$ to be infinite (although compact), then we should have $\U(\n)(\omega,D):=\int_{D} \U(a)(\omega)\; \n_D(\diff a)$.

In the next few sections, we note how our earlier results concerning deterministic
%\todo{did say ``non-probabilistic''}
picking strategies generalize to probabilistic picking strategies.

We will judge whether a given decision theory considers a probabilistic picking strategy $\n$ to be impermissible. This will depend on the range of alternatives available. That is, we will be judging whether $\n$ is an impermissible picking strategy from a set of picking strategies, $\Nu$. 
There are various natural proposals for what $\Nu$ contains, depending on one's interpretation and applications of our results. 
When $\Nu$ consists just of extremal picking strategies, it is equivalent to the set of deterministic picking strategies, $\S$, which we considered in the first half of the paper. 
If you think you get to pick by randomisation, and can select any randomisation process, then $\Nu$ will be the collection of all probabilistic picking strategies.
If you think we are just evaluating choice functions, and each one just comes along with a single randomisation process (for example, a uniform distribution over its choice set), %\todo{I added the `uniform'},
then $\Nu$ will have a particular $\n^\c$ for each $\c$, where $\n^\c$ picks for $\c$. 
If  instead you are just uncertain over how you'll pick when using a choice function $\c$, and assume that this is a matter governed by a precise probability, then again we'll have a $\n^\c$ representing your probabilistic uncertainty over how you'll pick once you've selected a choice function $\c$ and are faced with a decision $D$.

\subsubsection{Expected Utility Theory}

	%\begin{colored}{violet}
Our results all transpose to the probabilistic setting for any choice of $\Nu$ with a particular feature: it contains some $\nu^\c$, for each relevant choice function $\EU_p$ or $\EU_{b(\cdot|-)}$.
%We will just need a structural requirement on $\negies$ for our results to hold, which will be satisfied in these various interpretations: 
\begin{definition}\label{def:EU-complete}
	A set of probabilistic picking strategies, $\Nu$:
	
	\begin{itemize}
		\item $\Nu$ is \emph{$\EU$-complete} if, for every probability $p$ over $\Omega$, there is some $\n$ in $\Nu$ such that $\n$ picks for $\EU_p$.
	
	\item $\Nu$ is \emph{conditional-$\EU$-complete} if, for every probability $b$ over $\Omega\times\Decs$, there is some $\n$ in $\Nu$ such that $\n$ picks for $\EU_{b(\cdot|-)}$.

		
	\item $\Nu$ is \emph{deterministically full} if $\Nu\supseteq\S$, that is, if $\Nu$  contains all the deterministic picking strategies. 
	\end{itemize}

		

	%	
	%A set of probabilistic picking strategies is \emph{$\EU$-complete (for $\IB$)} if, for each $p\times \mu\in \IB$, there is $\n$ in $\negies$ such that $\n$ $\mu$-surely picks for $\EU_p$.
\end{definition}
If it contains some $\nu^\c$ for every possible choice function then $\Nu$ is deterministically full. 
\begin{proposition}\label{thm:EU-complete}
 $\Nu$ is deterministically full
		$\implies$  $\Nu$ is  conditional-$\EU$-complete 
		$\implies$  $\Nu$ is  $\EU$-complete.
\end{proposition}

These conditions would fail if, for example, our agents were bounded in a particular way that would render them unable to act according to a specified choice function; but we are assuming that isn't our case. 

In fact, our results only need 	$\Nu$ is {$\EU$-complete for $\IB$} which we can define as: for every  $b\in \IB$, there is some $\n$ in $\Nu$ such that $\n$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$,  but in the main body of the paper we will state the results with the more general restrictions on $\Nu$.
	
%\end{colored}
	
	

%\begin{colored}{red}
%	In fact, for all the results, one only needs that $\Nu$ is sufficiently $\EU$-complete in that it contains a strategy which is $\mu$-surely an $\EU_p$ strategy for relevant $p$ and $\mu$. We don't think that such weakenings are significantly interesting, so we simply impose $\EU$-completeness for ease, noticing that it applies both when $\Nu$ is the collection of all deterministic strategies and when $\Nu$ is the collection of all probabilistic picking strategies. 
%\end{colored}


\Cref{thm:eu-self-rec,thm:eu-uniquely-optimal} extend to this setting.
Suppose $p$ is a probability over $\Omega$ and $\mu$ is a probability measure over $\D$.
\begin{proposition}\label{thm:eu-nu-nec-suff}
If $\Nu$ is $\EU$-complete, we have:
$$\n \in \EU_{p\times \mu}(\Nu) \Leftrightarrow \n \text{ $\mu$-surely picks for $\EU_p$.}$$
If $\Nu$ is conditional-$\EU$-complete, then
$$\n \in \EU_{b}(\Nu) \Leftrightarrow \n \text{ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$.}$$
\end{proposition}
This is proved in \Cref{sect:EU-appendix}.

\subsubsection{E-Admissibility}
\Cref{thm:ead-equiv[dep],thm:ead-existence[dep],thm:ead-existence[indep],thm:ead-existsimpermissible[indep],thm:ead-existsimpermissible[indep]} also generalise to the probabilistic picking strategy setting. 

%{\color{violet}For the remainder, we will assume that $\IB$ makes $\Omega$ and $\D$ strongly independent, i.e., every $B\in\IB$ has the form $p\times\mu$ for some probability $p$ over $\Omega$ and $\mu$ over $\D$.}

Since a probabilistic picking strategy is in $\EAd_\IB$ iff, for some $b$ in $\IB$, it is in $\EU_b$, we get as an immediate consequence of \cref{thm:eu-nu-nec-suff}:
\begin{proposition}\label{thm:ead-nu-nec-suff}
If for some $p\times \mu\in \IB$, $\n$ $\mu$-surely picks for $\EU_p$, then $\n\in\EAd_\IB(\Nu)$. More generally, if for some $b\in\IB$, $\n$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$, then $\n\in\EAd_\IB(\Nu)$. 

Moreover, these are the only members of $\EAd_\IB$, at least assuming that $\Nu$ is conditional-$\EU$-complete: 
$$\n \in \EAd_\IB(\Nu) \Leftrightarrow \text{for some $b$ in $\IB$, $\n$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$.}$$
%If $\IB$ is strongly complete, then: $\n \in \EAd_\IB(\negies) \Leftrightarrow \n \text{ $\mu$-surely picks for $\EU_p$, for some $p\times \mu$ in $\IB$.}
%\end{align}

%If $\negies$ is $\EU$-complete, then $$\n \in \EAd_\IB(\negies) \Leftrightarrow \n \text{ $\mu$-surely picks for $\EU_p$, for some $p\times \mu$ in $\IB$.}$$
\end{proposition}
This is proved in \Cref{sect:EAd-EU-appendix}.
%In fact, the former result does not depend on any features of $\IB$ such as the strong independence. 

%\begin{proposition}\label{thm:ead-nu-reg-nec}
%Suppose $\c$ is a choice function and, for every $p\times \mu\in \IB$,  $\mu\{D\given \c(D)\subseteq \EU_p(D)\}< 1$. Then, if $\n$ is a regular picking strategy for $\c$, then $\n\notin \EAd_\IB(\negies)$. \todooldinfo{let's amend this to just being an EAd version! Do we know how this would look???}
%\end{proposition}

	\begin{proposition}\label{thm:ead-nu-reg-nec}
		Suppose that $\Nu$ is conditional-$\EU$-complete.
		
Suppose that for every $b\in\IB$, $b_\D\{D\given \EAd_{\IB(\cdot|-)}(D)\subseteq\EU_{b(\cdot|-)}\}<1$. 

That is, for all $b\in \IB$, $b_\D\{D\given \text{there is $b'\in\IB$ with }\EU_{b'(\cdot|-)}(D)\not\subseteq\EU_{b(\cdot|-)}(D)\}>0$. 
		
%	Suppose that for every $p\times \mu\in \IB$, $\mu\{D\given \EAd_\IP(D)\subseteq \EU_p(D)\}\neq 1$. That is, for all $p\times \mu\in \IB$, $\mu\{D\given \text{there is $p'\in\IP$ with }\EU_{p'}(D)\not\subseteq\EU_p(D)\}>0$. 
		
	Then, if $\n$ is a regular picking strategy for $\EAd_{\IB(\cdot|-)}$, then $\n\notin \EAd_\IB(\Nu)$.
	\end{proposition}
	



%The antecedent of the final part of the theorem ensures that $\IP$ is actually imprecise and that you think you'll be faced with a decision where this matters. In which case, then the $\n$ will not be an $\EU_p$ picking strategy for any $p\in\IP$, and moreover, will not be $\mu$-surely an $\EU_p$ picking strategy for any $p\times \mu\in \IB$. 


%Let's see the final part of this theorem at work in a very simple example. 
%Consider the Ellsberg setup, \cref{sect:Ellsberg} and suppose that you're in fact certain that you'll face decision problem $D^{\mathrm{Ellsberg}}_1=\{\text{1A, 1B}\}$. And you have a credal set $\{\}
%Suppose you're certain you'll face a decision problem $D = \{a_1, a_2\}$. So $\mu(D) = 1$. Suppose $\IP = \{p_1, p_2\}$, where $p_1$ expects $a_1$ to be strictly better than $a_2$, while $p_2$ expects $a_2$ to be strictly better than $a_1$. So E-Admissibility with $\IP$ says that both $a_1$ and $a_2$ are choiceworthy. Then for any picking strategy $\n$ such that $\n_D$ gives positive probability to $a_1$ and $a_2$, $p_1$ doesn't expect it to be best, and nor does $p_2$. So, by E-Admissibility, that picking strategy is not rationally permissible.
This is proved in \Cref{sect:appendix:eadundermining}.

Let's see this at work. Consider again the Ellsberg setup, \cref{sect:Ellsberg}. Recall that $\EAd_\IP(D^{\mathrm{Ellsberg}}_1)=\{\text{1E,1F}\}$ and $\EAd_\IP(D^{\mathrm{Ellsberg}}_2)=\{\text{2E,2F}\}$. 
Every probability in $\IP$ rules out at least one of the E-Admissible options as impermissible. For example, any $p(\emph{Black})>\nicefrac{7}{30}$ rules 1E as excluded, i.e., not in $\EU_p$, but there's some positive chance that $\n_{D^{\mathrm{Ellsberg}}_1}$ picks 1E, by the assumption that it is regular for $\EAd_\IP$. 
Thus, $\n$ does not pick for $\EU_p$. It also does not even $\mu$-surely pick for $\EU_p$ if we assume that each $\mu$ assigns positive probability to both $D^{\mathrm{Ellsberg}}_1$ and $D^{\mathrm{Ellsberg}}_2$. It is thus not E-Admissible. 

In fact, if $\IP$ is allowed to be non-convex, we get cases where $\n$ will be judged as impermissible even when you know what decision problem you'll be faced with.\footnote{These examples are avoided when $\IP$ is convex as then there will be  a probability $p^*\in\IP$ which is indifferent between the two actions, and thus, $\n\in\EU_{p^*}(\Nu)$.} %\todo{ref: Bayes for p not defined. C: changed it.}
Suppose you're certain you'll face a decision problem $D = \{a_1, a_2\}$. So $\mu(D) = 1$. And suppose $\IP = \{p_1, p_2\}$, where $p_1$ expects $a_1$ to be strictly better than $a_2$, while $p_2$ expects $a_2$ to be strictly better than $a_1$. So E-Admissibility with $\IP$ says that neither $a_1$ or $a_2$ are rejected. Then for any regular picking strategy for $\EAd_\IP$, $\n_D$ will give positive probability to both $a_1$ and $a_2$. $p_1$ doesn't expect it to be best, and nor does $p_2$. So, by E-Admissibility, $\n$ is not rationally permissible.
\todoold{double check wording of above. And make it match JKs eg}


%And the same will happen for any $\IB$ such that, for each $\seq{p, \mu} \in \IB$, $\mu\{D\given \EAd_\IP(D)\subseteq \EU_p(D)\}< 1$.



\begin{comment}
So, at least when we consider regular probabilistic picking strategies, things have become pretty bad for E-Admissibility: given some reasonable constraints on your uncertainty about the decision problem you'll face, the regular probabilistic picking strategies that pick for E-Admissibility are not themselves E-Admissible. And so, in this sense, E-Admissibility is self-undermining.

{
	There is a more fundamental point here: however one is going to judge choice functions, each probability, $p$, will think that $\EU_p$ is optimal; and so E-Admissibility will only judge expected utility theory as acceptable. When we considered (deterministic) strategies, we were accepting $\EU$ strategies as E-Admissibility strategies, so had some E-Admissibility strategies evaluated as E-Admissible. However, if we are judging the choice function by assigning a single evaluation of it, taking the imprecision into account, it will distinguish it from expected utility theory,  and thus all probability functions will think something else is better, namely being $\EU_p$ for the $p$ doing the evaluation; and thus, E-Admissibility is not itself E-Admissible. 
	}

\end{comment}
%\todooldinfo{Was there more in v14b to be brought back??}



	
	
		One motivation for introducing probabilistic picking strategies, and in particular regular probabilistic picking strategies, was to judge an agent's decision theory as a means to her ends. We wished to give a particular judgement of how good it would be to adopt a given decision theory, rather than simply leaving open a whole range of picking strategies, which represent a range of different ways of implementing that theory.
	If this is how we are trying to judge E-Admissibility, then E-Admissibility is self-undermining.
	For example, if one picks amongst the non-rejected options by randomisation, with a regular randomisation device, then E-Admissibility deems it impermissible. 
	The defender of E-Admissibility will argue that one shouldn't select by randomisation, and also shouldn't have uncertainty over how one picks in a way which amounts to randomisation. 
	Instead, the defender of E-Admissibility will highlight that it sees value in coordinating how you resolve incomparability. Randomisation, or anything that amounts to that, just won't do. 
	%\todooldinfo{yes, this was JKs stuff. I am still spiritially trying to say what I had said. }
	
	The point is a general one.  If you try to give any way of scoring, or measuring the utility of choice functions or decision rules at each world and at each decision problem, then you can only avoid being ruled out as impermissible by the lights of E-Admissibility if your rule is equivalent to expected utility theory. 
% \todooldinfo{this new}


\subsubsection{Maximality}\label{sect:nu:Max}


As in \cref{sect:Max}, since Maximality is more permissive than E-Admissibility, all $\EU_p$ strategies are evaluated as acceptable according to Maximality. We thus have, as a corollary to \cref{thm:eu-nu-nec-suff}, and extending \cref{thm:max-suff}:
\begin{proposition}\label{thm:max-nu-suff}
		If for some $p\times\mu\in \IB$, $\n$ $\mu$-surely picks for $\EU_{p}$, then $\n\in\Maximality_\IB(\Nu)$. 
		
		More generally, if for some $b\in \IB$, $\n$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$, then $\n\in\Maximality_\IB(\Nu)$. 
\end{proposition}
This is proved in \Cref{sect:maximality-appendix}.

For E-Admissibility, we were able to show that it is only these strategies that are judged acceptable by the decision theory. This result does not immediately apply to Maximality in a similar way because, for a strategy to be deemed impermissible, the various probabilities $b\in \IB$ have to agree on a particular alternative as better.

However, if we impose an additional restriction on $\IB$ we can obtain an analogous result: suppose your credence over which decision you'll face is given by a single, \emph{precise} probability, $\mu^*$, and that $\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$. All our results equally apply when $\IB$ is the convex hull of this, since taking a convex hull doesn't affect which acts are rejected by Maximality. But, if $\IP$ is convex, then $\{p\times\mu^*\given p\in\IP\}$ is also convex (since $\mu^*$ is fixed), and so we do not bother presenting this strengthening. 
\todoold{check!!!}


We will also place a further condition on $\mu^*$:
\begin{definition}\label{def:suff spread}
	$\mu^*$ \emph{requires almost everywhere decisiveness} iff for all probabilities $p$,$$\mu^*\Set{D\given \EU_p(D)\text{ is a singleton}}=1.$$ 
\end{definition}
That is, for each probability function $p$, $\mu^*$ is certain you'll face a decision problem in which only one act maximizes expected utility. That is, the set of decision problems in which there are ties for expected utility has measure 0.
For example, fix a proposition and suppose you will face the choice between paying $\pounds t$ for a bet that pays out $\pounds 1$ if the proposition is true and $\pounds 0$ if it is false, for unknown $t$ in $[0, 1]$. Then, if $\mu^*$ is a measure that assigns strictly positive weight to every non-degenerate interval $[x,y] \subseteq [0, 1]$, then $\mu^*$ requires almost everywhere decisiveness. Whatever your probability in the fixed proposition, the set of decisions of this form in which buying the bet and rejecting the bet have equal expected utility has measure 0 by the lights of $\mu^*$.
%Suppose you have any coherent rejection function over $\Omega$. 

%Wald gives us a very strong result linking being Bayes to be 

Then we have the following result.%
\footnote{{The assumptions on $\mu^*$ are not required if one instead assumes that $\Nu$ is convex, which is motivated when one considers randomisations as available options. If $D$ was allowed to be infinite, one should also ensure that $\Nu$ is closed, 
%		However, one should usually only apply these decision theories to compact sets, otherwise all options can be rejected, so we should ensure that $\negies$ is also closed,
		 for which one needs to allow merely finitely additive randomisations \citep{schervish2020finite}.}}
\begin{proposition}\label{thm:max-nu}Suppose $\Nu$ is $\EU$-complete. Suppose that 
	$\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$ and $\mu^*$ requires almost everywhere decisiveness.
	Then if $\n \in \Maximality_\IB(\Nu)$, then there is some probability $p$ such that $\n$ $\mu^*$-surely picks for $\EU_p$.%\todo{did we know that $p$ in $\IP$??}
	\todoold{I removed the converse because I don't know if the probability has to be in the original set, not sure if that follows from the Wald..???}
\end{proposition}
This is proved in \Cref{sect:wald:appendix}. It follows from a version of Wald's Complete Class Theorem. Using that, we show that, if $\n$ is not in $\EU_{p\times\mu^*}$ for any $p$, then there is some alternative $\n'$---in fact, an alternative $\n'$ that picks for some $\EU_p$---such that $\Exp_{\mu^*}[\U(\n')(\omega)]>\Exp_{\mu^*}[\U(\n)(\omega)]$ for all $\omega$, and thus for all probabilistic $p$, $\Exp_p[\Exp_{\mu^*}[\U(\n')]]>\Exp_p[\Exp_{\mu^*}[\U(\n)]]$, i.e., $\Exp_{p\times \mu^*}[\U(\n')]>\Exp_{p\times\mu^*}[\U(\n)]$. It follows that $\n\notin\Maximality_\IB(\Nu)$. 
	
%	\todooldinfo{Either we incldue a ref to SSK's finite randomisation stuff or we drop the comment that $\negies$ is convex. }
	
%	The assumptions on $\mu^*$ are not required if one instead assumes that $\negies$ is convex, which is motivated when one considers randomisations as available options. However, one should usually only apply these decision theories to compact sets, otherwise all options can be rejected, so we should ensure that $\negies$ is also closed, for which one needs to allow merely finitely additive randomisations. \todoold{ref to SSK ``what finadd''}
	

	
%	 If $\n$ is not Bayes\todooldinfo{here!}
%	If $\n$ does not $\mu^*$-surely pick for $\EU_p$ for any probability $p$, then by \cref{thm:eu-nu-nec-suff}, $\n\notin \EU_{p\times\mu^*}(\negies)$. We can then use a version of Wald's Complete Class Theorem to show that there is some $\n'$ where $\Exp_{\mu^*}[\U(\n')(\omega)]>\Exp_{\mu^*}[\U(\n)(\omega)]$ for all $\omega$, and thus for all $p$, $\EU_{p\times\mu^*}\U(\n')>\EU_{p\times\mu^*}\U(\n)$, so $\n\notin\Maximality_\IB(\negies)$. 
%	What we can show is that if $\n$ is such that there is no probability function with $\Exp_{p}\Exp_{\mu^*}[\U(\n)]$
%	 which shows that non-Bayes options are dominated. We 
%%	Using this, we show that if $\n$ is not Bayes for any 
%	if $\s$ does not $\mu^*$-surely pick for $\EU_p$, for some $p$ in $\IP$, then there is an alternative strategy $\s^*$ such that $\Exp_{\mu^*}[\U(\s)(\omega)] < \Exp_{\mu^*}[\U(\s^*)(\omega)]$, for each $\omega\in \Omega$; and thus also, $\Exp_{p\times\mu^*}[\U(\s)] < \Exp_{p\times \mu^*}[\U(\s^*)]$ for all $p\in\IP$ and thus $\s$ not in $\Maximality_\IB(\negies)$. }

The set $\S$ of all deterministic picking strategies discussed in the earlier part of the paper is EU-complete, and so we obtain the result that we hinted at in \cref{sect:Max}, namely, that if we have $\IB$ that satisfies the conditions of \Cref{thm:max-nu}, then it is only $\EU_p$ strategies that are in $\Maximality_\IB(\S)$. And so, if we have $\IB$ that satisfies those conditions, we can appeal to \Cref{thm:ead-existsimpermissible[dep]}, together with the fact that E-Admissibility is at least as permissive as Maximality, to give sufficient conditions under which there is a deterministic strategy $\S$ that picks for $\Maximality_{\IP}$ but that does not belong to $\Maximality_\IB(\S)$.

\begin{proposition}\label{thm:max-existsimpermissible[dep]}
	Suppose $\Nu$ is $\EU$-complete. Suppose that 
	$\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$ and $\mu^*$ requires almost everywhere decisiveness.

	
	Suppose there is a selection of pairwise disjoint events $E_q\subseteq\Decs$, one for each $q\in\IP$ (some of which may be empty), such that for all $p\in\IP$, 
	\[
	\mu^*\left(\bigcup_{q\in\IP}\{D\in E_q\given \EU_p(D)\cap\EU_q(D)=\emptyset\}\right)>0
	\]
	
	Then there is $\s$ which picks for $\Maximality_\IP$ but which is not in $\Maximality_\IB(\S)$. 
\end{proposition}


\begin{colored}{blue}
We can also apply the same trick to \cref{thm:seed-suff-impermissible-strat}:


\begin{proposition}\label{thm:max-seed-existsimpermissible}
	Suppose $\Nu$ is $\EU$-complete. Suppose that 
	$\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$ and $\mu^*$ requires almost everywhere decisiveness.

Suppose that for any $p\in\IP$, $\mu^*(U_b)>0$ where 
\[
U_p:=\bigl\{D\in\Decs\given \Maximality_\IP(D)\not \subseteq\EU_{p}(D)\bigr\}.
\] 
Suppose further that there is some measurable statistic $r:\Decs\rightarrow[0,1)$ such that for any $p\in\IP$ and any open interval $I\subset[0,1)$, 
\[
\mu^*\bigl(\,D\in U_p\given r(\Maximality_\IP(D))\in I \bigr)>0.
\]
Then there is $\s$ which picks for $\Maximality_\IP$ but which is not in $\Maximality_\IB(\S)$. 
\end{proposition}


Given the conditions of \Cref{thm:max-nu}, there are additional natural richness conditions that guarantee the existence of deterministic $\s$ that pick for $\Maximality_{\IP}$ but do not belong to $\Maximality_\IB(\S)$. For example:


\begin{proposition}\label{thm:atomless-existsimpermissible}
	For any choice function $\c$, if $\mu^*$ is atomless and for all $p\in\IP$, $\mu^*\{D\given \c(D)\subseteq\EU_p(D)\}<1$, then there is $\s$ which picks for $\c$ but for no $p$ does it $\mu^*$-surely pick for $\EU_p$. 
\end{proposition}




This is proved in \Cref{sect:wald-app:appendix}.


As an immediate corollary of \cref{thm:max-nu} and \cref{thm:atomless-existsimpermissible} we have:

\begin{corollary}\label{thm:atomless-max-existsimpermissible}
	Suppose $\Nu$ is $\EU$-complete. Suppose that 
	$\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$ and $\mu^*$ requires almost everywhere decisiveness.

	If $\mu^*$ is atomless and for all $p\in\IP$, $\mu^*\{D\given \Maximality_\IP(D)\subseteq\EU_p(D)\}<1$, then there is $\s$ which picks for $\Maximality_\IP$ but which is not in $\Maximality_\IB(\S)$. 
	\end{corollary}




\end{colored}


Just as we got a more challenging result for E-Admissibility when we restricted attention to \emph{regular} picking strategies, as these won't look like $\EU_p$ strategies, similarly we get a more challenging result for Maximality when we restrict to regular picking strategies because such regular picking strategies will not $\mu^*$-surely pick for any $\EU_p$, unless Maximality just collapses to $\EU_p$ for some $p$, or at least $\mu^*$-surely does so.
%We get a more interesting challenge for Maximality, though, if we restrict attention to regular picking strategies. This is relevant when we are trying to use probabilistic picking strategies to evaluate the utility of using the decision theory. 

%\todo{We're not even stating the existence of such statregies claim. Isn't that weird?? Perhaps it accidently got removed somewhen?}

\begin{proposition}\label{thm:max-nu-reg-nec}
	Suppose $\Nu$ is $\EU$-complete. 
	Suppose that $\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$ and $\mu^*$ requires almost everywhere decisiveness. Suppose that for every probability $p$, $\mu^*\{D\given \Maximality_\IP(D)\subseteq\EU_p(D)\}< 1$.\footnote{Equivalently, that for every probability $p$ there is a non-negligible set of decision problems for which there is some $a\in D$ which is not an $\EU_p$ act but which is Maximal: $\mu^*\{D\given \exists a\in D\left[(\exists b{\in} D \, \Exp_{p}(a)<\Exp_{p}(b))\text{ and }\forall b{\in} D\, \exists p'{\in}\IP \,\Exp_{p'}(b)\leq \Exp_{p'}(a)\right]\}>0$} %\todo{this might actaully need to say every p rather than every p in P, no??? It's supposed to say, it's not an EU strategy, so that we can use the fact that it does not mu surely pick for any EUp???!!!}
Then, if $\n$ is a regular picking strategy for $\Maximality_\IP$ then $\n\notin \Maximality_\IB(\Nu)$.
%\todo{do we also state that there is a strategy ruled out? Is it affected by our issues with EAd?}
\end{proposition}
This is proved in \Cref{sect:wald:appendix}.


	The lesson from this result is that you should not pick amongst the options that are not ruled out by applying a (regular) randomisation device; nor should you be uncertain over how you'll pick in a way which amounts to randomisation; at least when your opinions over which decision problem you'll face are precise and require almost everywhere decisiveness. 
	Just as with E-Admissibility, the defender of Maximality will argue that this is the right answer. In cases like this, you should coordinate how you resolve incomparability. There are reasons for rejection at the scale of picking strategies---reasons grounded in the (putative) value of coordination---that are not reasons for rejection at the scale of actions or options. 
	
	%	One's account of imprecise decision making has to say something more sophisticated about how one should pick.
\todoold{I rewrote this from JKs comment}
%{\color{red}The same sorts of considerations that potentially diffuse this challenge for E-Admissibility also diffuse it for Maximality.}



%Our core result is that if $\n$

%{\color{violet}This isn't unique to Maximality. It also doesn't depend on any strong independence condition. What we actually show is that if $\n$ is not Bayes, then there is $\n'$ such that $\Exp_{\mu^*}[\U(\n)(\omega)]<\Exp_{\mu^*}[\U(\n')(\omega)]$ for all $\omega$. So if $\c$ is any choice function allowing some non-$\EU_p$ strategies, then any regular $\n$ gives some positive probability to these non-$\EU_p$ options; which are thus not Bayes and thus dominated in expectation by some alternative. }
%
% It will hold for all {
%	\color{orange} manner of choice functions. 
%
%	For a choice function $\c$, let $\c_{\mu^*}$ be an extension of $\c$ to $\Omega\times \D$ which treats $\D$ as being governed by the precise probability $\mu^*$ and respects dominance, i.e., if $\Exp_{\mu^*}[\U(\n)(\omega)]<\Exp_{\mu^*}[\U(\n')(\omega)]$ for all $\omega\in\Omega$, then $\n\notin \c_{\mu^*}(\negies)$. 
%	}
%	\todooldinfo{Qu again for JK if this formulation is right}
%
%\begin{proposition}\label{thm:chiocefns-nu-reg-nec}	
%		Suppose $\negies$ is $\EU$-complete.  
%	Suppose that $\mu^*$ requires almost everywhere decisiveness and is countably additive.
%	
%	Suppose $\c$ is a choice function and, for every $p\in\IP$, $\mu\{D\given \c(D)\subseteq\EU_p(D)\}< 1$. 
%	
%	Then, if $\n$ is regular picking strategy for $\c$ then $\n\notin \c_{\mu^*}(\negies)$.\todoold{check this}
%\end{proposition}
%
%This will apply to $\Gamma$-Maximin:
%\begin{proposition}\label{thm:gamma}
%	Suppose $\negies$ is $\EU$-complete.  
%Suppose that $\mu^*$ requires almost everywhere decisiveness and is countably additive.
%
%Suppose that for every $p\in\IP$, $\mu^*\{D\given \Maximin_\IP(D)\subseteq\EU_p(D)\}< 1$. 
%
%Then, if $\n$ is regular picking strategy for $\Maximin_\IP$ then $\n\notin \Maximality_\IB(\negies)$, where 	$\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$. 
%\end{proposition}

\subsubsection{$\Gamma$-Maximin}


\begin{colored}{blue}
Since $\Gamma$-Maximin is a more restrictive theory than Maximality, for a strategy to be $\Gamma$-Maximin there must be some probability function $p$ % \todo{why in IP???}
for which the strategy $\mu^*$ surely picks for
% \todo{eg here should we replace?? I did so... changed order of quantifier}
$\EU_p$. As a result we have:

\begin{proposition}\label{thm:gamma-nu}
	Suppose $\Nu$ is $\EU$-complete. 
	Suppose that $\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$ and $\mu^*$ requires almost everywhere decisiveness. 
	
Suppose that for all $p\in\IP$, $\mu^*(U_p)>0$ where 
\[
U_p:=\bigl\{D\in\Decs\given \Gamma_\IP(D)\not \subseteq\EU_{p}(D)\bigr\}.
\] 
Then, if $\n$ is a regular picking strategy for $\Maximin_\IP$ then $\n\notin \Maximin_\IB(\Nu)$.
	\end{proposition}

This is proved in \Cref{sect:wald-app:appendix}.

We can also use \cref{thm:seed-suff-impermissible-strat} and \cref{thm:atomless-existsimpermissible} to that there are deterministic strategies $\s$ that pick for $\Gamma_{\IP}$ but do not belong to $\Gamma_\IB(\S)$.


%Given this, \cref{thm:seed-suff-impermissible-strat} yields:


\begin{corollary}\label{thm:gamma-seed-existsimpermissible}
	Suppose $\Nu$ is $\EU$-complete. Suppose that 
	$\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$ and $\mu^*$ requires almost everywhere decisiveness.

Suppose that for any $p\in\IP$, $\mu^*(U_p)>0$ where 
\[
U_p:=\bigl\{D\in\Decs\given \Gamma_\IP(D)\not \subseteq\EU_{p}(D)\bigr\}.
\] 
Suppose further that there is some measurable statistic $r:\Decs\rightarrow[0,1)$ such that for any $p\in\IP$ and any open interval $I\subset[0,1)$, 
\[
\mu^*\bigl(\,D\in U_p\given r(\Gamma_\IP(D))\in I \bigr)>0.
\]
Then there is $\s$ which picks for $\Gamma_\IP$ but which is not in $\Gamma_\IB(\S)$. 
\end{corollary}


Likewise, \cref{thm:atomless-existsimpermissible} yields:

\begin{corollary}\label{thm:atomless-gamma-existsimpermissible}
	Suppose $\Nu$ is $\EU$-complete. Suppose that 
	$\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$ and $\mu^*$ requires almost everywhere decisiveness.

	If $\mu^*$ is atomless and for all $p\in\IP$, $\mu^*\{D\given \Gamma_\IP(D)\subseteq\EU_p(D)\}<1$, then there is $\s$ which picks for $\Gamma_\IP$ but which is not in $\Gamma_\IB(\S)$. 
	\end{corollary}




\end{colored}


Even if a strategy $\mu^*$ surely picks for some $\EU_p$, it may nonetheless be impermissible according to $\Gamma$-Maximin, as we saw, for example, in the Ellsberg case (\cref{sect:gamma}) where the only strategy compatible with $\Gamma$-Maximin was judged impermissible by the theory itself. 


		
%	Unlike in the case for Maximality, though, we do not have the corresponding existence, and often those picking functions which $\mu$-surely pick for $\EU_p$ are nonetheless ruled impermissible by $\Gamma$-Maximin, as we saw, for example, in the Ellsberg case (\cref{sect:gamma}). 
	


%Since these results only assume that $\negies$ is $\EU$-complete, it applies also when $\negies$ is $\S$, the deterministic strategies discussed in the first half of the paper.\todoold{check if this is already stated elsewhere}

\todoold{The idea of N being closed and convex has now totally been deleted. }
\begin{comment}
	If you take $\negies$ to consist of all probabilistic picking strategies, then we in fact do not need the requirement that $\mu^*$ requires almost everywhere decisiveness (or countable additivity). 
The conclusions of \cref{thm:max-nu,thm:max-nu-reg-nec} hold without the assumption that $\mu^*$ requires almost everywhere decisiveness or is countably additive if we instead assume that $\negies$ is convex, i.e., that it contains any (finite) mixtures of members of $\negies$. 
\begin{proposition}Suppose that $\negies$ is $\EU$-complete and convex.\todooldinfo{Actually we should be careful: if $\negies$ is convex but not closed then it is non-compact and our decision theories aren't even defined for it!!!}
	
	Let $\IB$ have the form $\{p\times \mu^*\given p\in\IP\}$
	
	If for every $p\in\IP$, $\mu^*\{D\given \Maximality_\IP(D)\subseteq\EU_p(D)\}< 1$ and $\n$ is a regular picking strategy for $\Maximality_\IP$, then $\n\notin\Maximality_\IB(\negies)$.
%	
%	And, more generally, 
%	If for every $p\in\IP$, $\mu^*\{D\given \c(D)\subseteq\EU_p(D)\}< 1$ and $\n$ is a regular picking strategy for $\c$, then $\n\notin\c_{\mu^*}(\negies)$.
%	
%
\end{proposition}
\end{comment}

%We in fact also have a result that does not assume that $\mu^*$ requires almost everywhere decisiveness or countably additive, although we still do need the assumption that you think which decision you're faced with is captured with a precise probability. In this case, instead of assuming that $\negies$ is $\EU$-complete, we assume that it is convex, that is, whenever it contains two picking strategies, it contains any mixture of them. 
%
%\begin{proposition}
%	The conclusions of \cref{thm:max-nu,thm:max-nu-reg-nec} hold without the assumption that $\mu^*$ requires almost everywhere decisiveness or countably additive if we instead assume that $\negies$ is convex. 
%\end{proposition}
%
%This version of the result might be the most relevant if you conceive of picking strategies as combining choice rules and randomization procedures. That is, the choice rules narrow down the set of permissible acts, and then the picking strategies assign chances to those permissible acts. In this case, it's plausible that the set of randomization procedures you might be able to use is convex.



	\subsubsection{Uncertainty about decisions}
	\todo{change from paragraph to something else. }
	For both these Maximality and $\Gamma$-Maximin results, we have had to assume something particular about your uncertainty concerning the decision you'll face: we assume you have precise probabilities over the possible decision problems, and those probabilities are broad enough to ensure that they require almost everywhere decisiveness. It is, however, quite general, applying in a much broader range of cases than particular uncertainty generated from specific cases like the Ellsberg or Allais cases (see \cref{sect:reu:other mu}).
	
%	There may be some Maximality picking strategies that do not amount to picking in accordance 
	
%	Like in \cref{sect:reu:other mu}, these results hold when we assume something about your uncertainty concerning the decision you'll face: we assume you have precise probabilities over the possible decision problems, and those probabilities are broad enough to ensure that they require almost everywhere decisiveness. 
	It seems troubling enough that, should you acquire sufficient evidence to become uncertain about the decision problems you'll face in a way that is represented by precise probabilities, you would have to abandon the decision theory or the picking strategy you're using. 


	
	\subsection{Alternatives}
%	We proposed using probabilistic picking strategies, $\n$ in evaluating a decision theory. 
	
	\subsubsection{Imprecise picking strategies}\label{sect:IPpicking}
	So far, we've used decision theories to judge deterministic picking strategies, $\s$, and probabilistic picking strategies, $\n$. 
	But perhaps the proponent of imprecise probabilities thinks the way you pick is better represented by imprecise probabilities, indeed, a set of probabilistic picking strategies. 
%	Perhaps, it is the set of all strategies that pick for the choice function, $\c$. 
	

	Since E-Admissibility requires coordinating, and rejects all strategies except for those  equivalent to $\EU_p$ strategies, perhaps it is the set of all these $\EU_p$ strategies that E-Admissibility recommends. Can we apply E-Admissibility itself to judge this proposal? 
	
	
	To do this, we might extend E-Admissibility so that it judges what we might call imprecise acts, where we represent an imprecise act as a set of acts. So the imprecise acts available in decision problem $D$ is any $\mathbb{A}\subseteq D$. For instance, the set of all the $\EU_p$ strategies is such an imprecise act in the decision problem containing all the possible strategies.

	
%	A formally equivalent account arises if one thinks of assigning the utility of an imprecise choice function as the set of the utilities of all the compatible actions. 
%	This might also be proposed as an account of how to specify the utility of a choice function: it is an imprecise matter, the set of the utilities of all the options that are not ruled out. 


%		We can 
%	These are imprecise acts, and it is imprecise what utility they lead to. 
	%How might we apply our theories of imprecise probability to judge such imprecise acts, where it is imprecise what utility they lead to? 	We can understand an imprecise act as a set of acts. 
	For precise acts, E-Admissibility rejects an act when, for every $p$ in $\IP$, there is some alternative act $a'$ that $p$ expects to do better. When extending E-Admissibility to judge imprecise acts, we have to ask what it means for $p$ to expect an imprecise act $\mathbb{A}'$ to do better than $\mathbb{A}$. 
	
	A first suggestion is to say that $p$ expects $\mathbb{A}'$ to do better than $\mathbb{A}$ when, for every $a\in\mathbb{A}$ and $a'\in\mathbb{A}'$, $\Exp_p[\U(a')]>\Exp_p[\U(a)]$. This is a very hard condition to meet, so very few imprecise acts will be ruled out as impermissible on this basis. This can already rule as impermissible any imprecise picking strategy each of whose members is a regular picking strategy for $\EAd_\IP$, but it does not deem impermissible the imprecise act consisting of all picking strategies or all $\EU_p$ strategies, our motivating idea for imprecise picking strategies. 
	
	Alternatively, one might say that $p$ expects $\mathbb{A}'$ to do better than $\mathbb{A}$ when, for every $a\in\mathbb{A}$ and $a'\in\mathbb{A}'$, $\Exp_p[\U(a')]\geq\Exp_p[\U(a)]$, and there is some $a\in\mathbb{A}$ such that for all $a'\in\mathbb{A}'$, $\Exp_p[\U(a')]>\Exp_p[\U(a)]$.\footnote{Or perhaps this second disjunct should say that there is some $a\in\mathbb{A}$ and $a'\in\mathbb{A}'$ with $\Exp_p[\U(a')]>\Exp_p[\U(a)]$, but since our application of interest satisfies the slightly stronger property, we merely impose that. }
	This condition generates a version of E-Admissibility for imprecise acts which rules as impermissible the set of all picking strategies for $\EAd_\IP$. 
	
	This criterion rules out the imprecise picking strategy that consists of the set of all $\EU_p$ strategies, unless they all $\mu$-surely pick for $\EU_p$ for a single $p \times \mu\in\IB$. 
%	Using this, we rule out any imprecise picking strategy whose members do not all $\mu$-surely pick for $\EU_p$, for a single $p\times\mu\in\IB$.
%	Using this, we get a result paralleling that for precise picking strategies: to avoid being ruled out as impermissible, one's strategy needs to $\mu$-surely be an $\EU_p$ strategy for some $p\times\mu\in\IB$. (Or equivalently for the conditional version.)
	Suppose $\imprecpickstrat$ is a set of picking strategies, and there is no $p \times \mu$ in $\IB$ such that all strategies in $\imprecpickstrat$ $\mu$-surely pick for $\EU_p$; then each probability $b=p\times \mu$ evaluates the precise picking strategy $\{\n^p\}$, where $\n^p$ picks for $\EU_p$, to be better, in this sense: for every $\n\in\imprecpickstrat$, $\Exp_p[\U(\n)]\leq \Exp_p[\U(\n^p)]$, and there is some $\n\in\imprecpickstrat$ with $\Exp_p[\U(\n)]<\Exp_p[\U(\n^p)]$. 
%	 
%	 	It is, however, already strong enough to rule out an imprecise picking strategy for $\EAd_\IP$ which is regular, i.e., where every $\n\in\imprecpickstrat$ is a regular picking strategy for $\EAd_\IP$. This is because, for each $\n\in\imprecpickstrat$, $\Exp_{p\times\mu}[\U(\n)]\leq\Exp_{p\times\mu}[\U(\n^p)]$, where $\n^p$ picks for $\EU_p$, and there is some $\
%	 	and thus, $b=p\times\mu$ evaluates the precise picking strategy $\{\n^p\}$ to be better, in this sense; so $\imprecpickstrat$ is deemed impermissible by this extension of E-Admissibility.  
	
	%\todooldinfo{check that again}



%	These are imprecise acts, and it is imprecise what utility they lead to. How might we apply our theories of imprecise probability to judge such acts?
%	
%	We understand an imprecise act as a set of precise acts. So the imprecise acts available in decision problem $D$ is any $\mathbb{A}\subseteq D$. Suppose that $\mathbb{A}$ has the following feature: for every probability $p$ in one's credal set $\IP$, there is some alternative $\mathbb{A}'$, such that $\Exp_p[\U(a)]<\Exp_p[\U(a')]$ for all $a\in\mathbb{A}$ and $a'\in\mathbb{A}'$. Then, we propose that an extension of E-Admissibility to judge imprecise acts would deem $\mathbb{A}$ as impermissible. This is a very hard condition to meet, so only a few imprecise acts are deemed impermissible on this basis.
%	
%	It is already strong enough to rule out any set of regular probabilistic picking strategies for $\EAd_\IP$. 
%%	In our case, a set of probabilistic picking strategies, $\imprecpickstrat$, is not deemed impermissible in this way iff there exists some $\n\in\imprecpickstrat$ which $\mu$-surely picks for some $\EU_p$, for some $p \times \mu$ in $\IB$. But this is already strong enough to rule out any imprecise picking strategies which only contain regular probabilistic picking strategies. 
%	This is because each probability $p\times\mu$ in $\IB$ will evaluate every such regular $\n\in\imprecpickstrat$ to be worse than a $\EU_p$ strategy, $\n^p$ (by \cref{thm:ead-nu-reg-nec}). So for each $b$ in $\IB$, there is an alternative $\imprecpickstrat_p=\{\n^p\}$, where $\n^p$ picks for $\EU_p$ which is preferable. 
%	
%	However, we won't apply when we try to judge E-Admissibility by looking at the set of all picking strategies compatible with its recommendations, as some non-regular strategies are compatible, which is a natural application of the idea of imprecise picking strategies. 
%	
%	We can offer a slight strengthening, which we feel is still in the spirit of E-Admissibility. If $\mathbb{A}$ has the following feature, then it should be judged as impermissible: for every probability $p$ in $\IP$, there is some $\mathbb{A}'$ such that for all $a\in\mathbb{A}$ and $a'\in\mathbb{A}'$, $\Exp_p[\U(a)]\leq\Exp_p[\U(a')]$ and there exists some $a\in\mathbb{A}$ such that for all $a'\in\mathbb{A}'$, $\Exp_p[\U(a)]<\Exp_p[\U(a')]$. 
%	
%	With this strengthening, we get a result paralleling that for precise picking strategies: to avoid being ruled out as impermissible, one's strategy needs to $\mu$-surely be an $\EU_p$ strategy for some $\mu\times p\in\IB$. 
%%	
%	If $\imprecpickstrat$ is a set of picking strategies, and there is no $p \times \mu$ in $\IB$ such that all strategies in $\imprecpickstrat$ $\mu$-surely pick for $\EU_p$, then $\imprecpickstrat$ is judged  impermissible by this slightly strengthened account. This is because each probability $p\times \mu$ evaluates the precise picking strategy $\{\n^p\}$, where $\n^p$ picks for $\EU_p$, to weakly dominate it, i.e., every $\n\in\imprecpickstrat$, $\Exp_p[\U(\n)]\leq \Exp_p[\U(\n^p)]$, and there is some $\n\in\imprecpickstrat$ with $\Exp_p[\U(\n)]<\Exp_p[\U(\n^p)]$. 
%	
%%	So, if one extends E-Admissibility to judge imprecise acts in the proposed way then we get a result paralleling that in for precise probabilistic picking strategies: it must essentially be an $\EU_p$ strategy. The only E-Admissible imprecise picking strategies are those that are just a set of strategies all of which $\mu$-surely pick for $\EU_p$, for a single $p\times\mu\in\IB$. 
%	
%%	We would not expect to be able to obtain similar results for Maximality
%%	We would not expect the analogue results to apply for Maximality because our results show for each $\n$ there's a $\n'$ which is better according to every probability, but there's no guarantee of a single $\n'$ which is better than all the $\n\in\imprecpickstrat$. 
%
%%We would not expect to obtain similar results for Maximality. Even if we assume that one's probability over which decision she'll be faced with is precise, we don't have 
%%We would not expect to obtain similar challenges for extending Maximality, as we can only show that each $\n$ has a $\n'$ which is preferable, but there's no guarantee. 
We should not expect to obtain similar results for Maximality.
Consider an imprecise picking strategy consisting of the set of all compatible picking strategies, or even all those which are coordinated and pick for $\EU_p$ for some $p$ in one's credal set $\IP$. Each probability in $\IP$ agrees that there is a precise picking strategy that is better, but they disagree about which this precise picking strategy is: for which $p$ should it pick for $\EU_p$?
Maximality thus avoids the charge of evaluating the imprecise picking strategy as impermissible. There can be imprecise picking strategies that are Maximal and which do not all pick for a single $\EU_p$, unlike for E-Admissibility.


%We nonetheless are unsure about the 

%When we assume that one's probability over which decision she'll be faced with is precise, we showed that for every $\n$ which is not $\mu^*$-surely an $\EU_p$ strategy we get some $\n'$ which every probability $p$ agrees is preferable. But we can't guarantee that given a set of $\n$s, $\imprecpickstrat$, we get any agreement on which $\n'$ are preferable.


	
	
%	{\color{green}\todoold{RP: added this as a very rough summary of what CCM and I discussed at the whiteboard yesterday.}How might we evaluate them? Suppose $\Uset$ is a utility function that takes an act $a$ and returns not a single utility profile $\U = \langle u_1, \ldots, u_n\rangle$, where $u_i$ gives the utility of $a$ at state $\omega_i$, but a set of such utility profiles. How might we state E-Admissibility for such a conception of utility? Given a credal set $\IP$, we want to say that an act $a$ in a decision problem $D$ is rejected or impermissible if, for every probability $p$ in $\IP$, there is $a'$ in $D$ such that $p$ deems $a'$ better than $a$. But what do we mean when we say $p$ deems $a'$ better than $a$, when the utilities of both acts are represented by sets of utility profiles? One very permissive proposal---that is, a proposal that will lead E-Admissibility more rarely to reject acts---is that $p$ deems $a'$ better than $a$ when it deems $a'$ determinately better than $a$, that is, when for all utility profiles $\U$ in $\Uset(a)$ and all utility profiles $\U'$ in $\Uset(a')$, $\Exp_p[\U'] > \Exp_p[\U]$. In this case, we write $a' \succ_{p, \Uset} a$. So
%	$$\EAd_\IP(D) = \Set{a \in D \given (\exists p \in \IP)(\forall a' \in D)[a' \not \succ_{p, \Uset} a']}$$ 
%	Let's now apply this understanding to our case. Let $\PowN$ be the set of all sets of probabilistic picking strategies, and let $\negies$ be one such set of these strategies. Then $\negies$ is in $\EAd_\IB(\PowN)$ iff there is $\n$ in $\negies$ that $\mu$-surely picks for $\EU_p$. After all, in that case, for any alternative $\negies'$ and any $\n'$ in $\negies'$, $\Exp_{p\times \mu}[\n] \geq \Exp_{p\times \mu}[\n']$. So, by \cref{thm:ead-nu-reg-nec}, if $\negies$ contains only regular probabilistic picking strategies that pick for $\EAd_\IP$, then $\negies$ is not in $\EAd_\IB(\PowN)$.
%	What of Maximality? Here the natural version says that an act $a$ in a decision problem $D$ should be rejected if there is $a'$ in $D$ that every $p$ in $\IP$ deems better than $a$. That is:
%	$$\Maximality_\IP(D) = \Set{a \in D \given (\forall a' \in D)(\exists p \in \IP)[a' \not \succ_{p, \Uset} a']}$$
%	In this case, we don't get the self-undermining result we have for E-Admissibility. For some sets $\negies$ of probabilistic picking strategies that pick for $\Maximality_\IP$, there will be no alternative set $\negies'$ that is deemed determinately better by the lights of each probability function in $\IB$.\todoold{RP: do we know this is true?}
%	}
%	


	So, whilst this approach is a challenge for E-Admissibility, it is an option for Maximality.  
	So, if picking strategies may be imprecise acts, represented by sets of precise probabilistic picking strategies, then Maximality sometimes evades the charge of being self-undermining. However, it is hard to see how to implement an imprecise picking strategy. Perhaps one could choose by tossing a coin about whose bias you have imprecise probabilities, or perhaps one should have imprecise probabilistic uncertainty about how one will pick. But to maintain this response, one had better not gain additional information sufficient to make one precise. 
%	what mechanism one could use for picking between options your choice function does not reject that doesn't amount to randomisation. Moreover, 
	

%\todooldinfo{I deleted the Max response! Because I no longer get it...!!!}
	
	
	
%	
%\subsection{Imprecise probabilistic picking strategies}\label{sect:imprecise nu}
%
%
%\todoold{check this sec again}
%	
%So far, we've used decision theories to judge deterministic picking strategies, $\s$ and probabilistic picking strategies, $\n$. 
%%So far, we've asked what decision theories say about the deterministic or non-probabilistic picking strategies that pick for their choice functions, and what they say about the probabilistic picking strategies that do so. 
%But perhaps the proponent of imprecise probabilities thinks the way you pick is better represented by a imprecise probabilities, indeed, a set of probabilistic picking strategies. What do E-Admissibility and Maximality then say about these?
%
%The first thing to do is to define the utility of a set of probabilistic picking strategies. Given a state of the world $\omega$ and a decision problem $\D$, what is the utility of a set $\negies$ of such strategies? The natural thing is to say that the utility is itself imprecise. That is, it is the utility of $\negies$ is represented by the following set of utility functions $\Uset_\negies = \Set{\U(\n) \given \n \in \negies}$.
%
%The problem with this is that, as we've formulated them, E-Admissibility and Maximality are defined for precise utility functions. However, it's straightforward to extend them to this case.
%
%\hspace{5mm} $\EAd_{\IP,\Uset}(D) =  \Set{a \in D \given (\exists p \in \IP, \U \in \Uset)(\forall a' \in D)(\Exp_p[\U(a)]\geq\Exp_p[\U(a')])}$
%%
%%That is $a\in\EAd_{\IP,\Uset}(D)$ iff $a\in\EU_\IP(D)$ for some $\U$
%
%\hspace{5mm}  $\Maximality_{\IP, \Uset}(D) = \Set{a \in D \given (\forall a'\in D)(\exists p\in\IP, \U \in \Uset)(\Exp_p[\U(a)] \geq\Exp_p[\U(a')])}$
%
%In this context, we can extend the results about E-Admissibility. Applying our definition, we have that $\negies\in\EAd_\IB(\PowN)$ iff there is some $\n\in\negies$ and $p\times \mu\in \IB$ such that 
%
%
%Let $\PowN$ be a set of sets of picking strategies which is either the set of all deterministic picking strategies, or the set of all probabilistic picking strategies. 
%\begin{enumerate}[{\normalfont (i)}]
%\item A set $\negies$ of probabilistic picking strategies is in $\EAd_\IB(\PowN)$ iff there is $\langle p, \mu \rangle$ in $\IB$ and $\n$ in $\negies$ such that $\n$ $\mu$-surely picks for $\EU_p$. (This is an extension of \cref{thm:ead-nu-nec-suff}.)
%\item Suppose each $\n$ in $\negies$ is regular. Then, by \cref{thm:ead-nu-reg-nec} there is no $\n$ which is $\negies$ is not in $\EAd_\IB(\PowN)$, where $\IB$ is as in that theorem.
%%\item Suppose there is some $\n$ which does not $\mu$-surely pick for $\EU_p$ for any $p\times \mu\in \IB$, then 
%%
%%\item Suppose each $\n$ in $\negies$ is (a) regular and (b) $\mu^*$-surely picks for $\EAd_\IP$; where $\mu^*$ is precise, requires almost everywhere decisiveness, and countably additive, then $\negies$ is not in $\EAd_\IB(\PowN)$. 
%%(This is a corollary of \cref{thm:ead-nu-reg-nec}.)
%%\item Suppose that $N$ 
%\end{enumerate}
%
% However, we don't get any result analogous to \cref{thm:max-nu,thm:max-nu-reg-nec}. In those theorems, we showed that, if $\mu^*$ is precise, requires almost everywhere decisiveness, and countably additive, then, for any $\n$ that doesn't $\mu^*$-surely pick for $\EU_p$, for some $p$, there is an alternative $\n'$ that is better than $\n$ in expectation. And this is sufficient to give us the two analogous results for E-Admissibility just stated. But it is not sufficient to give the analogous results for Maximality, because there is no guarantee that it is the same $\n'$ that is better in expectation than each $\n$ in $\negies$.
%
%
%So, the advocate of Maximality might respond to our results by saying that all it shows is that you shouldn't pick by randomising; or, if you do, then you shouldn't learn which picking strategy represents your randomisation, and so shouldn't attain a precise probability over the decision problems. 
%	
%Two responses to this: first, it's hard to see what mechanism one could use for picking between options your choice function deems permissible that doesn't amount to randomisation; second, it seems troubling that you would have to abandon the decision theory you're using or the picking strategy you're using upon learning what it is. 
%
%
%
%
%%\begin{colored}{red}
%%
%%	
%%	Perhaps the advocate of imprecise probabilities thinks it is misguided to seek a precise measure of the utility of a choice function when that choice function arises from an imprecise decision theory. What might they say instead? Well, given a choice function $C$, say that $C^*$ is a precisification of $C$ if, for all $D$, $C^*(D) = \{a\} \subseteq C(D)$. That is, $C^*$ picks a particular act from each choice set. Then we might say that the utility of a choice function $C$ is the set of utilities of its precisifications. 
%%	
%%	Of course, by doing so, we make it so that we simply cannot apply the imprecise decision rule to itself: for the imprecise decision rule relies on there being determine precise utilities for the acts between which it adjudicates; and this strategy removes that.\todoold{CCM: and if we extend the Max and E-admiss to apply to utilitiesi n the natural way too, what happens? Do our results hold? I think it does for E-admiss but not for Max? Can we say that...}
%%	
%%	This would at least give a principled reason for saying that the decision theory cannot be applied to itself. But it ignores the fact that, while a choice function can be non-committal between two different acts, declaring both choiceworthy, an agent faced with a decision problem must choose only one. And so, if we really are to judge decision theories by extent to which they get us what we want, we must look at what they actually lead us to choose. And, for that, we need a picking strategy and from that we obtain a precise account of the utility of the decision theory.
%%\end{colored}
%
%
%
%
\subsubsection{Utility of a choice function not given by a picking strategy}

Perhaps we should specify the utility of a choice function in an alternative way. %, specifying $\U(\c,D,\omega)$ for the various $D$ and $\omega$. 
%Perhaps the utility of adopting a choice function $\c$ isn't governed by randomisation. 
%Even if we impose that $\U(\c,D,\omega)$ should be a mixture of $\U(a,\omega)$ for $a\in\c(D)$ our results do not follow. 
For example, we might say that $\U(\c,D,\omega)=\sup\{\U(a,\omega)\given a\in \c(D)\}$. If we do this, our results clearly do not hold. In fact, if we measure the utility of a choice function in this way, one should be maximally imprecise in every decision problem, that is, one should set $\c(D)=D$. And so, even if we require that $\U(\c,D,\omega)$ is a mixture of $\U(a,\omega)$ for $a\in\c(D)$, there are ways to define $\U$ such that our results do not follow. 
%An alternative defence is to argue that there's no representation in terms of a mixture of utilities of the non-rejected options. If for example $\U(\c,D,\omega)=\sup\{\U(a,\omega)\given a\in \c(D)\}$, then our results would not hold, in fact, then one should be maximally imprecise in every decision, setting $\c(D)=D$. 

However, measuring the utility of a choice function in this way would need more justification. Why should it be evaluated this way?
Why would this be the right judgement of what utility I will get if I adopt the choice function $\c$?

Or we could say that, when there's an imprecise decision set, one should do something else to make the decision, such as consulting an expert or gathering more evidence \citep{de2014efficient}. But then why is the possibility of consulting an expert or gathering more evidence not represented as an option in the original decision problem?
%A defence by Jasper etc\todoold{what?} say that when there's an imprecise decision set one should do something else, for example gather more evidence. We're not sure however, whether that's that helpful. Why wasn't the gathering more evidence option an option that was available in the first setting up of the decision problem? 




%\begin{colored}{orange}
%There is a different defence that the imprecise defender may argue for which we think would be successful, which will result in the feature that there's no representation in terms of a mixture of utilities of the choiceworthy options. If for example $\U(C,D,\omega)=\sup\{U(a,\omega)\given a\in C(D)\}$, then our results would not hold, in fact, then one should be maximally imprecise in every decision, setting $C(D)=D$. This, however, needs more justification, why should it be evaluated this way. A defence by Jasper etc\todoold{what?} say that when there's an imprecise decision set one should do something else, for example gather more evidence. We're not sure however, whether that's that helpful. Why wasn't the gathering more evidence option an option that was available in the first setting up of the decision problem? 
%\end{colored}
%
%\todooldinfo{Add stuff! JK, but also the stuff we were discussing!} 
%
%
%
%
%%\subsubsection{Picking strategies vs judging choice theories}



\section{Conclusion}


We have asked what happens when we use a decision theory to judge itself, or to judge strategies compatible with its recommendations, and we've found significant challenges for a host of theories that diverge from expected utility theory. 
%Our formal analysis often parallels that of existing known challenges for these theories such as diachronic inconsistencies exhibited by Dutch book arguments or paradoxes of sequential choice, but our interpretation of the results is different, understanding it as the decision theory undermining its own recommendations. 


In \cref{sect:reu}, we showed that risk-weighted expected utility theory, and other theories that accommodate the Allais preferences, are self-undermining in a particular way: for any such theory, there are particular ways of being uncertain about which decisions you'll face and a single deterministic picking strategy that chooses in line with the recommendations the decision theory would make were you to face each possible decision you might face, and that strategy is not itself acceptable according to the decision theory. These decision theories undermine their own recommendations; they recommend that you should choose in each decision problem in a way that the theory itself rejects when you're uncertain which decision problem you'll face. We generated these examples on the basis of the Allais preferences---and indeed any failure of the Independence Axiom would do. We then noted that we see the same phenomenon if we know we'll face a binary decision defined over two possible states of the world, and we place a uniform distribution over these different possible decisions; and similarly for a number of beta distributions we might place over them. And so the extent of the self-undermining is reasonably broad, but we don't have a precise general result that shows how broad it is.

In \cref{sect:eut}, we showed that traditional Savage-style expected utility theory does not have the same flaw: it always recommends its own picking strategies.

We then turned to decision theories that accommodate ambiguity and imprecision. In \cref{sect:gamma}, we saw that $\Gamma$-maximin is self-undermining in the way the Allais-permitting theories were, and we generated the witness to this using the Ellsberg preferences.\todoold{are we going to say something about} That is, they can rule out their (only) picking strategy as impermissible. 

In \cref{sect:e-admiss}, we observed that E-Admissibility and Maximility aren't vulnerable to the same challenge, since they judge some of their picking strategies to be permissible. In the case of E-Admissibility, we noted that the decision theory judges a picking strategy acceptable only if there is some probability function such that the picking strategy is certain to pick an option that maximizes expected utility from the point of view of that probability function; and so E-Admissibility requires picking strategies that coordinate across decisions.

%In \cref{sect:e-admiss}, we noted that the only E-Admissible strategies are those that are EU strategies: that is, they pick for $\EU_p$ for some probability in the credal set $\IP$.\todoold{check phrasing} But since these pick for E-Admissibility, that theory is not self-undermining in the same way. And, if we assume that your uncertainty about the decision problem is precise and requires almost everywhere decisiveness and countably additive, the only strategies that Maximality permits are EU ones. But again, since these pick for Maximality, that theory is not self-undermining in this way. 

%In \cref{sect:Max} we showed that the more permissive decision theories such as Maximality still have the same feature, that only EU strategies are evaluated as permissible, thus it undermines its own recommendations when there is non-trivial imprecision. However, for these results we needed to make a stronger assumption: that one has \emph{precise} probabilities over which decision she'll be faced with, along with an assumption that this requires almost everywhere decisiveness over a whole range of decisions. Whilst this is a limitation of our results, it nonetheless shows a whole slew of cases where these theories collapse into EU. \todoold{check that phrasing}

In \cref{sect:nu}, we turned from deterministic picking strategies, which select a single option from each decision problem, to probabilistic picking strategies, which place a probability distribution over the options in each decision problem. And we asked the same questions: when are decision theories self-undermining? A probabilistic picking strategy might represent a randomisation process; or it might represent your uncertainty about how you'll pick when that is governed by a precise probability.%; or simply that how we judge the utility of a choice rule should be given by a mixture of the utilities of the actions that are not ruled out. 

We noted that all our previous results generalise to this setting and, moreover, the situation is worse for the imprecise decision theories:
 E-Admissibility now judges any regular probabilistic picking strategy that picks for it to be impermissible, since such a strategy no longer looks like an expected utility strategy, at least given some mild assumptions on the set of probabilities that represents your uncertainty. 
For Maximality, we were able to show something similar, although in this case we need a much stronger assumption: that our decision-maker's uncertainty over which decision she'll face is governed by a precise probability, along with a further assumption about how likely it is you'll face a decision that has more than one option that maximizes expected utility. %broadness assumption that this requires almost everywhere decisiveness. 
	These considerations highlight that one should not in general pick by randomisation amongst the non-rejected options, or have uncertainty over how you'll pick in a way that amounts to randomisation. Imprecise decision theories see value in coordination. %have to see the value in coordination. 
%What these considerations highlight is the general 
%We saw that these considerations while \emph{prima facie} challenging, are perhaps less worrying or surprising than one might expect.
%Since these theories require one to pick in accordance with expected utility theory for some probability, one might try to extend the analysis to use E-Admissibility itself to judge this set of picking strategies. And, at least under our particular way of spelling this out, we obtain a similar challenge: since each probability function $p^*$ thinks you should pick in accordance with $\EU_{p^*}$, they agree that the set of all $\EU_p$ strategies is at least as bad as an alternative set, and some precisification is better. 



	We also considered extending the theories so that they might judge imprecise picking strategies, represented as sets of picking strategies, such as the set of all expected utility picking strategies. For instance, we suggested that, since each probability function considers a picking strategy that always picks options that maximize expected utility relative to it to be at least as good as all other picking strategies and better than some, we might say that it prefers its own strategy to the set of all picking strategies, and so E-Admissibility might then rule out as impermissible the set of all picking strategies, since each probability function considers something else better. Thus, under this way of applying E-Admissibility to judge imprecise picking strategies, the only strategies that are not judged impermissible are those which correspond to expected utility for a particular probability. \todooldinfo{ARGH!}

%
%We understand this as a result that these decision theories for imprecise probability do not judge themselves to be optimal. 
%So if this is how we ask an imprecise decision theory to judge itself, they rule themselves out as impermissible. 
%We also considered imprecise picking strategies. This is still susceptible to the analogue result in the E-Admissibility case: even if one's picking strategy is imprecise, to be E-Admissible it must look like an $\EU_p$ strategy, thus requiring coordination. 
However, similar considerations do not show that Maximality is self-undermining when we consider imprecise picking strategies. 

We also noted that our results would not go through were we to measure the utility of an imprecise choice set in some alternative way. For instance, if we say that the utility of a choice function faced with a decision problem at a state of the world is the supremum of the utilities, at that world, of the options in the decision problem that the choice function doesn't rule out, then of course one should have a maximally imprecise choice function. But motivating and justifying any such analysis remains an important task, and in any case, the consequence in this case is not desirable.
%
%{\color{violet}Some defences might be given by, for example, considering imprecise picking strategies, or ways of picking that don't amount to randomisation or mixtures but track the good options somehow. Whilst we acknowledge these defences, they are harder to implement than mixing and would like further analysis and motivation. 
%}
%{\color{orange}The defender of imprecise probabilities might argue that she should have imprecise opinions about which picking strategy she'll use, or that we should assign utility values just to the imprecise choice rule that provide imprecise utilities. These responses are not particularly helpful for the defender of E-admissibility as we still have the feature that the EU strategies are the only ones that are permissible, so if we extend the considerations to being imprecise in SLIGHTLY CONTROVERTIAL in a natural way we will still obtain the undermining feature. These defences do, however, help the defender of Maximality. It means, however, that one needs to have a method of picking which does not amount to randomisation, and/or she should abandon the decision theory if she does happen to be precise about how she'll pick. And if we are simply saying that utilities are imprecise, (some of) the authors remain unhappy because we want to ask of more from a decision theory: we need some guidance about what to do; simply holding hands up and saying, well, here's a set of options which are not ruled out but offering no guidance of how to pick, then it's not a very useful decision theory!
%
%There is a different defence that the imprecise defender may argue for which we think would be successful, which will result in the feature that there's no representation in terms of a mixture of utilities of the choiceworthy options. If for example $\U(C,D,\omega)=\sup\{U(a,\omega)\given a\in C(D)\}$, then our results would not hold, in fact, then one should be maximally imprecise in every decision, setting $C(D)=D$. This, however, needs more justification, why should it be evaluated this way. A defence by Jasper etc\todoold{what?} say that when there's an imprecise decision set one should do something else, for example gather more evidence. We're not sure however, whether that's that helpful. Why wasn't the gathering more evidence option an option that was available in the first setting up of the decision problem? 
%}
%\todooldinfo{RP: I think CCM and JK better placed to finalise the previous couple of paragraphs.}




To summarise: we have found %significant 
challenges for any of the decision theories we've considered that depart from expected utility theory. 
%When we ask a whole range of decision theories how they think one should pick, they pretty systematically recommend picking in accordance with expected utility theory, and thus undermining their own recommendations whenever those recommendations don't collapse into the recommendations of expected utility theory. 
When we ask a whole range of decision theories how they think one should pick, they pretty systematically recommend picking in accordance with expected utility theory. For some of the theories we considered (REU, $\Gamma$-maximin), this undermines their own recommendations whenever they don't collapse into the recommendations of expected utility theory. For others (E-Admissibility, Maximality), %it rather reflects a certain value, \emph{viz.}, the value of coordinating how you resolve incomparability across decision problems.
the situation is less clear, as picking in accordance with expected utility theory is compatible with the theory and choice-worthy according to the theory, however other picking strategies are deemed impermissible, and all regular probabilistic picking strategies are deemed impermissible. These theories thus have to accept a deep-seated value for coordinating how to resolve incomparability across decision problems.
% This may simply reflect a deep-seated value for coordinating how to resolve incomparability across decision problems; a value that may be palatable to proponents of those theories.
 What \emph{is} clear is that decision theorists must face the question of how to pick head on. %must theorise more systematically about how to pick.}}
\todooldinfo{Recheck the conclusion??}




\appendix

%\section{REU}
%\todooldinfo{As above, we need to think about how to present this.}\todooldinfo{???}

%\section{Setup?}
%We will work in the appendix throughout with $\n$. Recall the definitions from \cref{def:nu stuff}


\bibliographystyle{apa-good}
\bibliography{bibliography}
\begin{colored}{violet}

%\section{Summary of results}

%\todoinfo{NB: see end of intro for a wordy thing. Perhaps we should just do that and not this??}

%There are two main dimensions of stronger undermining results:
%\begin{enumerate}
%	\item\label{itm:uncertainty} Uncertainty over possible decisions:
%	\begin{enumerate}
%		\item\label{dimension:uncertainty:exists} Just a single example of being uncertain where it’s undermining.
%		\item\label{dimension:uncertainty:plausible} A plausible way of being uncertain where it’s undermining.\\Uniform
%		\item\label{dimension:uncertainty:range} It’s undermining for a decent range of ways of being uncertain.\\When precise, requires almost everywhere decisiveness...
%		\item\label{dimension:uncertainty:all} It’s undermining in almost all ways of being uncertain.\\All, except those where it reduces to EU.
%	\end{enumerate}
	
%	\item\label{dimension:strategies} Are all or just some of the strategies deemed impermissible?
%	\begin{enumerate}[label=(\alph*), ref=\theenumi\alph*]
%		\item\label{dimension:strategies:some} All non-EU strategies are impermissible. So (typically), some of its strategies ruled impermissible. 
%		\begin{itemize}
%			\item Each choiceworthy act is part of a choiceworthy strategy: for each $D\in\D$ and $a\in\c(D)$ there’s some $\s\in\c(\S)$ with $\s(D)=a$.
%			\item Some decisions have choiceworthy acts which are not picked by any choiceworthy strategy.
%		\end{itemize}
%		\item\label{dimension:strategies:allprob} All its regular probabilistic picking strategies deemed impermissible.% does this lie between the others?
%		\item\label{dimension:strategies:all} All its picking strategies ruled impermissible.
%	\end{enumerate}
%\end{enumerate}

%\bigskip

%\begin{itemize}
%	\item EU: \label{itm:EU}
%	\begin{itemize}
%		\item Has none of these dimensions of undermining: in all ways of being uncertain, all picking strategies are choiceworthy.\cref{thm:eu-self-rec,thm:eu-uniquely-optimal,thm:eu-nu-nec-suff}
%	\end{itemize}
	
%	\item Risk / Allais cases / Independence failures\label{itm:allais}
%	\begin{itemize}[nosep]
%		\item An instance of uncertainty (\ref{dimension:uncertainty:exists}) where all picking strategies are rejected (\ref{dimension:strategies:all}). \Cref{sect:reu}
%		\item For REU/Quiggin: strengthen to the uniform distribution (\ref{dimension:uncertainty:plausible}), still rejecting all strategies (\ref{dimension:strategies:all}). \Cref{sect:reu:other mu}
%	\end{itemize}
	
%	\item $\Maximin$\label{itm:maximin}
%	\begin{itemize}[nosep]
%		\item Some way of being uncertain (\ref{dimension:uncertainty:exists}) where all strategies are rejected (\ref{dimension:strategies:all}). \Cref{sect:Ellsberg}
%		\item If one’s uncertainty is precise, countably additive, and requires almost‐everywhere decisiveness (\ref{dimension:uncertainty:range}), then its only choiceworthy strategies are $\EU$ picking strategies (\ref{dimension:strategies:some}). \Cref{thm:gamma-nu}
%		\item If one’s uncertainty is precise, countably additive, and requires almost‐everywhere decisiveness (\ref{dimension:uncertainty:range}), then no regular probabilistic picking strategy is choiceworthy (\ref{dimension:strategies:allprob}). \Cref{thm:gamma-nu}
%	\end{itemize}
%	\item $\EAd$
%	\begin{itemize}
%		\item For all uncertainty, (\ref{dimension:uncertainty:all}), its only choiceworthy strategies are $\EU$ picking strategies (\ref{dimension:strategies:some}). There are others, which are ruled out. \Cref{thm:ead-equiv[indep]} (also, when decision-state dependence: \cref{thm:ead-equiv[dep]})
%		\item For all uncertainty which is imprecise (\ref{dimension:uncertainty:all}), all regular picking strategies are ruled out (\ref{dimension:strategies:allprob}). \Cref{thm:ead-nu-reg-nec}
%		\item For all uncertainty (\ref{dimension:uncertainty:all}), the only imprecise picking strategy which is not rejected (under our proposed extension of that for EAd) is to be precise and follow expected utility (NO REF ABOVE??) \Cref{sect:IPpicking}
%	\end{itemize}
%	\item Maximality:
%	\begin{itemize}
%		\item  If one’s uncertainty is precise, countably additive, and requires almost‐everywhere decisiveness (\ref{dimension:uncertainty:range}), then its only choiceworthy strategies are $\EU$ picking strategies (\ref{dimension:strategies:some}).  \Cref{thm:max-suff}
%		\item If one’s uncertainty is precise, countably additive, and requires almost‐everywhere decisiveness (\ref{dimension:uncertainty:range}), then no regular probabilistic picking strategy is choiceworthy (\ref{dimension:strategies:allprob}) \Cref{thm:max-nu-reg-nec}
%	\end{itemize}
%\end{itemize}

%\bigskip 
%ARE THEY STRICTLY ORDERED? 2B IMPLIES 2A?? NOT REALLY. ADD PIC FOR ORDERING, SO WE KNOW WHAT OTHER THMS WE HAVE AS WEAKER ONES??
%\begin{center}
%	\begin{tabular}{l|cccc}
%	& \ref{dimension:uncertainty:exists} & \ref{dimension:uncertainty:plausible} & \ref{dimension:uncertainty:range} & \ref{dimension:uncertainty:all} \\ \hline
%	\ref{dimension:strategies:some}    &  &  &  \makecell[l]{$\Maximin$\\$\Maximality$}& \makecell[l]{$\EAd$} \\
%	\ref{dimension:strategies:allprob} &  &  &  \makecell[l]{$\Maximin$\\$\Maximality$}&  \makecell[l]{$\EAd$} \\
%	\ref{dimension:strategies:all}     & \makecell[l]{Allais\\$\Maximin$} & REU &  &  
%\end{tabular}
%\end{center}

%\begin{tabularx}{1.2\linewidth}{X|l|l|l|l|l|}
%&Allais &EU&$\Maximin$&$\EAd$&$\Maximality$\Bstrut\\\hline\Tstrut
%bad: For some $\mu$, every $\s$ which picks for $\c$ is not in $\c(\S)$\newline
%good: For all $\mu$, some $\s$ which picks for $\c$ is in $\c(\S)$
%	&bad&good&bad&good &good\Bstrut\\\hline\Tstrut
%bad: For some $\mu$, some $\s$ which picks for $\c$ is not in $\c(\S)$ \newline
%good: For all $\mu$ and $\s$, if $\s$ picks for $\c$ it is in $\c(\S)$
%	&bad&good&bad&bad &bad\Bstrut\\\hline\Tstrut
%bad: For many $\mu$, every $\s$ which picks for $\c$ is not in $\c(\S)$\newline
%good: 
%	&?uniform&good&?&good &good\Bstrut\\\hline\Tstrut
%bad: For many $\mu$, some $\s$ which picks for $\c$ is not in $\c(\S)$\newline
%good: 
%	&?&good&bad&bad &bad ($\mu$ prec \& req dec)\Bstrut\\\hline\Tstrut
%bad: For many $\mu$, every regular $\n$ which picks for $\c$ is not in $\c(\Nu)$\newline
%good: 
%&?&good&?&bad &bad($\mu$ prec \& req dec)\Bstrut\\\hline\Tstrut
%bad: For many $\mu$, some regular $\n$ which picks for $\c$ is not in $\c(\Nu)$\newline
%good: 
%&?&good&?&bad &bad ($\mu$ prec \& req dec)\Bstrut\\\hline\Tstrut
%Imprecise $\imprecpickstrat$??
%\end{tabularx}



	

	
	\section{Measure theoretic considerations}\label{sect:appendix:measure}
	Throughout the paper, we ignored the question of measurability. We have considered various probability measures: $p$ a probability on $\Omega$, $\mu$ a probability on $\Decs$, and $b$ a probability on $\Omega\times\Decs$. To make this precise, we should fix the $\sigma$-algebras on each of these spaces.
	
	Since $\Omega$ is finite, we can equip it with the discrete $\sigma$-algebra, $\mathcal{F}=\wp(\Omega)$, so that every subset of $\Omega$ is measurable. 	
	
	$\Decs$ is defined as finite subsets of the set of acts $\A$, with $\A$ simply being an arbitrary non-empty set. 
	The $\sigma$-algebra we generate will be defined relative to a utility function $\U:\A\to\Re^\Omega\cong\Re^n$. 	\begin{colored}{blue}Since we have assumed that $\U$ is bounded, we can suppose that 	$\U\geq0$ WLOG. We do so for the remainder of the appendix.\end{colored}	
	
	We define a metric on $\A$ induced by $\Re^n$, that is $d(a,a'):=d(\U(a),\U(a'))$, with the Euclidean metric. 
	This then defines the topology on $\A$ and the associated Borel $\sigma$-algebra. 
	
	In fact, if there are some $a,a'$ that have the same utility profile, $\U(a)=\U(a')$, then $d(a,a')=0$, so it is actually a pseudo-metric. Any measurable notions will treat such acts equivalently and it is Borel isomorphic to the structure which identifies any two such acts.
	
	We can then use the Hausdorff metric on $\Decs$ to obtain our topology and the associated Borel $\sigma$-algebra.
	  \[
	d(D, D') = \max\Bigl\{
	\sup_{a \in D}\inf_{a' \in D'}d(a,a'),
	\;\sup_{a' \in D'}\inf_{a \in D}d(a,a')
	\Bigr\}.
	\]
	
	
	\begin{colored}{red}\todo{I no longer use in pf so get rid of it?
		}
		Note that this is identical to the Vietoris, or hit-and-miss, topology which is generated by the subbasis consisting of $\{D\in \Decs\given D\cap U\neq \emptyset\}$ and $\{D \in\Decs\given D\subseteq U\}$ for $U$ open subset of $\A$. 
	\end{colored}
	

	

	
	We will throughout additionally assume that $\U(\A)$ is a Borel subset of $\Re^n$, then both $\A$ and $\Decs$ are standard Borel spaces.\todo{delete the below pf as we don't use it??... that's not actually true. to be careful in our ``define s as ...'' we need to make measurable and this uses a selection theorem which I think needs standard Borel...!}
	 \begin{colored}{red}
	 	To see this, note that by quotienting out acts with the same utility profile, we can suppose that $\A$ is a Borel subspace of $\Re^n$, and thus is standard Borel. Then also $K(\A)$, the compact subsets of $\A$, is standard Borel, and we can show that $\Decs$ is Borel isomorphic to a Borel subset of that to obtain that it is also standard Borel.
	 Quotienting by $\sim_\U$, we see it is Borel isomorphic to $\bigcup_{n\in\mathbb{N}\setminus\{0\}}\{C\in K(\A)\given 0<\# C\leq n\}$, and we can show that this set is closed for each $n$: Suppose $C_i\longrightarrow C^*$ with $\# C_i\leq n$. If $\# C^* >n$ then there are $n+1$ disjoint $\epsilon$-balls in $\A$ which have non-empty intersection with $C^*$. And so for some tail of $C_i$, they also have non-empty intersection with these $n+1$ disjoint balls, and thus have cardinality $>n$, contradicting the assumption. 
	 \end{colored}
	
%	
%	
%	
%		
%	
%	Then just take the Borel $\sigma$-algebra generated by the open balls $B_\epsilon(a)=\{a'\in \A\given a\in \A\}$.
%	
%	
%	
%	We will first construct a $\sigma$-algebra on $\A$. This will be defined relative to a utility function $\U:\A\to\Re^\Omega\cong\Re^n$. 
%	We consider the standard Borel $\sigma$-algebra on $\Re^n$, and make an assumption on $\U$: that $\U(\A)$ is a Borel set. 
%	We can then equip $\A$ with the $\sigma$-algebra, $\mathcal{B}(\A)=\Set{\U^{-1}(B)\given B\in\mathcal{B}(\Re^n)}$. This implies that any measurable function cannot distinguish acts with the same utility profiles.    By assumption that $\U(\A)$ is Borel, this is a standard Borel space. 
%	
%	 \todo{I think these are all equivalent.}
%	One can then construct a $\sigma$-algebra on $\Decs$ from $\mathcal{B}(\A)$.
%	
%	We consider the 
%	
%	First, consider the Vietoris (or hit-and-miss) topology on $K(\A):=\{C\subseteq\A\given C\text{ is compact}\}$, which is generated by the sub-basis $$\left\{\{C\in K(\A)\given C\subseteq K(\A)\},\{C\in K(\A)\given C\cap K(\A)=\emptyset\}\right\}$$
%	Note that it is exactly the topology generated by the Hausdorff metric  \[
%	d(D, D') = \max\Bigl\{
%	\sup_{a \in D}\inf_{a' \in D'}d(a,a'),
%	\;\sup_{a' \in D'}\inf_{a \in D}d(a,a')
%	\Bigr\}.
%	\]
%	
%	Using this to generate the $\sigma$-algebra, we obtain a  standard Borel space. 
%	
%	We then check that $\Decs=\{C\in K(\A)\given C\text{ is finite}\}$ is a Borel subset of this so that it is also standard Borel. To do this, we will observe that $\{C\in K(\A)\given \# C\leq n\}$ is closed for each $n$. Suppose $C_i\longrightarrow C^*$ with $\# C_i\leq n$. If $\# C^* >n$ then there are $n+1$ disjoint $\epsilon$-balls in $\A$ which have non-empty intersection with $C^*$. And so for some tail of $C_i$, they also have non-empty intersection with these $n+1$ disjoint balls, and thus have cardinality $>n$, contradicting the assumption. 
%	
%	\begin{colored}{red}
%		
%	
%	\begin{itemize}
%	
%		\item Put $\Sigma$ as the $\sigma$-algebra generated by $\Set{D\in \Decs\given D\cap A\neq\emptyset}$ and $\Set{D\in \Decs\given D\cap A=\emptyset}$, for $A\in\mathcal{B}(\A)$. This is the finite-set Vietoris, or hit-and-miss topology, and it is a standard Borel space.
%		\begin{itemize}
%			\item Consider $ K(\A)=\{K\subseteq \A\given K \neq\emptyset,\;K\text{ compact}\}$ endowed with the Vietoris (hit-and-miss) topology generated by $\Set{K\in K(\A)\given K\cap A= \emptyset}$ and $\Set{K\in K(\A)\given K\cap A\neq \emptyset}$ for $A\in\mathcal{B}(\A)$. This topology is metrizable by the Hausdoff metric, under which it is complete and separable, thus Polish. And so it is a standard Borel space. 
%			For each $n\in\mathbb{N}\setminus\{0\}$, $\{K\given \# K\leq n\}$ is closed: If $K_i\longrightarrow K^*$ and $\# K^*>n$ then $K^*$ contains $n+1$ many points all separated by disjoint $\epsilon$-balls, but then some $K_m$ does too, so $\# K_m\geq n+1$. Thus $\Decs=\bigcup_n\{K\in K(\A)\given \# K\leq n\}$ is a Borel subset of $K(\A)$. It is thus a standard Borel space, under the induced $\sigma$-algebra, which is generated by $\Set{D\in \Decs\given D\cap A\neq\emptyset}$ and $\Set{D\in \Decs\given D\cap A=\emptyset}$ for $A\in\mathcal{B}(\A)$.
%		\end{itemize}
%	\item Endow $\Decs$ with the Hausdorff metric \[
%d(D, D') = \max\Bigl\{
%\sup_{a \in D}\inf_{a' \in D'}d(a,a'),
%\;\sup_{a' \in D'}\inf_{a \in D}d(a,a')
%\Bigr\}.
%\]
%Then let $\Sigma$ be the $\sigma$-algebra generated by $B_\epsilon(D_0)=\Set{D\in\Decs\given d(D,D_0)<\epsilon}$. 
%		\item Put $\Sigma$ as the smallest $\sigma$-algebra containing each $\{D\in\Decs\given \#(D\cap A)=k\}$ for $A\in\mathcal{B}(\A)$ and $k\in\mathbb{N}\setminus\{0\}$.
%		\item 
%		Consider $k$-tuples in $\A$ with the product sigma-algebra on $\A^k$. Note that the $\Set{\seq{a_1,\ldots,a_n}\given a_i=a_j\text{ for some $i\neq j$}}$ is a Borel subset, so so is the $k$-tuples, excluding any repeating members. Let's call that $\A^{(k)}$. Then quotient this out by the action of the symmetric group which permutes coordinates. This will remain Borel. Now take the disjoint union of these, and we still have a standard Borel space. 
%		\item Consider $\Decs$ as the set of point measures (??) $f:\A\to\Set{0,1}$ such that $f(\A)<\infty$....?
%		\item  Since $\A$ is standard Borel, we can consider $\phi:\A\to B\subseteq \Re$ a Borel isomorphism. $\A^k$ is standard Borel. 
%		Then consider $Y_k=\Set{\seq{a_1,\ldots,a_k}\given \phi(a_1)<\ldots<\phi(a_k)}=\phi^{-1}(\Set{\seq{x_1,\ldots,x_k}\in B^k\given x_1<\ldots<x_n})$; with this an open (and thus Borel) subset of a Borel space. So $Y_k$ is Borel. Then $\D$ is the countable disjoint union of these $Y_k$, thus remaining standard Borel. \todo{\url{https://www.jstor.org/stable/23041875}}
%	\end{itemize}
%%	Equivalently, it can be seen as the countable disjoint union of $k$-tuples in $\Re^n$, modulo permutations, with the obvious inherited $\sigma$-algebra.\todo{more care}
%	\end{colored}
	
	We then require $p$ a probability on $(\Omega,\mathcal{F})$, $\mu$ a probability on $(\Decs,\Sigma)$, and $b$ a probability on $(\Omega\times\Decs,\mathcal{F}\otimes \Sigma)$.

	
	All the results in this paper are restricted to \emph{measurable} picking strategies, either of the deterministic form, $\s:\Decs\to\A$, or measurable probabilistic picking strategies $\n:\Decs\to\Delta(\A)$. This ensures that the induced payoffs, $\U(\s),\U(\n):\Omega\times\Decs\to\Re$, are measurable random variables with respect to $(\Omega\times\Decs,\mathcal{F}\otimes \Sigma)$ (recalling that $\U(\n)(\omega,D):=\Exp_{\n_D}[\U(\cdot)(\omega)]$). 
	

	
	
	
\section{Decision-State Dependence}\label{sect:appendix:decdep}


When we have decision-state dependence, we made use of the idea of conditional probabilities. For $b$, a probability measure on $(\Omega\times\Decs,\mathcal{F}\otimes \Sigma)$, we assumed we had appropriate conditional probability measures, $b(\cdot | D)$, on $\Omega$, defined for $b_\Decs$-almost every $D$. %Since both $(\Omega,\mathcal{F})$ and $(\Decs,\Sigma)$ are standard Borel, 
Since $(\Omega,\mathcal{F})$ is standard Borel, this follows immediately from the Conditional Distribution Disintegration Theorem \citep[Theorem 8.5]{kallenberg1997foundations}, which guarantees that $b(\cdot|D)$ is defined and unique for $b_\Decs$-almost every $D$, and that for every $X\in L^2(b)$ and $b_\Decs$-almost every $D$:
\begin{align}
	&\Exp_{b}[X | D] =\int_\Omega X(\omega,D)b(\diff \omega | D)=\sum_{\omega\in\Omega} X(\omega,D)b(\omega|D).
\end{align}
where $\sigma(D)$ is the $\sigma$-field generated by $D$, the conditional expectation, $\Exp_{b}[X | \sigma(D)]$, is defined as the orthogonal projection of $X$ onto the linear subspace of $\sigma(D)$-measurable random variables, and $\Exp_{b}[X | D]$ is the value of this random variable at $D$. (This extends by continuity to $X\in L^1(b)$.)

By the tower property of conditional expectation \citep[Theorem 8.1]{kallenberg1997foundations} we have $\Exp_b[X]=\Exp_{b}[\Exp_{b}[X | D]]$, which implies
\begin{align}
\Exp_{b}[\Exp_{b}[X | D]]&=\int_{\Omega\times \Decs} \Exp_{b}[X | D] b(\diff \omega, \diff D)\\
&=\int_{\Decs} \Exp_{b}[X | D] b_\Decs(\diff D)\\
&=\int_{\Decs} \left[\sum_{\omega\in\Omega} X(\omega,D)b(\omega|D)\right] b_\Decs(\diff D)\\
&=\Exp_{b_\Decs}[\Exp_{b(\cdot|D)}[X(\cdot, D)]]
\end{align}
Henceforth we write $\Exp_{b_\Decs}[\Exp_{b(\cdot|D)}[X]]$ as shorthand for $\Exp_{b_\Decs}[\Exp_{b(\cdot|D)}[X(\cdot, D)]]$. So $\Exp_b[X]=\Exp_{b_\Decs}[\Exp_{b(\cdot|D)}[X]]$.



When $b=p\times\mu$, then $b_\Decs=\mu$ and $b(\cdot|D)=p$ for $\mu$-almost every $D$. So $\Exp_{p\times\mu}[X]=\Exp_{\mu}[\Exp_{p}[X]]$. 



%So 
%\begin{align}
%\Exp_{p\times\mu}[X]=\int_{\Decs}\left[\sum_{\omega\in\Omega} X(\omega,D)p(\{\omega\})\right]\mu(\diff D)=\Exp_{\mu}[\Exp_{p}[X]]
%\end{align}
%where $\Exp_{\mu}[\Exp_{p}[X]]$ is shorthand for $\Exp_{\mu}[\Exp_{p}[X(\cdot, D)]]$.












\begin{comment}

When $\Decs$ has finite support, we can simply define $b(\cdot|D)$ by the ratio formula for those $D$ with $b(\Decs)>0$. 
Then $b(\cdot|D)$ is defined and probabilistic for $b_\Decs$-almost every $D$ (and $D\mapsto b(\cdot|D)$ is measurable). 
Moreover, and importantly for us, the law of total expectation holds: for measurable integrable random variables $X:\Omega\times\Decs\to\Re$, $\Exp_b[X]=\Exp_{b_\Decs}[\Exp_{b(\cdot|D)}[X]]$. We will in particular be applying this to $\U(\s)$ and $\U(\nu)$. 
%\todo{Actually, we could probably instead remove it as a *background* assumption?? Just as we restrict to measurable $\s$ or $\n$, we could restrict to bounded or integrable strategies?? (though ``integrable'' is relative to a measure...) Anyway, I don't think we shoudl change this, but just to note it. }




In the more general setting, we need to make use of further machinery.

As $\U(\A)$ is assumed to be a Borel subset of $\Re^\Omega$, $\Decs$ is standard Borel so the disintegration theorem can be used to find this \citep[Theorem 3.4]{kallenberg1997foundations}. %Theorem 8.5
This will give $b(\cdot|D)$ defined and probabilistic for $b_\Decs$-almost every $D$, with $D\mapsto b(A|D)$ is measurable for every $A\subseteq\Omega$. 
% and where for measurable $A\times E\subseteq\Omega\times\Decs$, 
%\[
%b(A\times E)=\int_E b(A|D) b_\Decs(\diff D)
%\]
For every non-negative (or bounded) measurable $X:\Omega\times\Decs\to\Re$, \begin{align}
	&\int_{\Omega\times \Decs} X(\omega,D) b(\diff \omega, \diff D)=\int_\Decs \left[\sum_{\omega\in\Omega} b(\omega|D)X(\omega,D)\right]\,b_\Decs(\diff D)
\end{align}
\todo{Need better reference to disintegration theorem } 
That is, $\Exp_b[X]=\Exp_{b_\Decs}[\Exp_{b(\cdot|D)}[X]]$.

\begin{colored}{blue}
Since $\Omega$ is finite, it could alternatively be constructed directly using Radon-Nikodym derivatives by putting $b(A|D)$ as $\frac{\diff b(A\times\cdot)}{\diff b_\Decs}(D)$ for $A\subseteq\Omega$. 
By the Radon-Niokodym theorem, this is well-defined for $b_\Decs$-almost every $D$ (and each $D\mapsto b(A|D)$ is measurable in $b_\Decs$) and we obtain $b(A\times E)=\int_E b(A|D) b_\Decs(\diff D)$.
As each $b(A|D)$ is well defined on $b_\Decs$-almost every $D$ and there are only finitely many $A\subseteq\Omega$, $b(\cdot|D)$ is still well-defined on $b_\Decs$-almost every $D$. It is also probabilistic by the linearity of Radon Nikodym derivatives. Thus, also for measurable integrable $X$, $\Exp_b[X]=\Exp_{b_\Decs}[\Exp_{b(\cdot|D)}[X]]$.
\end{colored}


%For any $\omega$ with $b(\{\omega\}\times\Decs)>0$, let $\beta_\omega$ be the measure on $\Decs$ given by $\beta_\omega=b(\{\omega\}\times \cdot)$. 
%As $b_\Decs=\sum_{\omega\in\Omega}\beta_\omega$, each $\beta_\omega$ is absolutely contiuous 


%
%
%
%
%
%
%\todo{was trying to rewrite and simplify with refs... but it's going to take longer than I thought...}
%
%Important for our results is that we have the law of total expectation for integrable measurable random variables, $\Exp_b[X]=\Exp_{b_\Decs}[\Exp_{b(\cdot|D)}[X]]$, which we will apply in particular for our $\U(\s)$ or $\U(\nu)$ (which are bounded). 
%We need to ensure that $D\mapsto b(\cdot|D)$ is measurable and $b(A\times E)=\int_{D\in E}b(A|D)\;b_\Decs(\diff D)$ for all measurable $A\subseteq\Omega$ and $E\subseteq\Decs$. This is the regular conditional probability kernel. 
%
%
%
%When $\Decs$ has finite support, we can just define $b(\cdot | D)$ by the ratio formula for any $D$ with $b_\Decs(D)>0$ and verify that the law of total expectation holds. 
%
%In the more general setting, we need to make use of further machinery to find this regular conditional probability kernel. As $\Omega$ is finite, this can just be done from Radon-Nikodym derivatives. 
\end{comment}



\begin{colored}{red}
	\section{some more details on the RN approach}\todo{doesn't make use of standard Borel!}
	
	\subsection{v1}
Let $\Omega_b:=\Set{\omega\given b(\{\omega\}\times\Decs)>0}$, and note that $b(\Omega_b\times\Decs)=1$. For any $\omega\in \Omega_b$, let $\beta_\omega$ be the measure on $\Decs$ given by $\beta_\omega(E)=b(\{\omega\}\times E)$ for measurable $E\subseteq \Decs$. 
As $b_\Decs=\sum_{\omega\in\Omega_b}\beta_\omega$, each $\beta_\omega$ is absolutely continuous with respect to $b_\Decs$, and thus by the Radon-Nikodym theorem, for each $\omega$ there is a $b_\Decs$-measurable function $\frac{\diff \beta_\omega}{\diff b_\Decs}:\Decs\to[0,\infty)$ such that $b_\Decs(\{\omega\}\times E)=\beta_\omega(E)=\int_E \frac{\diff \beta_\omega}{\diff b_\Decs}b_\Decs(\diff D)$.
Note then that \begin{align}
	b(A\times E)&=\sum_{\omega\in A\cap \Omega_b}\beta_\omega(E)=\sum_{\omega\in A\cap \Omega_b}\int_E \frac{\diff \beta_\omega}{\diff b_\Decs}(D)\;b_\Decs(\diff D)\\
	&=\int_E\sum_{\omega\in A\cap \Omega_b} \frac{\diff \beta_\omega}{\diff b_\Decs}(D)\;b_\Decs(\diff D)
\end{align}
Let $b(\cdot|D)$ be a measure on $\Omega$ given by $b(A|D)=\sum_{\omega\in A\cap \Omega_b} \frac{\diff \beta_\omega}{\diff b_\Decs}(D)$ so that for any measurable $A\subseteq\Omega$ and $E\subseteq\Decs$, 
\[
b(A\times E)=\int_E b(A|D) b_\Decs(\diff D)
\]
And thus, \todo{Reference monotone convergence theorem from simple functions? Better to find a reference though... } for every integrable (e.g., bounded) measurable $X:\Omega\times\Decs\to\Re$, \begin{align}
	&\int_{\Omega\times \Decs} X(\omega,D) b(\diff \omega, \diff D)\\
	&=\int_\Decs \left[\sum_{\omega\in\Omega} b(\omega|D)X(\omega,D)\right]\;b_\Decs(\diff D)
\end{align}
That is, $\Exp_b[X]=\Exp_{b_\Decs}[\Exp_{b(\cdot|D)}[X]]$.

Note also that by the almost everywhere linearity of Radon-Nikodym derivatives, $\sum_{\omega\in\Omega_b}\frac{\diff \beta_\omega}{\diff b_\Decs}=\frac{\diff \sum_{\omega\in\Omega_b}\beta_\omega}{\diff b_\Decs}=\frac{\diff b_\Decs}{\diff b_\Decs}=1$ almost everywhere. Thus $b(\cdot|D)$ is a probability function on $\Omega$ for almost all $D$.


\subsection{v2}
	

%When $b$ is supported on finite subset of $\Decs$, this is easy to define: we update $b$ by the ratio formula, whenever $b(D)\neq 0$. More carefully:
%
%Let $b_\omega$ a measure on $\Decs$ given by $b_\omega(\omega)=b(\{\omega\}\times E)$ for $E\subseteq D$ measurable. Put $b_\Decs=\sum_{\omega\in\Omega} b_w$, is the marginal of $b$ on $\D$. 
%
%If $b_\Decs$ is supported on a finite subset $\Decs'\subseteq\Decs$, i.e., $b_\Decs(\Decs')=1$,, then we can just define $b(\cdot|D^*)$ as a probability measure over $\Omega$ given by the ratio formula, i.e., $b(\omega|D^*)=\frac{b(\{\omega\}\times \{D^*\})}{b(\Omega\times \{D^*\})}=\frac{b_\omega(D^*)}{b_\Decs(D^*)}$, whenever $b_\Decs(D^*)>0$; which is for $b_\Decs$ almost all $D^*$, by assumption of finite support. 
%
%
%Then, for any random variable, $X:\Omega\times\Decs\to\Re$, (in particular, for our $\U(\s)$ or $\U(\n)$), $\Exp_b[X]=\Exp_{b_\Decs}[\Exp_{b(\cdot|D)}[X]]$ 
%This is because
%\begin{align}
%	\Exp_b[X]&=\sum_{D\in\Decs'}\sum_{\omega\in\Omega}X(\omega,D)b(\omega,D)\\
%	&=\sum_{D\in\Decs'}\sum_{\omega\in\Omega}X(\omega,D)\left[b_\Decs(D)\frac{b(\omega,D)}{b_\Decs(D)}\right]\\
%	&=\sum_{D\in\Decs'}b_\Decs(D)\sum_{\omega\in\Omega}X(\omega,D)\left[\frac{b(\omega,D)}{b_\Decs(D)}\right]\\
%	&=\Exp_{b_\Decs}[\Exp_{b(\cdot|D)}[X]]
%\end{align}
%
%
Now, if $b$ is supported on an infinite set $\Decs$, we need to use some more machinery to define the appropriate conditional probabilities. 



Let $b_\omega$ be a measure on $\Decs$ given by $b_\omega(E)=b(\{\omega\}\times E)$ for $E\subseteq \Decs$ measurable. 
Then the marginal on $\Decs$ is given by  $b_\D=\sum_{\omega\in\Omega} b_w$. 

As $b_\D$ is the finite sum of these $b_\omega$, they are absolutely continuous with respect to it; and thus by Radon–Nikodym theorem, for each $\omega$ there is a (measurable) function $f_\omega$ on $\Decs$ (unique almost everywhere) such that for all measurable $E\subseteq\Decs$, $b_\omega(E)=\int_{E}f_\omega(D) b_\D(\diff D)$. 
%Put $b(\omega |D):= f_\omega(D)$. 


For any $A\subseteq\Omega$, define $b(A | D):= \sum_{\omega\in A}f_\omega(D)$. Then we have $b_\omega(E)=\int_{E}b(\{\omega\} |D) b_\D(\diff D)$ for measurable $E\subseteq \Decs$. 



Note that for almost every $D$, $b(\cdot |D)$ is a probability measure over $\Omega$. To see this, suppose that $b(\Omega | D)\not=1$ for all $D$ in some measurable $E\subseteq\Decs$ with $b_\D(E)>0$. Let $E^+=\Set{D\in E\given b(\Omega | D)>1}$ and $E^-=\Set{D\in E\given b(\Omega | D)<1}$. Then either $b_\D(E^+)>0$ or $b_\D(E^-)>0$. Suppose WLOG that $b_\D(E^+)>0$. Then
\begin{align}
	b_\D(E^+)&=\sum_{\omega\in\Omega} b_w(E^+)\\
	&=\sum_{\omega\in\Omega}\int_{E^+}b(\{\omega\} |D) b_\D(\diff D)\\
	&=\int_{E^+}b(\Omega |D) b_\D(\diff D)\\
	&>\int_{E^+} 1 b_\D(\diff D)\\
	&=b_\D(E^+)
\end{align}


%Since $b_\D=\sum_{\omega\in\Omega}b_\omega$, one can check that for $b_\D$ almost every $D$, $b(\cdot |D)$ is a probability measure over $\Omega$.\todo{check! Although, we don't actually care! We just need the law total expectation... }



For any integrable $X: \Omega\times \Decs\to\Re$ (for example, when $X$ is bounded)


%\begin{align}
%	\Exp_b[X]&=\int_{\Omega\times\Decs} X(\omega, D) b(\diff \omega,\diff D)\\
%	&=\sum_\omega\int_\D X(\omega,D) b(\omega,\diff D)\\
%	&=\sum_\omega\int_\D X(\omega,D) b_\omega (\diff D)\\
%	&=\sum_\omega\int_\D X(\omega,D) f_\omega(D) b_\D(\diff D)&&\text{(change of measures formula)}\\
%		&=\sum_\omega\int_\D X(\omega,D) b(\omega |D) b_\D(\diff D)\\
%		&=\int_\D [\sum_\omega X(\omega,D) b(\omega |D)] b_\D(\diff D)\\
%		&=\Exp_{b_\D}[\Exp_{b(\cdot|D)}[X(\cdot,D)]]
%\end{align}

	Hence, for any integrable $X:\Omega\times\Decs\to\Re$, 
\begin{align}
	&\int_{\Omega\times \Decs} X(\omega,D) b(\diff \omega, \diff D)\\
	&=\int_{\Omega_b\times \Decs} X(\omega,D) b(\diff \omega, \diff D)\\
	&=\sum_{\omega\in\Omega_b} \int_\Decs X(\omega,D)\beta_\omega(\diff D)&&\text{definition of $\beta_\omega$ and}\\
	&=\sum_{\omega\in\Omega_b} \int_\Decs X(\omega,D)\frac{\diff \beta_\omega}{\diff b_\Decs}b_\Decs(\diff D)&&\text{change of measure}\\
	&=\sum_{\omega\in\Omega_b} \int_\Decs X(\omega,D)b(\omega|D)b_\Decs(\diff D)&&\text{definition of $b(\cdot|D)$}\\
	&=\int_\Decs \left[\sum_{\omega\in\Omega_b} b(\omega|D)X(\omega,D)\right]\;b_\Decs(\diff D)&&\text{definition of $b(\cdot|D)$}\\
\end{align}
That is, $\Exp_b[X]=\Exp_{b_\Decs}[\Exp_{b(\cdot|D)}[X]]$.


\begin{align}
	\Exp_b[X]&=\int_{\Omega\times\Decs} X(\omega, D) b(\diff (\seq{\omega,D}))\\
		&=\sum_{\omega\in\Omega:b_\omega(\Decs)>0}\left[\int_{\{\omega\}\times \D} X(\omega,D) {b(\{\omega\},\diff D)}\right]\\
%	&=\sum_{\omega\in\Omega:b_\omega(\Decs)>0}b_\omega(\Decs)\left[\int_\D X(\omega,D) \frac{b(\{\omega\},\diff D)}{b_\omega(\Decs)}\right]\\
	&=\sum_{\omega\in\Omega:b_\omega(\Decs)>0}\int_\D X(\omega,D) b_\omega (\diff D)\\
	&=\sum_{\omega\in\Omega:b_\omega(\Decs)>0}\int_\D X(\omega,D) f_\omega(D) b_\D(\diff D)&&\text{(change of measures formula)}\\
	&=\sum_{\omega\in\Omega:b_\omega(\Decs)>0}\int_\D X(\omega,D) b(\omega |D) b_\D(\diff D)\\
		&=\int_\D \left[\sum_{\omega\in\Omega} X(\omega,D) b(\omega |D)\right] b_\D(\diff D)\\
		&=\Exp_{b_\D}[\Exp_{b(\cdot|D)}[X(\cdot,D)]]
\end{align}


%\bigskip
%
%ALTERNATIVE...
%
%
%
%
%Define its marginal on $\Decs$ by $b_\Decs(E)=b(\Set{(\omega,D)\given D\in E})$ for $E\subseteq\Decs$. 
%By the disintegration theorem (since $\Omega$ and $\Decs$ are standard Borel), there are conditional probabilities $b(\cdot | D)$ which are unique for $b_\Decs$-almost all $D$. 
%
%Note that $\Exp_b[X]=\Exp_{b_\Decs}[\Exp_{b(\cdot|-)}[X]]$ for any $X$ a measurable random variable on $\Omega\times \Decs$. 
%
%Note that if $b$ is a product, $p\times\mu$, then $b_\Decs$ is just $\mu$ and $b(\cdot|D)=p$ for all $D$. 
\end{colored}




\subsection{$\EU$-completeness and measurability}

With the clarification that we restrict to \emph{measurable} selection functions, $\Nu$ being $\EU$-complete is taken to mean that for every probability $p$ over $\Omega$ there is some $\nu\in\Nu$ which picks for $\EU_p$. 

\begin{lemma}\label{thm:EU-complete-measurable}
	For every probability $p$ there is a measurable $\s\in\S$ which picks for $\EU_p$. 
\end{lemma}
\begin{proof}
	We will apply the Measurable Maximum Theorem of \citet[Theorem 18.19]{aliprantis2006infinite}.
	
	Define $\varphi$ a measurable correspondence from $\Decs$ to $\A$ by $\varphi(D)=D$. It is weakly measurable, i.e., for $U$ open $\subseteq\A$, $\{D\given U\cap D\neq\emptyset\}$ is measurable (in fact, open) in $\Decs$ \citep[3.91]{aliprantis2006infinite}. It also takes non-empty compact values by specification of $\Decs$. 
	
	$\Exp_p[\U(a)]=\sum_{\omega\in\Omega}p(\omega)\,\U(a)(\omega)$ is a continuous function of $a$. Conceiving of it as a function from $\A\times\Decs\to\Re$ which doesn't depend on $D$, it is trivially measurable as a function of $D$. 
	It is thus a Carathéodory function and we obtain a measurable selector for $\EU_p$, as required. 
\end{proof}

Similarly for being conditional $\EU$-complete: it requires the existence of \emph{measurable} picking strategies for $\EU_{b(\cdot|-)}$. 

\begin{lemma}\label{thm:EU-complete-measurable[dep]}
	For every probability $b$ over $\Omega\times\Decs$, there is some measurable $\s\in\S$ which picks for $\EU_{b(\cdot|-)}$. 
\end{lemma}

\begin{proof}
	We will apply the Measurable Maximum Theorem of \citet[Theorem 18.19]{aliprantis2006infinite}. 

As in \cref{thm:EU-complete-measurable}, $\varphi$ is a weakly measurable correspondence from $\Decs$ to $\A$ which takes non-empty compact values. 
	
	Consider $\Exp_{b(\cdot|D)}[\U(a)]$, a function from $\Decs\times\A\to\Re$. 
	
	For fixed $D$, this is $=\sum_{\omega\in\Omega}b(\cdot|D)(\omega)\U(a)(\omega)$, which is linear and continuous in $a$. 
	
	We need to show that it is measurable in $D$, for fixed $a$. This holds because $D\mapsto b(\cdot|D)$ is measurable. 
	
	It is thus a Carathéodory function and we obtain a measurable selector for $\EU_{b(\cdot|-)}$, as required. 
\end{proof}

\Cref{thm:EU-complete} thus follows from these. 

\end{colored}
\section{EU and E-admissibility}

	
\subsection{EU (\cref{thm:eu-self-rec,thm:eu-uniquely-optimal,thm:eu-nu-nec-suff,thm:eu-dep})}\label{sect:EU-appendix}
Our first series of results rely on the fact that a picking strategy has maximal expected utility iff it $\mu$-surely picks for expected utility theory combined with a particular probability. This core result, stated in \cref{thm:eu-self-rec,thm:eu-uniquely-optimal}, is then extended to cover cases of decision-state dependence (\cref{thm:eu-dep}) and probabilistic picking strategies (\cref{thm:eu-nu-nec-suff}). 

We will prove the result in generality to cover all these cases. 

%
%\begin{theorem}\label{thm:EU-appendix} 
%	\begin{enumerate}[label=\normalfont(\roman*), ref=\roman*]
%		\item  If $\nu$ $\mu$-surely picks for $\EU_{p}$ then, for any $\nu'$, $\Exp_{p\times\mu}[\U(\nu)]\geq\Exp_{p\times\mu}[\U(\nu')]$
%		\item  If $\nu$ $\mu$-surely picks for $\EU_{p}$ and $\nu'$ does not, then $\Exp_{p\times\mu}[\U(\nu)]>\Exp_{p\times\mu}[\U(\nu')]$.
%	\end{enumerate}
%\end{theorem}
%\begin{proof}
%	Since $\U$ is assumed to be bounded, $\abs{\U(a)(\omega)}\leq M$ for all $a\in\A$ and $\omega\in\Omega$. Thus $\abs{\U(\nu)(\omega,D)}\leq M$, so $\int_{\Omega\times \D} \abs{\U(\nu)(\omega,D)} \; b(\diff \omega,\diff D)\leq M$, i.e., it is absolutely integrable. Thus, by Fubini's theorem, integrals can be exchanged freely. 
%	
%	The basic reason is by exchange of expectations: $$\Exp_{p\times\mu}[\U(\nu)]:=\Exp_{p\times\mu}[\Exp_{\nu_D}[\U]]=\Exp_\mu[\Exp_{\nu_D}[\Exp_p[\U]]]$$.
%	This exchange is legitimate because $\Omega$ and each $D$ are finite, so it's exchanging an integral with two finite sums. It is also legitimate without the assumption that each $D$ is finite (we mentioned the possibility that it is merely compact), as $\U$ is bounded, so it is absolutely integrable and by Fubini's theorem, integrals can be exchanged at will. 
%	
%	One can observe that this obtains it optimum when each $\nu_D(\EU_p(D))=1$, putting maximal weight on those acts which maximise expected utility, and reaches this maximal exactly when $\nu_D(\EU_p(D))=1$ for $\mu$-almost every $D\in\D$. 
%
%
%\end{proof}

\begin{theorem}\label{thm:EU-appendix} 
	\hspace*{1mm}
	\begin{enumerate}[label=\normalfont(\roman*), ref=\roman*]
		\item  If $\n$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$ then, for any $\n'$, $\Exp_b[\U(\n)]\geq\Exp_b[\U(\n')]$
		\item  If $\n$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$ and $\n'$ does not, then $\Exp_b[\U(\n)]>\Exp_b[\U(\n')]$.
	\end{enumerate}
\end{theorem}
\begin{proof}

%$b$ is a measure on $\Omega\times\D$. $\Omega$ finite, we consider all subsets measurable; it is a standard Borel space. 
%Given the utility, $\Decs$ can be considered as finite subsets of $[-M,M]^{|\Omega|}\subseteq\Re^n$; again a standard Borel space. 
%So it admits a regular conditional probability kernel $b(\cdot \given D):\Omega\to [0,1]$ for $b_\D$-almost every $D$. Where 

As in \cref{sect:appendix:decdep}, we have $b(\cdot\given D)$ defined for $b_\Decs$-almost every $D$ such that, for every bounded measurable random variable $X:\Omega\times\Decs\to\Re$, the law of total expectation holds: $\Exp_b[X]=\Exp_{b_\Decs}[\Exp_{b(\cdot|D)}[X]]$.

$\U(\n)$ is a measurable random variable on $\Omega\times\Decs$; and, since we have assumed that $\U$ is bounded above and below, $\U(\n)$ is bounded. And so, $\Exp_{b}[\U(\n)]=\Exp_{b_\Decs}[\Exp_{b(\cdot | D)}[\U(\n)]]$. 


Consider any $D^*\in\D$ for which $b(\cdot\given D^*)$ is well defined. Then\footnote{More carefully:
	\begin{align}
		\Exp_{b(\cdot | D^*)}[\U(\n)(\cdot,D^*)]&=	\sum_{\omega\in\Omega}b(\omega| D^*)\sum_{a\in D^*}\n_{D^*}(a)\; \U(a)(\omega)&&\text{definition of $\U(\n)$}\\
		&=\sum_{a\in D^*}\n_{D^*}(a)\sum_{\omega\in\Omega}b(\omega| D^*)\;\U(a)(\omega)
\end{align}	}
 $$\Exp_{b(\cdot | D^*)}[\U(\n)]=\Exp_{b(\cdot | D)}[\Exp_{\nu_{D^*}}[\U]]=\Exp_{\nu_{D^*}}[\Exp_{b(\cdot | D)}[\U]].$$

$\Exp_{b(\cdot | D^*)}[\U(a)]$ is maximised, by definition, at any $a\in \EU_{b(\cdot|-)}(D^*)$. 

Thus, $\Exp_{b(\cdot | D^*)}[\U(\n)]=\Exp_{\nu_{D^*}}[\Exp_{b(\cdot | D^*)}[\U]]$ is maximised when $\n_{D^*}(\EU_{b(\cdot|-)}(D^*))=1$. 

And so $\Exp_{b}[\U(\n)]=\Exp_{b_\Decs}[\Exp_{b(\cdot | D)}[\U(\n)]]$ is maximised when $\n_{D^*}(\EU_{b(\cdot|-)}(D))=1$ for $b_\Decs$-almost every $D$. 
i.e., when $\n$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$. 
Our claims follow from this.
%
%
%
%Consider any $D^*\in\D$ for which $b(\cdot\given D^*)$ is well defined. Then
%\begin{align}
% &	\Exp_{\omega\sim b(\cdot | D^*)}[\U(\n)(\omega,D^*)]\\
% 	&=\Exp_{\omega\sim b(\cdot | D^*)}[\Exp_{a\sim \n_{D^*}}[\U(a)(\omega)]]&&\text{definition of $\U(\n)$}\\
% 	&=\Exp_{a\sim\n_{D^*}}[\Exp_{\omega\sim b(\cdot | D^*)}[\U(a)(\omega)]].&&\text{$\Omega$ and $D^*$ are finite.}
% \end{align}
% \todo{I thought I stopped using this notation, but seems not...}
%
%
%$\Exp_{\omega\sim b(\cdot | D^*)}[\U(a)(\omega)]$ is maximised, by definition, at any $a\in\EU_{b(\cdot|-)}(D^*)$. Thus $\Exp_{a\sim\n_{D^*}}[\Exp_{\omega\sim b(\cdot | D^*)}[\U(a)(\omega)]]$ is maximised just when $\n_{D^*}(\EU_{b(\cdot|-)}(D^*))=1$.
%
%Thus, $\Exp_{b}[\U(\n)]=\Exp_{b_\Decs}[\Exp_{b(\cdot | D)}[\U(\n)]]$ is maximised just when for $b_\Decs$ almost every $D$,  $\n_{D^*}(\EU_{b(\cdot|-)}(D))=1$, which is to say that $\n$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$. 
%
%
%Observe that $\Exp_{b(\cdot | D)}[\U(\n)]=\Exp_{\nu_{D^*}}[\Exp_{b(\cdot|D^*)}[\U]]$.
%\begin{align}
%	\Exp_{b(\cdot | D)}[\U(\n)(D,\omega)]&=\Exp_{b(\cdot| D)}[\Exp_{\n_D}[\U(a)(\cdot)]]&&\text{definition  of $\U(\n)$}\\
%	&=\Exp_{\n_D}[\Exp_{b(\cdot | D)}[\U(a)]]&&\text{ as both are just finite weighted sums.\footnote{\begin{align}
%					\sum_{\omega\in\Omega}b(\omega| D)\sum_{a\in D}\n_D(a)\; \U(a)(\omega)&&\text{definition of $\U(\n)$}\\
%				&=\sum_{a\in D}\n_D(a)\sum_{\omega\in\Omega}b(\omega| D)\;\U(a)(\omega)\\
%	\end{align}}}
%\end{align}	
%
%Consider any $D^*\in\D$ for which $b(\cdot\given D^*)$ is well defined. Then 
%		$\Exp_{b(\cdot | D^*)}[\U(\n)(\cdot,D^*)]
%		%=\Exp_{b(\cdot | D^*)}[\Exp_{\n_{D^*}}[\U]]$ by the definition of $\U(\n)$, which $
%		=\Exp_{\n_{D^*}}[\Exp_{b(\cdot | D^*)}[\U]]$.
%More carefully:
%\begin{align}
%	\Exp_{b(\cdot | D^*)}[\U(\n)(\cdot,D^*)]&=	\sum_{\omega\in\Omega}b(\omega| D^*)\sum_{a\in D^*}\n_{D^*}(a)\; \U(a)(\omega)&&\text{definition of $\U(\n)$}\\
%				&=\sum_{a\in D^*}\n_{D^*}(a)\sum_{\omega\in\Omega}b(\omega| D^*)\;\U(a)(\omega)
%\end{align}	
%
%$a\in\EU_{b(\cdot|-)}(D^*)$, by definition, iff it is a maximiser within $D^*$ of  $\Exp_{b(\cdot| D^*)}[\U(a)]=\sum_{\omega\in\Omega}b(\omega| D^*)\;\U(a)(\omega)$. Let this maximum value be $t_b(D^*)$.
%
%Thus, $\Exp_{b(\cdot | D^*)}[\U(\n)(D^*)]\leq t_b(D^*)$ with equality just when $\n_{D^*}$ is supported on $\EU_{b(\cdot | -)}(D^*)$.
%
%Thus $
%	\Exp_{b}[\U(\n)]=\Exp_{b_\Decs}[\Exp_{b(\cdot | D)}[\U(\n)]]
%$
%obtains its maximum at $\Exp_{b_\Decs}[t_b(D)]$ when $\n_D(\EU_{b(\cdot|-)}(D))=1$ for $b_\D$-almost all $D$, i.e., when $\n$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$.
\end{proof}
\begin{corollary}\label{thm:EU-appendix corollary}
	\begin{enumerate}[label=\normalfont(\roman*), ref=(\roman*)]
		\item\label{itm:eu-1} If $\nu$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$ then $\nu\in\EU_b(\Nu)$.
		\item \label{itm:eu-2}Suppose $\Nu$ contains some $\nu^b$ that picks for $\EU_{b(\cdot|-)}$.  Then $\nu\in\EU_b(\Nu)$ iff $\nu$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$.
		\todo{I changed the statement of this so it's clearer.}
	\end{enumerate}
\end{corollary}
\begin{proof}
	\ref{itm:eu-1} is immediate from \cref{thm:EU-appendix}. 
	
	For \ref{itm:eu-2}, if $\nu$ does not $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$, then \cref{thm:EU-appendix} implies that $\Exp_b[\U(\nu^b)]>\Exp_b[\U(\nu)]$, so $\nu\notin\EU_b(\Nu)$. 
\end{proof}

This suffices to prove \cref{thm:eu-self-rec,thm:eu-uniquely-optimal,thm:eu-nu-nec-suff,thm:eu-dep}.

%\end{colored}



%\begin{colored}{red}
%	
%\subsection{EU}
%Our first series of results rely on the fact that a picking strategy is an optimiser of expected utility iff it is an expected utility picking strategy (or at least looks like one, i.e., is $\mu$-surely one). This core result, stated in \cref{thm:eu-self-rec,thm:eu-uniquely-optimal}, is then extended to cover cases of act-state dependence (\cref{thm:eu-dep}) and probabilistic picking strategies (\cref{thm:eu-nu-nec-suff}). 
%
%
%We present our result in generality, covering both the decision-state dependence and probabilistic picking strategy cases. 
%
%Suppose $b$ is probability measure over $\Omega\times\D$ which is absolutely continuous with respect to $u\times\lambda$, where $u$ is the uniform distribution on $\Omega$ and $\lambda$ is the restriction of the Lebesgue measure to $\D$\todo{What does that mean??}. Let $f:\Omega\times\D\rightarrow\mathbb{R}_{\geq0}$ be a Radon-Nikodym derivative (or density) of $b$, so that for any measurable $A\subseteq\Omega\times\D$
%\[
%b(A)=\sum_{\omega\in\Omega}\int_{A_\omega} f(\omega,D) \frac{1}{|\Omega|}\diff\lambda(D)
%\]
%where, for any $\omega\in\Omega$, $A_\omega:=\left\{\left<\omega^*,D^*\right>\in A\given \omega=\omega^*\right\}$.
%
%The marginal density, $f_\D$, is given by $f_\D(D)=\sum_{\omega\in\Omega}f(\omega,D)$. 
%
%	
%Let $\D':=\{D\in\D\given f_\D(D)>0\}$.
%
%\begin{definition}
%	For any $D\in\D'$ and any $a\in D$, $b(\cdot|D)$ is a probability function over $\Omega$ defined by $b(\omega|D)=\frac{f(\omega,D)}{f_\D(D)}$. \todo{why do we sometimes use angle brackets?}
%	So,  \[\Exp_{b(\cdot|D)}[\U(a)]:=\displaystyle\sum_{\omega\in\Omega}\frac{f(\omega,D)}{f_\D(D)}\U(a)(\omega)\]
%\end{definition}
%	
%	Recall \cref{def:cond}, defining the choice function $\EU_{b(\cdot|-)}$: For $D\in\D'$ (when this is well-defined), $\EU_{b(\cdot|-)}(D)=\EU_{b(\cdot|D)}(D)$, which, using \cref{def:EU} is 
%		\[a\in\EU_{b(\cdot|-)}(D)\text{ iff for all $a'\in D$, }\Exp_{b(\cdot|D)}[\U(a)]\geq\Exp_{b(\cdot|D)}[\U(a')].\]
%	If $D\notin\D'$, we can put $\EU_{b(\cdot|-)}(D)$ arbitrary, for example just make it equal $\D$. 
%	A picking strategy $\s\in\S$ is then said to $b_\Decs$-surely pick for $\EU_{b(\cdot|-)}$ when \[b\{\seq{\omega,D}\given\omega\in\Omega,\, \s(D)\in \EU_{b(\cdot|-)}(D)\}=1\] i.e., for the marginal $b_\D$, $b_\D\{D\given \s(D)\in\EU_{b(\cdot|-)}(D)\}=1$. A probabilistic picking strategy $\n$ is said to $b_\Decs$-surely pick for $\EU_{b(\cdot|-)}$ when \[b\{\seq{\omega,D}\given\n_D(\EU_{b(\cdot|-)}(D))=1\}=1\]
%
%
%	
%%\begin{definition}
%%	$\EU_{b(\cdot|-)}$ is the choice function defined by \[\EU_{b(\cdot|-)}(D):=\EU_{b(\cdot|D)}(D)\]when $D\in\D'$, i.e., when $f_\D(D)>0$; and when $D\notin\D'$, we put $\EU_{b(\cdot|-)}(D)=D$ (this is arbitrary, and it won't play a role in our result).\todoold{I added the when def!!} 
%%\end{definition}
%%
%%
%%\todo{we should make the theorem already cover the prob case!!}
%%\begin{definition}
%%A picking strategy $\s$ \emph{$b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$} iff \[b\{\seq{\omega,D}\given\omega\in\Omega,\, \s(D)\in \EU_{b(\cdot|-)}(D)\}=1\] i.e., for the marginal $b_\D$, $b_\D\{D\given \s(D)\in\EU_{b(\cdot|-)}(D)\}=1$.
%%\end{definition}
%
%\begin{theorem}\label{thm:EU-appendix} 
%	\begin{enumerate}[label=\normalfont(\roman*), ref=\roman*]
%		\item  If $\nu$ $\mu$-surely picks for $\EU_{p}$ then, for any $\nu'$, $\Exp_{p\times\mu}[\U(\nu)]\geq\Exp_{p\times\mu}[\U(\nu')]$
%		\item  If $\nu$ $\mu$-surely picks for $\EU_{p}$ and $\nu'$ does not, then $\Exp_{p\times\mu}[\U(\nu)]>\Exp_{p\times\mu}[\U(\nu')]$.
%	\end{enumerate}
%\end{theorem}
%\begin{proof}
%	The basic reason is by exchange of expectations: $$\Exp_{p\times\mu}[\U(\nu)]:=\Exp_{p\times\mu}[\Exp_{\nu_D}[\U]]=\Exp_\mu[\Exp_{\nu_D}[\Exp_p[\U]]]$$. The exchange is .
%	 and one can observe that this obtains it optimum when each $\nu_D(\EU_p(D))=1$, putting maximal weight on those acts which maximise expected utility, and reaches this maximal exactly when $\nu_D(\EU_p(D))=1$ for $\mu$-almost every $D\in\D$. 
%	
%	
%	
%	
%	
%	For maximum perspicuity, we will write everything out with integrals, to keep track of the variables. However, note that $\Omega$ and each $D$ have been assumed to be finite. 
%	
%	Let $t_p(D):=\sup_{a\in D}\Exp_p[\U(a)]$, the maximum attainable expected utility on $D$. $\EU_p(D)=\{a\in D\given \Exp_p[\U(a)]=t_p(D)\}$.
%	$\nu_D$ is a measure over $D$, so:
%	\begin{align}
%		\int_D \Exp_p[\U(a)]\;\nu_D(\diff a)&\leq t_p(D)\\
%			\text{ and }	\int_D \Exp_p[\U(a)]\;\nu_D(\diff a)&= t_p(D)\text{ iff }\nu_D(\EU_p(D))=1
%	\end{align}
%	
%	Therefore 
%	\begin{align}
%	\int_\D\int_D \Exp_p[\U(a)]\;\nu_D(\diff a)\mu(\diff D)&\leq \int_\D t_p(D)\mu(\diff D)\\
%	\text{ and }	\int_\D\int_D \Exp_p[\U(a)]\;\nu_D(\diff a)\mu(\diff D)&= \int_\D t_p(D)\mu(\diff D)\\\text{ iff }\mu\{D\given \nu_D(\EU_p(D))=1\}=1
%\end{align}
%	
%	So for all $a\in D$, $\Exp_p[\U(a)]\leq t_p(D)$, with equality just when $a\in \EU_p(D)$. 
%	
%	$\nu_D$ is a measure over $D$ ($D$ is finite, but we write it as an integral for), so $\Exp_{\nu_D}[\Exp_p[\U]]\leq t_p(D)$, with equality just when $\nu_D(\EU_p(D))=1$. 
%	
%	Thus, $\Exp_\mu[\Exp_{\nu_D}[\Exp_p[\U]]]\leq \Exp_\mu[t_p(D)]$, with equality just when $\mu\{D\given \nu_D(\EU_p(D))=1\}=1$. 
%	
%	Now, observe that $\Exp_{p\times\mu}[\U(\nu)]=$
%	
%\end{proof}
%
%\begin{theorem}\label{thm:EU-appendix} 
%	\begin{enumerate}[label=\normalfont(\roman*), ref=\roman*]
%	\item  If $\nu$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$ then, for any $\nu'$, $\Exp_b[\U(\nu)]\geq\Exp_b[\U(\nu')]$
%	\item  If $\nu$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$ and $\nu'$ does not, then $\Exp_b[\U(\nu)]>\Exp_b[\U(\nu')]$.
%\end{enumerate}
%\end{theorem}
%\begin{proof}
%
%
%\end{proof}
%
%
%
%\begin{theorem}\label{thm:EU-appendix} 
%	\hspace*{1mm}
%	\begin{enumerate}[label=\normalfont(\roman*), ref=\roman*]
%		\item  If $\s$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$ then, for any $\s'$, $\Exp_b[\U(\s)]\geq\Exp_b[\U(\s')]$
%		\item  If $\s$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$ and $\s'$ does not, then $\Exp_b[\U(\s)]>\Exp_b[\U(\s')]$.
%	\end{enumerate}
%\end{theorem}
%
%
%\begin{proof}
%	For any $\omega\in\Omega$ and $D\in\D'$, let $t_b(\omega,D):=\sup\{\Exp_{b(\cdot|D)}[\U(a)]\given a\in D\}$. We can define it arbitrarily for $D\notin \D'$. 
%	Note that $t_b(\omega,D)$ only depends on $D$. Nevertheless, we define it as a function on $\Omega\times\D$ in order to take expectations relative to $b$. 
%	
%	Suppose $D\in\D'$. By definition of $t_b$, $\Exp_{b(\cdot|D)}[\U(a)]\leq t_b(\omega^*,D)$ for any $\omega^*\in\Omega$. 
%	For $\n$ a probabilistic picking strategy, $\n_D$ is a measure over $D$, so $\U(\n)(\omega,D):=\Exp_{\n_D}[\U(a)(\omega)]=\sum_{a\in D}\n_D(a)(\omega)$. Since 
%	
%	By definition of $\EU_{b(\cdot|-)}(D)$, $\Exp_{b(\cdot|D)}[\U(a)]= t_b(\omega^*,D)$ exactly when $a\in \EU_{b(\cdot|-)}(D)$. 
%	
%	
%	
%	Now, 
%	
%	%	Observe that $\Exp_{b(\cdot|D)}[\U(a)]\leq t_b(\omega,D)$ for all $a\in D$, with equality iff $a\in \EU_{b(\cdot|-)}(D)$, by definition of .\todoold{this is only true for $D\in\D'$!}
%	
%	%	Let $\X:=\{\left<\omega,D\right>\in\Omega\times\D\given f_\D(D)>0\}$.
%	
%	%	For any $\omega\in\Omega$, let $\X_\omega:=\left\{\left<\omega^*,D^*\right>\in\X\given \omega=\omega^*\right\}$.	
%	
%	%	For any $\omega\in\Omega$, let $\X_\omega:=\left\{\left<\omega,D\right>\given D\in\D'\right\}$.	
%	
%	
%	
%	{\allowdisplaybreaks
%		\begin{align}
%			\Exp_b[\U(\n)]&=\sum_{\omega\in\Omega}\int_{\D} \U(\n)(\omega,D) f(\omega,D) \frac{1}{|\Omega|}\diff\lambda(D)\\
%			&=\sum_{\omega\in\Omega}\int_{\D'} \U(\n)(\omega,D) f(\omega,D) \frac{1}{|\Omega|}\diff\lambda(D)\\
%			&=\int_{\D'}\left[\sum_{\omega\in\Omega}\frac{f(\omega,D)}{f_\D(D)}\U(\n)(\omega,D)\right]f_\D(D)\frac{1}{|\Omega|}\diff\lambda(D)\\
%			&=\int_{\D'}\Exp_{b(\cdot|D)}[\U(\n)(\omega,D)]\;f_\D(D)\frac{1}{|\Omega|}\diff\lambda(D)\\
%			&=\sum_{\omega\in\Omega}\int_{\D'}\Exp_{b(\cdot|D)}[\U(\n)(\omega,D)]\;f(\omega,D)\frac{1}{|\Omega|}\diff\lambda(D)\\
%			&\leq\sum_{\omega\in\Omega}\int_{\D'}t_b(\omega,D)f(\omega,D)\frac{1}{|\Omega|}\diff\lambda(D)\\
%			&=\sum_{\omega\in\Omega}\int_{\D}t_b(\omega,D)f(\omega,D)\frac{1}{|\Omega|}\diff\lambda(D)\\
%			&=\Exp_b[t_b]
%	\end{align}}
%	
%	Thus, $\Exp_b[\U(\s)]\leq \Exp_b [t_b]$ with equality iff $\Exp_{b(\cdot|D)}[\U(\n)(\omega,D)]=t_b(\omega,D)$ almost everywhere, which is true iff $b\{\left<\omega,D\right> \in \Omega\times\D \given \s(D)\in \EU_{b(\cdot|-)}(D)\}=1$, i.e., iff $\s$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$. Both (i) and (ii) follow immediately from this.
%\end{proof}
%
%\begin{color}{red}
%\begin{theorem}\label{thm:EU-appendix} 
%\hspace*{1mm}
%	\begin{enumerate}[label=\normalfont(\roman*), ref=\roman*]
%		\item  If $\s$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$ then, for any $\s'$, $\Exp_b[\U(\s)]\geq\Exp_b[\U(\s')]$
%		\item  If $\s$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$ and $\s'$ does not, then $\Exp_b[\U(\s)]>\Exp_b[\U(\s')]$.
%	\end{enumerate}
%\end{theorem}
%
%
%\begin{proof}
%	For any $\omega\in\Omega$ and $D\in\D'$, let $t_b(\omega,D):=\sup\{\Exp_{b(\cdot|D)}[\U(a)]\given a\in D\}$. We can define it arbitrarily for $D\notin \D'$. 
%	Note that $t_b(\omega,D)$ only depends on $D$. Nevertheless, we define it as a function on $\Omega\times\D$ in order to take expectations relative to $b$. 
%	
%	Suppose $D\in\D'$. By definition of $t_b$, $\Exp_{b(\cdot|D)}[\U(a)]\leq t_b(\omega^*,D)$ for any $\omega^*\in\Omega$. By definition of $\EU_{b(\cdot|-)}(D)$, $\Exp_{b(\cdot|D)}[\U(a)]= t_b(\omega^*,D)$ exactly when $a\in \EU_{b(\cdot|-)}(D)$.
%	
%	Now, 
%	
%%	Observe that $\Exp_{b(\cdot|D)}[\U(a)]\leq t_b(\omega,D)$ for all $a\in D$, with equality iff $a\in \EU_{b(\cdot|-)}(D)$, by definition of .\todoold{this is only true for $D\in\D'$!}
%	
%%	Let $\X:=\{\left<\omega,D\right>\in\Omega\times\D\given f_\D(D)>0\}$.
%	
%%	For any $\omega\in\Omega$, let $\X_\omega:=\left\{\left<\omega^*,D^*\right>\in\X\given \omega=\omega^*\right\}$.	
%	
%%	For any $\omega\in\Omega$, let $\X_\omega:=\left\{\left<\omega,D\right>\given D\in\D'\right\}$.	
%
%	
%
%{\allowdisplaybreaks
%\begin{align}
%\Exp_b[\U(\s)]&=\sum_{\omega\in\Omega}\int_{\D} \U(\s(D))(\omega) f(\omega,D) \frac{1}{|\Omega|}\diff\lambda(D)\\
%&=\sum_{\omega\in\Omega}\int_{\D'} \U(\s(D))(\omega) f(\omega,D) \frac{1}{|\Omega|}\diff\lambda(D)\\
%&=\int_{\D'}\left[\sum_{\omega\in\Omega}\frac{f(\omega,D)}{f_\D(D)}\U(\s(D))(\omega)\right]f_\D(D)\frac{1}{|\Omega|}\diff\lambda(D)\\
%&=\int_{\D'}\Exp_{b(\cdot|D)}[\U(\s(D))]f_\D(D)\frac{1}{|\Omega|}\diff\lambda(D)\\
%&=\sum_{\omega\in\Omega}\int_{\D'}\Exp_{b(\cdot|D)}[\U(\s(D))]f(\omega,D)\frac{1}{|\Omega|}\diff\lambda(D)\\
%&\leq\sum_{\omega\in\Omega}\int_{\D'}t_b(\omega,D)f(\omega,D)\frac{1}{|\Omega|}\diff\lambda(D)\\
%&=\sum_{\omega\in\Omega}\int_{\D}t_b(\omega,D)f(\omega,D)\frac{1}{|\Omega|}\diff\lambda(D)\\
%&=\Exp_b[t_b]
%\end{align}}
%
%	Thus, $\Exp_b[\U(\s)]\leq \Exp_b [t_b]$ with equality iff $\Exp_{b(\cdot|D)}[\U(\s(D))]=t_b(\omega,D)$ almost everywhere, which is true iff $b\{\left<\omega,D\right> \in \Omega\times\D \given \s(D)\in \EU_{b(\cdot|-)}(D)\}=1$, i.e., iff $\s$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$. Both (i) and (ii) follow immediately from this.
%	\end{proof}
%
%
%\begin{theorem}\label{thm:EU-appendix}Suppose $p$ is a probability function over $\Omega$ and $\mu$ is a measure over $\D$. Then:
%	\begin{enumerate}
%		\item  If $\n$ $\mu$-surely picks for $\EU_p$ then, for any $\n'$, $\EU_{p\times\mu}[\U(\n)]\geq\EU_{p\times\mu}[\U(\n')]$
%		\item If $\n$ $\mu$-surely picks for $\EU_p$, and $\n'$ does not, then $\EU_{p\times\mu}[\U(\n)]>\EU_{p\times\mu}[\U(\n')]$.
%	\end{enumerate}
%\end{theorem}
%\begin{proof}
%	Let $m_D(p):=\sup\{\Exp_p[\U(a)]\given a\in D\}$.
%	
%	So $\Exp_p[\U(a)]\leq m_D(p)$ for all $a\in D$, with equality only if $a\in \EU_p(D)$. 
%	
%	Since $\n_D$ is a probability over $D$, we know that $\Exp_{\n(D)}\Exp_p[\U]\leq m_D(p)$ with equality only if $\n_D(\EU_p(D))=1$. And note that $\Exp_{\n(D)}\Exp_p(a)=\Exp_p[\U(\n)(D)]$
%%	
%%	{\color{cyan}
%%		If $P$ is probability over $\Omega\times\D$, 
%%		$\Exp_P[\U(\n)]=\Exp_{P(\D)}\Exp_{P(\cdot|D)}[\U(\n)]$. This is a standard fact about iterated expectations. We have shown that $\Exp_{P(\cdot|D)}[\U(\n)]\leq m_D(p(\cdot|D))$, with equality iff $\n_D(\EU_{P(\cdot|D)}(D))=1$. Thus, $\Exp_P[\U(\n)]\leq\Exp_{P(\D)} m_D(p(\cdot|D))$ with equality only if $P(\{D\given\n_D(\EU_{P(\cdot|D)}(D))=1 \}=1$, i.e., only if $\n$ $P$-surely picks for $\EU_P$.)
%%		
%%%		$\Exp_P[\U(\n)]=\sum_{D\text{ s.t., }P(D)\neq 0} P(D)\sum_\omega \frac{P(D\wedge\omega)}{P(D)}\U(\n,D,\omega)$
%%		}
%		
%	Thus, $\EU_{p\times\mu}[\U(\n)]\leq \Exp_\mu [t(p)]$ with equality only if $\mu\Set {D \given \n_D(\EU_p(D))=1} = 1$, i.e., only if $\n$ $\mu$-surely picks for $\EU_p$. 
%%	By definition of $\EU_p$, we have that $a\in\EU_p(D)$ iff $\Exp_p\U(a)\geq \Exp_p\U(b)$ for all $b\in D$. 
%%	So if $a\in\EU_p(D)$ and $b\in D\setminus \EU_p(D)$ then $\Exp_p\U(a)>\Exp_p\U(b)$.
%%	
%%	Let $m_{p,D}:=\Exp_p(a)$ for any $a\in\EU_p(D)$, observing that this exists because we have assumed $D$ is finite so $\EU_p(D)\neq\emptyset$, and that it is well-defined because any $a,a'\in\EU_p(D)$ have $\Exp_p(a)=\Exp_p(a')$. 
%%	
%%	Thus, if $\n_D(\EU_p(D))=1$, then $\Exp_{\n(D)}\Exp_p(a)=m_{p,D}$. 
%%	And if $\n_D(\EU_p(D))\neq 1$, then $\Exp_{\n(D)}\Exp_p(a)<m_{p,D}$.
%%	
%%	Thus, if $\n$ does $\mu$-surely pick for $\EU_p$, i.e., $\mu\{D\given \n_D(\EU_p(D))=1\}=1$, then $\Exp_\mu\Exp_{\n(D)}\Exp_p(a)=\Exp_\mu m_{p,D}$
%%	
%%	If $\n$ does not $\mu$-surely pick for $\EU_p$, then $\mu\{D\given \n_D(\EU_p(D))\neq 1\}>0$, then $\Exp_\mu\Exp_{\n(D)}\Exp_p(a)<\Exp_\mu m_{p,D}$. 
%%	
%%	Observe that $\EU_{p\times\mu}\Exp_{\n(D)}a=\Exp_\mu\Exp_{\n(D)}\Exp_p(a)$ by interchange of expectations. This obtains our result. \todooldinfo{is this cleaner than RPs writeup?}
%\end{proof}
%\end{color}
%
%
%All the theorems about Expected Utility Theory and E-Admissibility, as well as the existence of Maximality strategies can be seen as quick corollaries of this: 
%\Cref{thm:eu-self-rec,thm:eu-uniquely-optimal,thm:eu-nu-nec-suff,thm:eu-dep}
%%\cref{thm:eu-self-rec,thm:eu-uniquely-optimal,thm:eu-nu-nec-suff,thm:eu-dep,thm:ead-equiv[indep],thm:ead-existence[dep],thm:ead-existsimpermissibel[indep],thm:ead-nu-nec-suff,thm:ead-nu-reg-nec,thm:ead-suff-indep,thm:max-suff,thm:max-suff[dep],thm:max-nu-suff,thm:ead-equiv[dep]}
%
%\begin{comment}
%	
%In fact, we can create a version of this result allowing dependence between the decision problem you're faced with and the state of the world, assuming that when you make a decision you first conditionalise your probabilities on which decision problem you're faced with and then use expected utility using that updated probability to make the decision. 
%This is because $\Exp_b[\U(\n)]=\Exp_{b_\D}\Exp_{b(\cdot|D)}[\U(\n)]$, where $b_\D$ is the marginal. Each $\Exp_{b(\cdot|D)}[\U(\n)]$ is maximised when $\n_D(\EU_{b(\cdot|D)}(D))=1$, at least, whenever this is well-defined. So, similarly, $\Exp_b[\U(\n)]$  is maximised when $b_\D\{D\given \n_D(\EU_{b(\cdot|D)}(D))=1\}=1$.
%\end{comment}
%
%%Since, 
%%		If $P$ is probability over $\Omega\times\D$, 
%%$\Exp_P[\U(\n)]=\Exp_{P(\D)}\Exp_{P(\cdot|D)}[\U(\n)]$. This is a standard fact about iterated expectations. We have shown that $\Exp_{P(\cdot|D)}[\U(\n)]\leq t_D(p(\cdot|D))$, with equality iff $\n_D(\EU_{P(\cdot|D)}(D))=1$. Thus, $\Exp_P[\U(\n)]\leq\Exp_{P(\D)} t_D(p(\cdot|D))$ with equality only if $P(\{D\given\n_D(\EU_{P(\cdot|D)}(D))=1 \}=1$, i.e., only if $\n$ $P$-surely picks for $\EU_P$.)
%
%
%
%
%\end{colored}

%\begin{colored}{violet}
%\subsection{E-Admissibility}
\subsection{E-Admissibility and EU equivalences\\  (\cref{thm:ead-existence[dep],thm:ead-existence[indep],thm:ead-equiv[dep],thm:ead-equiv[indep],thm:ead-nu-nec-suff})}\label{sect:EAd-EU-appendix}
The results just stated imply many of the results about E-Admissible strategies.

We will again state the results for probabilistic picking strategies, $\nu$. The results concerning deterministic picking strategies, $\s$, are then special cases, recalling that, when $\Nu=\S$, the same definitions apply.
 
%Judgements about strategies being E-Admissible are as follows:
\begin{lemma}\label{thm:appendix:ead:strategiesjudge}\ 
	\begin{enumerate}[label=\normalfont(\roman*), ref=\roman*]
		\item $\nu\in\EAd_\IB(\Nu)$ iff there is some $b\in\IB$ such that $\nu\in\EU_b(\Nu)$.  
		\item If $p\times\mu\in \IB$ and $\nu\in\EU_{p\times\mu}(\Nu)$, then $\nu\in\EAd_\IB(\Nu)$ 
		\item If $\IB$ makes $\Omega$ and $\Decs$ completely independent, then $\nu\in\EAd_\IB(\Nu)$ iff there is some $p\times\mu\in\IB$ such that $\nu\in\EU_{p\times\mu}(\Nu)$.  
	\end{enumerate}
\end{lemma}
\begin{proof}
	Immediate from definitions. 
\end{proof}
We introduce a new definition that encompasses the notions of $\EU$-completeness and conditional-$\EU$-completeness given in \cref{def:EU-complete}, by specifying the set for which the set of picking strategies is $\EU$-complete: 
\begin{definition}
	$\Nu$ is $\EU$-complete for $\IB$ iff for every $b\in\IB$, there is some $\nu^b\in\Nu$ such that $\nu^b$ picks for $\EU_{b(\cdot|-)}$. 
\end{definition}
Note that, if $\Nu$ is deterministically full, i.e., $\Nu\supseteq\S$, then it is $\EU$-complete for any $\IB$. 
\begin{corollary}\label{thm:appendix:ead:eu}
	Suppose $\Nu$ is $\EU$-complete for $\IB$.
	\begin{enumerate}[label=\normalfont(\roman*), ref=(\roman*)]
		\item $\nu\in\EAd_\IB(\Nu)$ iff there is some $b\in\IB$ such that $\nu$ $b_\Decs$-picks for $\EU_{b(\cdot|-)}$.  
		\item \label{itm:ead:2}If $p\times\mu\in \IB$ and $\nu$ $\mu$-surely picks for $\EU_p$, then $\nu\in\EAd_\IB(\Nu)$.
		\item If $\IB$ makes $\Omega$ and $\Decs$ completely independent, then $\nu\in\EAd_\IB(\Nu)$ iff there is some $p\times\mu\in\IB$ such that $\nu$ $\mu$-surely picks for $\EU_p$.
	\end{enumerate}
\end{corollary}
\begin{proof}
	Immediate from \cref{thm:appendix:ead:strategiesjudge,thm:EU-appendix}.
\end{proof}
This gives \cref{thm:ead-equiv[indep],thm:ead-nu-nec-suff,thm:ead-equiv[dep]}. For \cref{thm:ead-existence[dep],thm:ead-existence[indep]}, we will use a further lemma. 


\begin{lemma}\label{thm:appendix:ead:pickingeu}\ 
	\begin{enumerate}[label=\normalfont(\roman*), ref=(\roman*)]
		\item\label{itm:appendix:ead:pickingeu:1} If $p\in \IP$ and $\nu$ picks for $\EU_p$, then $\nu$ picks for $\EAd_\IP$.
		\item\label{itm:appendix:ead:pickingeu:2}  If $b\in\IB$ and $\nu$ picks for $\EU_{b(\cdot|-)}$, then $\nu$ picks for $\EAd_{\IB(\cdot|-)}$. 
	\end{enumerate}
\end{lemma}
\begin{proof}
	It follows from the definition of $\EAd_\IP$ that, for all $D$ and $p \in \IP$, $\EU_p(D)\subseteq \EAd_\IP(D)$.
	
	If $\nu$ picks for $\EU_p$, then for all $D\in\Decs$, $\nu_D(\EU_p(D))=1$. And so, since  $\EU_p(D)\subseteq \EAd_\IP(D)$, $\nu_D(\EAd_\IP(D))=1$, i.e.~$\nu$ picks for $\EAd_\IP$. 
	
	An analogous argument gives \ref{itm:appendix:ead:pickingeu:2}, as,  for all $D$, $\EU_{b(\cdot|-)}(D)\subseteq\EAd_{\IB(\cdot|-)}(D)$. 
\end{proof}

\begin{corollary}\label{thm:appendix:ead:exists}\ 
	\begin{enumerate}[label=\normalfont(\roman*), ref=(\roman*)]
		\item \label{itm:ead:blah1}Suppose $p\in\IP$,  $p\times\mu\in\IB$ and $\nu$ picks for $\EU_p$. Then $\nu$ picks for $\EAd_\IP$ and is in $\EAd_\IB(\Nu)$. 
		\item \label{itm:ead:blah2}Suppose $b\in\IB$ and $\nu$ picks for $\EU_{b(\cdot|-)}$. Then $\nu$ picks for $\EAd_{\IB(\cdot|-)}$ and is in $\EAd_\IB(\Nu)$. 
	\end{enumerate}
\end{corollary}
\begin{proof}
	\ref{itm:ead:blah1}: From \cref{thm:appendix:ead:pickingeu}, $\nu$ picks for $\EAd_\IP$. By \cref{thm:appendix:ead:eu}, $\nu\in\EAd_\IB(\Nu)$. 
	
	\ref{itm:ead:blah2}: From \cref{thm:appendix:ead:pickingeu}, $\nu$ picks for $\EAd_{\IB(\cdot|-)}$. By \cref{thm:appendix:ead:eu}, $\nu\in\EAd_\IB(\Nu)$. 
\end{proof}
\cref{thm:ead-existence[indep],thm:ead-existence[dep]} follow from this.



We have thus proved \cref{thm:ead-existence[dep],thm:ead-existence[indep],thm:ead-equiv[dep],thm:ead-equiv[indep],thm:ead-nu-nec-suff}. 


%
%
% \begin{proposition}[\cref{thm:ead-suff-indep}]
%	If $p\in\IP$ and $p\times\mu\in\IB$ then any $\s$ which picks for $\EU_p$ both picks for $\EAd_\IP$ and is in $\EAd_\IB(\S)$. 
%	
%	If there exists some $p$ and $\mu$ with $p\in\IP$ and $p\times\mu\in\IB$, then there are some strategies which pick for $\EAd_\IP$ and are in $\EAd_\IB(\S)$. 
%	
%	If for every $p\in\IP$ there is some $\mu$ such that $p\times\mu\in\IB$, then for every $D\in\Decs$ and $a\in\EAd_\IP(D)$, there is some $\s$ such that $\s(D)=a$ and $\s\in\EAd_\IB(\S)$. 
%\end{proposition}
%
%\begin{proposition}[\cref{thm:ead-equiv[indep]}] Suppose $\D$ and $\Omega$ are completely independent in $\IB$ (so that every $b\in\IB$ has the form $p\times\mu$). In that case, $\s\in\EAd_\IB(\Strategies)$ iff there is some $p\times \mu\in\IB$ where $\s$ $\mu$-surely picks for $\EU_p$. 
%	%	If $\s$ does not $\mu$-surely pick for $\EU_p$, for any $p\times \mu\in \IB$, then $\s$ is not in $\EAd_\IB(\Strategies)$.
%\end{proposition}
%
%	\begin{proposition}[\cref{thm:ead-equiv[dep]}]
%	$\s\in\EAd_\IB(\Strategies)$ iff for some $b$ in $\IB$, $\s$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$.
%	
%	Thus, there is some $\s$ which picks for  $\EAd_{\IB(\cdot|-)}$ and is in $\EAd_\IB(\Strategies)$, namely, for any $b\in\IB$, a strategy $\s$ which $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$.
%\end{proposition}
%
%\begin{proposition}[\cref{thm:ead-nu-nec-suff}]
%	If $\n$ picks for $\EU_p$ for some $p\times \mu\in \IB$, then $\n\in\EAd_\IB(\Nu)$. 
%	More generally, if for some $b\in\IB$, $\n$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$, then $\n\in\EAd_\IB(\Nu)$. 
%	
%	Moreover, these are the only members of $\EAd_\IB$, at least assuming that $\Nu$ is $\EU$-complete: 
%	$$\n \in \EAd_\IB(\Nu) \Leftrightarrow \text{for some $b$ in $\IB$, $\n$ $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$.}$$
%	%If $\IB$ is strongly complete, then: $\n \in \EAd_\IB(\negies) \Leftrightarrow \n \text{ $\mu$-surely picks for $\EU_p$, for some $p\times \mu$ in $\IB$.}
%	%\end{align}
%	
%	%If $\negies$ is $\EU$-complete, then $$\n \in \EAd_\IB(\negies) \Leftrightarrow \n \text{ $\mu$-surely picks for $\EU_p$, for some $p\times \mu$ in $\IB$.}$$
%\end{proposition}

\subsection{Maximality (\cref{thm:max-suff,thm:max-suff[dep],thm:max-nu-suff})}\label{sect:maximality-appendix}
As Maximality is a more permissive theory than E-Admissibility, \cref{thm:appendix:ead:exists,thm:appendix:ead:eu} also imply our results that the relevant expected utility strategies both pick for Maximality and are themselves judged as Maximal (\cref{thm:max-suff,thm:max-suff[dep],thm:max-nu-suff}); so that Maximality is not undermining in the way that we've seen the risk-sensitive decision theories or $\Gamma$-maximin are.

\subsection{Underminingness of E-Admissibility \\(\cref{thm:ead-existsimpermissible[indep],thm:ead-existsimpermissible[dep],thm:ead-nu-reg-nec})}\label{sect:appendix:eadundermining}

We now move to \cref{thm:ead-existsimpermissible[indep],thm:ead-existsimpermissible[dep],thm:ead-nu-reg-nec}. For these results, we need to give conditions under which there exists a strategy that picks for E-Admissibility and does not look like an expected utility strategy from the point of view of our measure $\mu$ over the decision problems. 

For regular picking strategies, this is simple: E-Admissibility must disagree with each $\EU_p$, at least $\mu$-surely.

	\begin{proposition}[\cref{thm:ead-nu-reg-nec}]
	Suppose that, for every $b\in\IB$, $b_\D\{D\given \EAd_{\IB(\cdot|-)}(D)\subseteq\EU_{b(\cdot|-)}(D)\}<1$. 
	%That is, for all $b\in \IB$, $b_\D\{D\given \text{there is $b'\in\IB$ with }\EU_{b'(\cdot|-)}(D)\not\subseteq\EU_{b(\cdot|-)}(D)\}>0$. 
	
	Then, if $\n$ is a regular picking strategy for $\EAd_{\IB(\cdot|-)}$, then $\n\notin \EAd_\IB(\Nu)$.
\end{proposition}

\begin{proof}
	Suppose $\nu$ is a regular picking strategy for $\EAd_{\IB(\cdot|-)}$ and the conditions of the theorem hold. 
	
	Take any $b\in\IB$.
	If $\EAd_{\IB(\cdot|-)}(D)\not\subseteq\EU_{b(\cdot|-)}(D)$, then, since $\n_D$ is a regular probability function, $\nu_D(\EU_{b(\cdot|-)}(D))< 1$. 
	Since 
	$b_\D\{D\given \EAd_{\IB(\cdot|-)}(D)\not\subseteq\EU_{b(\cdot|-)(D)}\}>0$, we have $\mu\{D\given \nu(\EU_{b(\cdot|-)}(D))<1\}>0$.
	 So $\nu$ does not $b_\Decs$-surely pick for $\EU_{b(\cdot|-)}$. 
	 
	 By \cref{thm:appendix:ead:eu}, it follows that $\nu\notin\EAd_\IB(\Nu)$. 
\end{proof}

To ensure the existence of \emph{deterministic} picking strategies that are not $\EU_p$ strategies, this assumption does not suffice, as the following example demonstrates.
\begin{example}
	If $\IP=\{p_1,p_2\}$ and $p_1$ expects $a_1$ to be better than $a_2$ and $p_2$ expects $a_2$ to be better than $a_1$. Suppose $\mu$ is sure you'll face $D^*=\{a_1,a_2\}$, i.e., $\mu(\{D^*\}) = 1$. Then picking strategies are determined by their selection on this single decision problem, picking either $a_1$ or $a_2$. So any strategy is $\mu$-surely an $\EU_p$ strategy for some $p \in \IP$, even though, for each $p \in \IP$, $\mu\{D\given \EAd_\IP(D)\subseteq\EU_p(D)\}< 1$. 
\end{example}

Instead, the requirement of coordination needs to be visible from the point of view of the measure $\mu$. There need to be distinct decisions where the probabilities in $\IP$  require coordination across the decisions, but E-Admissibility does not. This is what happens in the Ellsberg case or the Coordination cases discussed in the main text. 

In these cases, we have distinct decisions and probabilities such that every probability function disagrees with the recommendations of $\EU_{q^*_i}$ on $D_i$, and the $D_i$ have positive measure according to every $\mu$. More generally:
\begin{proposition}[\cref{thm:ead-existsimpermissible[indep]}]

Suppose $\IB$ makes $\Omega$ and $\Decs$ completely independent (so every $b\in\IB$ has the form $p\times\mu$.)

Suppose there is a selection of measurable, pairwise disjoint events $E_q\subseteq\Decs$, one for each $q\in\IP$ (some of which may be empty), such that for all $p\times\mu\in\IB$, 
\[
\mu\left(\bigcup_{q\in\IP}\{D\in E_q\given \EU_p(D)\cap\EU_q(D)=\emptyset\}\right)>0
\]

Then there is $\s$ that picks for $\EAd_\IP$ but which is not in $\EAd_\IB(\S)$. 
\end{proposition}
\begin{proof}
	Define $\s$ as follows:
	\begin{itemize}
	\item for $D \in E_q$, $\s(D)$ is any member of  $\EU_q(D)$; 
	\item for $D\notin \bigcup_{q\in\IP}E_q$, $\s(D)$ is any member of $\EAd_\IB(D)$.
	\end{itemize} 
	
	As they are disjoint, this is well-defined. 
	
	\begin{colored}{violet}
		Moreover, such an $\s$ can be chosen to be measurable. For each $q$ there is a measurable $\s_q$ (\cref{thm:EU-complete-measurable}) and so we can specify $\s(D)=\s_q(D)$ for $D\in E_q$ and $\s(D)=\s_{q_0}(D)$ for $D\notin \bigcup_{q\in\IP}E_q$ where $q_0\in\IP$. As $E_q$ are assumed to be measurable, this will be a measurable function. 
	\end{colored}
%	\begin{colored}
%		{blue}
%		By requiring the selection to itself be measurable, we ensure that such an $\s$ can be found which is measurable, by the Kuratowski and Ryll-Nardzewski measurable selection theorem.\todo{requires selection theorem!!} DOES THIS WORK? I DON'T UNDERSTAND WELL ENOUGH.
%	\end{colored}
	
	Then consider any $p \times \mu\in\IB$. 
	If $\s(D)\in\EU_q(D)$ and $\EU_p(D)\cap\EU_q(D)=\emptyset$, then $\s(D)\notin\EU_p(D)$. 
		So, for each $q\in\IP$, $\{D\in E_q\given \EU_p(D)\cap\EU_q(D)=\emptyset\}\subseteq\{D\given \s(D)\notin\EU_p(D)\}$. Thus, $$\{D\given \s(D)\notin\EU_p(D)\}\supseteq\bigcup_{q\in\IP}\{D\in E_q\given \EU_p(D)\cap\EU_q(D)=\emptyset\}.$$ By our assumption on $\mu$, it follows that $\mu(\{D\given \s(D)\notin\EU_p(D)\})>0$. So $\s$ does not $\mu$-surely pick for $\EU_p$. 
\end{proof}

%\begin{lemma}\label{thm:appendix:ead:existsimpermissibe:conditiontwoprobs[indep]}
%	If there exist some (distinct) $p^*_1,p^*_2\in\IP$ and disjoint $E_1,E_2\subseteq\Decs$ such that for all $(p,\mu)\in\IB$ there is at least one of $p^*_1$ or $p^*_2$ such that
%	\[
%	\mu\{D\in E_i\given \EU_p(D)\cap\EU_{p^*_i}(D)=\emptyset\}>0
%	\]
%	
%	Then there is $\s$ which picks for $\EAd_\IP$ but there is no $(p,\mu)\in\IB$ such that $\s$  $\mu$-surely picks for $\EU_p$. 
%\end{lemma}
%\begin{proof}
%	Set $\s$ so that $\s(D)\in\EU_{p^*_1}(D)$ for $D\in E_1$, $\s(D)\in\EU_{p^*_2}(D)$ for $D\in E_2$, and $s(D)\in\EAd_{\IP}(D)$ for any other $D$. 
%	
%	By construction it picks for $\EAd_\IP$. 
%	
%	For any $(p,\mu)\in\IB$ there is at least one of $p^*_1$ or $p^*_2$ such that
%	\[
%	\mu(\{D\in E_i\given \EU_p(D)\cap\EU_{p^*_i}(D)=\emptyset\})>0
%	\]
%	If $D\in E_i$ and $\EU_p(D)\cap\EU_{p^*_i}(D)=\emptyset$ then $\s(D)\notin \EU_p(D)$. So  
%	\begin{align}
%		\mu\{D\given\s(D)\notin \EU_p(D)\}\geq 	\mu\{D\in E_i\given \EU_p(D)\cap\EU_{p^*_i}(D)=\emptyset\}>0
%	\end{align}It thus does not $\mu$-surely pick for $\EU_p$. 
%\end{proof}
%This condition can be verified in cases such as the Ellsberg example or the example in \cref{eg:coord}.
%
%It can also be extended to more than two probabilities: In fact, we could choose an event for each probability in $\IP$ (allowing some to be empty, so it encompasses the previous result).
%
%%\begin{theorem}
%%	If 
%%	
%%	There is a selection of disjoint $E_p\subseteq\Decs$ for each $p\in\IP$ (some possibly empty), such that for all $(p_0,\mu_0)\in\IB$, $$\mu_0\left(\bigcup_{p\in\IP}\{D\in E_p\given \EU_p(D)\cap\EU_{p_0}(D)=\emptyset\}\right)>0.$$
%%	
%%	Then there is 
%%\end{theorem}
%
%%It furthermore extends to the conditional probabilities case, so we present the result including both generalisations. 

\begin{proposition}[\cref{thm:ead-existsimpermissible[dep]}]
Suppose there is a selection of measurable, pairwise disjoint events $E_{b'}\subseteq\Decs$, one for each $b'\in\IB$ (some of which may be empty),  such that for all $b\in\IB$, $$b_\Decs\left(\bigcup_{b'\in\IB}\{D\in E_{b'}\given \EU_{b(\cdot|-)}(D)\cap \EU_{b'(\cdot|-)}(D)=\emptyset\}\right)>0.$$

Then there is $\s$ which picks for $\EAd_{\IB(\cdot|-)}$ but where there is no $b\in\IB$ such that $\s$  $b_\Decs$-surely picks for $\EU_{b(\cdot|-)}$. 
\end{proposition}
\begin{proof}
	As above, except ensure $\s(D)$ some member of $\EU_{b(\cdot|D)}(D)$, for $D\in E_b$; and $\s(D)$ some member of $\EAd_{\IB(\cdot|-)}(D)$, for $D \notin \bigcup_{b\in\IB}E_b$. 
\end{proof}

%We suspect this condition 
%
%It will also apply in the conditional case. 
%\begin{proposition}\label{thm:appendix:ead:existsimpermissibe:conditiontwoprobs[dep]}
%	If there exist some (distinct) $b^*_1,b^*_2\in\IB$ and disjoint $E_1,E_2\subseteq\Decs$ such that for all $b\in\IB$ there is at least one of $b^*_1$ or $b^*_2$ such that
%	 \[
%		b_\Decs(\{D\in E_i\given \EU_{b(\cdot|D)}(D)\cap \EU_{b^*_i(\cdot|D)}=\emptyset\})>0
%	\]
%\end{proposition}
%\begin{proof}
%	Exactly as \cref{thm:appendix:ead:existsimpermissibe:conditiontwoprobs[indep]}.
%\end{proof}

%\begin{theorem}
%	Suppose that $\IB$ makes $\Omega$ and $\Decs$ completely independent. 
%		
%	Suppose $\IP$ is non-singleton, there is some for every $(p,\mu)\in\IB$, for every $p'\in\IP$ with $p\neq p'$, $$\mu\{D\given \EU_p(D)\cap\EU_{p'}(D)=\emptyset\}>0.$$
%	
%	Then there is $\s$ which picks for $\EAd_\IP$ but there is no $p\times\mu\in \IB$ such that $\s$ $\mu$-surely pick for $\EU_p$.
%\end{theorem}
%
%\begin{proof}
%	Take 
%\end{proof}

%And the same proof also establishes \Cref{thm:max-existsimpermissible[dep]}.

We can find cases with such events when we make additional assumptions that each $\mu$ is sufficiently spread. %\cref{thm:ead-existsimpermissible[dep]:spreadegtakeorleave}



\begin{proposition}\label{thm:ead-existsimpermissible[dep]:spreadegtakeorleave}%\todo{why am I now using g? We were using X as rv, althoguh that was for rv on OmegaxDecs}
	Suppose that $\IB$ makes $\Omega$ and $\Decs$ completely independent. 
	
	Assume $\U(\A)=[l,h]^\Omega$ with $l<0<h$. In particular, for every $X\in [l,h]^\Omega$ there is some $a\in \A$ with $\U(a)=X$. 


	Suppose $\IP$ is non-singleton and for every $p \times \mu\in\IB$, for every open non-empty subset $U \subseteq\A$, $\mu\{\{a,0\}\given a\in U\}>0$.

Then there is $\s$ that picks for $\EAd_\IP$ but for which there is no $p\times\mu\in \IB$ such that $\s$ $\mu$-surely pick for $\EU_p$.
\end{proposition}
\begin{proof}





\begin{sublemma}
	Suppose $V$ is a non-empty open subset of $[l,h]^\Omega$ such that for each $X\in \Re^\Omega$ there is some $\lambda>0$ such that $\lambda X\in V$. 
	
	Then, for any $p\neq q$, $\{X\in V\given \Exp_p[X]>0>\Exp_q[X]\}$ is non-empty and open.
\end{sublemma}
\begin{proof}
	{It is non-empty}:
	First, observe that there is some $X\in\Re^\Omega$ such that $\Exp_p[X]>0>\Exp_q[X]$. For example, with $A$ such that $p(A)\neq q(A)$, we can put $X=\mathbf{1}_A-\frac{p(A)-q(A)}{2}\mathbf{1}$; or the negative of this, if required. %\todo{cleaner eg??} 
	By our assumption concerning $V$, there is some $\lambda >0$ with $\lambda X\in V$. And so $\Exp_p[\lambda X]>0>\Exp_{q}[\lambda X]$. 
	
	It is open by continuity of expectation. 
\end{proof}

Thus, for any $p\times\mu\in\IB$ and any $q\neq p$, $$\mu(\{\{a,0\}\given \U(a)\in V\text{ and }\Exp_p[\U(a)]>0>\Exp_q[\U(a)] \})>0.$$ Note also that for $D=\{a,0\}$ with $\Exp_p[\U(a)]>0>\Exp_q[\U(a)]$, then $\EU_{p}(D)=\{a\}$ and $\EU_q(D)=\{0\}$, so they are disjoint. 
For $E_V:=\{\{a,0\}\given a\in V\}$, then $\mu(\{D\in E_V\given \EU_p(D)\cap\EU_q(D)=\emptyset\})>0$. 

To construct our disjoint $E_q$ satisfying the conditions of \cref{thm:ead-existsimpermissible[indep]}, first note that we can find two \emph{disjoint} $V_1$ and $V_2$ that are  non-empty open subsets of $[l,h]^\Omega$ such that for each $i\in\{1,2\}$ and each $X\in \Re^\Omega$ there is some $\lambda>0$ such that $\lambda X\in V_i$.
For example, we could put  $V_1:=\{X\in[l,h]^n\given \|X\|<0.5\}$ and $V_2:=\{X\in[l,h]^n\given \|X\|>0.5\}$ (assuming that $l<-0.5<0.5<h$). 


Then take any distinct $q^*_1,q^*_2\in\IP$. 

Put $$E_q:=\begin{cases}
	E_{V_1}=\{\{a,0\}\given a\in V_1\}&q=q^*_1\\
	E_{V_2}=\{\{a,0\}\given a\in V_2\}&q=q^*_2\\
	\emptyset&\text{otherwise}
\end{cases}$$
and observe that the conditions of \cref{thm:ead-existsimpermissible[indep]} are then satisfied. 
\end{proof}


\begin{proposition}\label{thm:ead-existsimpermissible[dep]:spreadeg}Suppose that $\IB$ makes $\Omega$ and $\Decs$ completely independent. 
	
	Assume $\U(\A)=[l,h]^\Omega$. In particular, for every $X\in [l,h]^\Omega$ there is some $a\in \A$ with $\U(a)=X$. 
	
	Suppose $\IP$ is non-singleton and for every $p \times \mu\in\IB$, $\mu$ has full support on $\Decs$ (assigning strictly positive measure to every non-empty open subset of $\Decs$).
	
	Then there is $\s$ that picks for $\EAd_\IP$ but for which there is no $p\times\mu\in \IB$ such that $\s$ $\mu$-surely pick for $\EU_p$.
	
\end{proposition}
\begin{proof}
	\begin{sublemma}
		Let $E = \{D\in\D\given D\subseteq V\}$ for some open subset $V \subseteq [l,h]^\Omega$.
		
		For any $p\neq q$,
		$\{D\in E\given \EU_{p}(D)\cap \EU_{q}(D)=\emptyset\}$ is open and non-empty $\subseteq\Decs$.
	\end{sublemma}
	\begin{proof}
		
		%		It is open: As $E$ is open, we just need to show that $\{D\given \EU_{q_1}(D)\cap \EU_{q_2}(D)=\emptyset\}$ is open. 
		%		Since $q_1\neq {q_2}$ there are $a_1,a_2\in\A$ such that $\Exp_{q_1}[\U(a_1)]>\Exp_{q_1}[\U(a_2)]$ and $\Exp_{q_2}[\U(a_1)]<\Exp_{q_2}[\U(a_2)]$. For example, use a construction like in \cref{thm:ead-existsimpermissible[indep]:CCM-1:nondegentakeleave}. 
		%		As $\Exp$ is continuous, we can also find open $U_1\ni a_1$ and $U_2\ni a_2$ with the same inequality of expectations. 
		%		So $\{D\given D\cap U_1=\emptyset\text{ and }D\cap U_2=\emptyset\}$ is open and it is a subset of $\{D\given \EU_{q_1}(D)\cap \EU_{q_2}(D)=\emptyset\}$.
		%		
		
		
		\textbf{It is nonempty:}
		
		Take any $D_0\in E$. If $\EU_{p}(D_0)\cap \EU_{q}(D_0)=\emptyset$ this suffices. 
		
		Otherwise, there is some $a_0\in \EU_{p}(D_0)\cap \EU_{q}(D_0)$. 
		
		As in \cref{thm:ead-existsimpermissible[indep]}, we can find some $X^*$ such that $\Exp_{p}[X^*]>0>\Exp_{q}[X^*]$. And, moreover, we can choose a scalar $\lambda$ small enough so that $\U(a_0)+\lambda X^*\in[l,h]^n$ and thus that $a_0+\lambda X^*\in\U(\A)$.% (abusing notation). 
		
		So $\Exp_{p}[\U(a_0+\lambda X^*)]>\Exp_{p}[\U(a_0)]$ and $\Exp_{q}[\U(a_0+\lambda X^*)]<\Exp_{q}[\U(a_0)]$.
		
		Consider $D^*=D_0\cup\{a_0+\lambda X^*\}$, recalling that $a_0\in D_0$. 
		
		Observe that $\EU_{p}(D^*)=\{a_0+\lambda X^*\}$ but that $a_0+\lambda X^*\notin\EU_{q}(D^*)$, since $q$ finds $a_0$ preferable. 
		Thus $\EU_{p}(D^*)\cap \EU_{q}(D^*)=\emptyset$.
		
		Since $\U(a_0)+\lambda X^*\in V$, by choice of $\lambda$, $D^*\subseteq V$, and so $D^*\in E$, as required. 
		
		\textbf{It is open:}
		
		Take any $D_0\in E$ with $\EU_{p}(D_0)\cap \EU_{q}(D_0)=\emptyset$. 
		
		Let $t_p=\max_{a\in D_0}\Exp_{p}[\U(a)]$ and $t_q=\max_{a\in D_0}\Exp_{q}[\U(a)]$.
		
		As  $\EU_{p}(D_0)\cap \EU_{p}(D_0)=\emptyset$, for all $a\in D_0$, either $t_p>\Exp_{p}(a)$ or  $t_q>\Exp_{q}(a)$. So, define $f(a):=\max\{t_p-\Exp_{p}[\U(a)],t_q-\Exp_{q}[\U(a)]\}>0$, for all $a\in D_0$. Since $D_0$ is finite, let $\delta=\min_{a\in D_0}f(a)>0$. So that for all $a\in D_0$, either  $\Exp_{p}[\U(a)]\leq t_p-\delta$ or $\Exp_{q}[\U(a)]\leq t_q-\delta$
		
		Let $\epsilon=\nicefrac{\delta}{2}$. Suppose $d(D_0,D)<\epsilon$. That is, for all $a\in D_0$, there is some $c\in D$ such that $d(a,c)<\epsilon$ and, for all $c\in D$, there is some $a\in D_0$ such that $d(a,c)<\epsilon$. 
		
		Take any $a_p\in \EU_{p}(D_0)$, so $\Exp_{p}[\U(a_p)]=t_p$. There is some $c_p\in D$ such that $d(a_p,c_p)<\epsilon$, and thus $\Exp_{p}[\U(c_p)]>t_p-\epsilon$. Thus, $\max_{c\in D}\Exp_{p}[\U(c)]>t_p-\epsilon$, and so if $c\in \EU_{p}(D)$, then $\Exp_{p}[\U(c)]>t_p-\epsilon$. 
		
		
		By an analogous argument, if $c\in \EU_{p}(D)$ then $\Exp_{q}[\U(c)]>t_q-\epsilon$. 
		
		For any $c\in D$, there is some $a_c\in D_0$ such that $d(c,a_c)<\epsilon$. If, also,  $c\in \EU_{p}(D)\cap\EU_{p}(D)$ then 
		\begin{align}
			&\Exp_{p}[\U(a_c)]>\Exp_{p}[\U(c)]-\epsilon>t_p-2\epsilon\\
			\text{and }&\Exp_{q}[\U(a_c)]>\Exp_{q}[\U(c)]-\epsilon>t_q-2\epsilon
		\end{align}
		By choice of $\epsilon=\nicefrac{\delta}{2}$ there is no such $a_c\in D_0$. 
		%	
		%	
		%	
		%		
		%		\textbf{It is open:} 
		%		As $E$ is open, we just need to show that $\{D\given \EU_{q_1}(D)\cap \EU_{q_2}(D)=\emptyset\}$ is open.
		%		
		%		The complement is $$\{D\given \EU_{q_1}(D)\cap \EU_{q_2}(D)\neq \emptyset\}=\bigcup_{a\in \A}\{D\given a\in \EU_{q_1}(D)\text{ and } a\in\EU_{q_2}(D)\}$$
		%		
		%		For each fixed $a\in \A$, $\{b\given \Exp_q[\U(b)]\leq\Exp_q[\U(a)]\}$ is closed $\subseteq\A$. So $$\{D\given D\subseteq \{b\given \Exp_q[\U(b)]\leq\Exp_q[\U(a)]\}\}$$ is closed in $\Decs$. $\{D\given a\in\EU_q(D)\}$ is the intersection of this with the closed set $\{D\given a\in D\}$. 
		%		
		%		So $\{D\given \EU_{q_1}(D)\cap \EU_{q_2}(D)\neq \emptyset\}$ is an intersection of closed sets and thus is closed. 
		%		
	\end{proof}
	
	Let $V_1,V_2$ be any disjoint non-empty open subsets of $[l,h]^\Omega$. 
	
	Then take any distinct $q^*_1,q^*_2\in\IP$. 
	
	Let $$E_q:=\begin{cases}
		\{D\in\Decs\given D\subseteq V_1\}&q=q^*_1\\
			\{D\in\Decs\given D\subseteq V_2\}&q=q^*_2\\
		\emptyset&\text{otherwise}
	\end{cases}$$
	and observe that the conditions of \cref{thm:ead-existsimpermissible[indep]} are then satisfied. 
\end{proof}





To prove \cref{thm:seed-suff-impermissible-strat}, let $\c$ be any choice function. Let $r:\Decs\rightarrow[0,1)$ be any measurable statistic, \textit{e.g.},  $r(D)=\Bigl(\sum_{x\in D}\|x\|^{2}\Bigr)\bmod 1$. 

\begin{proposition}[\cref{thm:seed-suff-impermissible-strat}]
Suppose that for any $b\in\IB$, $b_\Decs(U_b)>0$ where 
\[
U_b:=\bigl\{D\in\Decs\given \c(D)\not \subseteq\EU_{b(\cdot|-)}(D)\bigr\}.
\] 
Suppose further that for any $b\in\IB$ and any open interval $I\subset[0,1)$, 
\[
b_\Decs\bigl(\,D\in U_b\given r(\c(D))\in I \bigr)>0.
\]
Then there exists a measurable function
$
  \s:\Decs\to\mathbb \A
$
which picks for $\c$ but for no $b\in\IB$ does it $b_\Decs$-surely pick for $\EU_{b(\cdot|-)}$.

\end{proposition}

\begin{proof}
For any $D\in\Decs$, enumerate the choice set in lexicographic order
$
  \c(D)=\{x_{1}(D),\dots,x_{n_D}(D)\},
$
where $n_D=|\c(D)|$. Partition $[0,1)$ into $n_D$ intervals
$
  I_{j}(D)=\bigl[\tfrac{j-1}{n_D},\tfrac{j}{n_D}\bigr)
$.
Define
\[
\alpha(D)=\min\bigl\{j\given r(\c(D))\in I_{j}(D)\bigr\},
  \qquad
  s(D)=x_{\alpha(D)}(D).
\]
Measurability follows immediately from the measurability of $r$ and $\min$, and $s(D)\in\c(D)$ by construction. So $\s$ picks for $\c$.

Choose $b\in\IB$.


For each $D\in U_b$, choose
$x_{\beta(D)}(D)\in \c(D)\setminus\EU_{b(\cdot|-)}(D)$.
If $r(D)\in I_{\beta(D)}(D)$ then $s(D)=x_{\beta(D)}(D)\notin\EU_{b(\cdot|-)}(D)$.

Define
$
 V_b:=\{D\in U_b\given r(\c(D))\in I_{\beta(D)}(D)\}.
$
Because $I_{\beta(D)}(D)$ has positive length $1/n_D$ (and hence contains an open interval), we must have $b_\Decs(V_b)>0$.

For all $D\in V_b$, $s(D)\notin\EU_{b(\cdot|-)}(D)$, hence
\[
b_\Decs\bigl(\,D\given s(D)\notin\EU_{b(\cdot|-)}(D)\bigr)\ge b_\Decs(V_b)>0.
\]
Therefore
$
b_\Decs\bigl(\,D\given s(D)\in\EU_{b(\cdot|-)}(D)\bigr)<1.
$
So $\s$ does not $b_\Decs$-surely pick for $\EU_{b(\cdot|-)}$.

\end{proof}


So we have proved \cref{thm:eu-self-rec,thm:eu-uniquely-optimal,thm:eu-nu-nec-suff,thm:eu-dep,thm:ead-equiv[indep],thm:ead-existence[dep],thm:seed-suff-impermissible-strat,thm:ead-existsimpermissible[indep],thm:ead-nu-nec-suff,thm:ead-nu-reg-nec,thm:ead-existence[indep],thm:max-suff,thm:max-suff[dep],thm:max-nu-suff,thm:ead-equiv[dep]}

The remaining theorems, \cref{thm:max-nu,thm:max-nu-reg-nec,thm:gamma-nu} require a different approach.
%\todo{add ref to the new undermining thm we're adding. }

%\end{colored}
\section{Maximality \\(\cref{thm:max-nu,thm:max-nu-reg-nec,thm:max-existsimpermissible[dep]})}\label{sect:wald:appendix}
To prove \cref{thm:max-nu,thm:max-nu-reg-nec,,thm:max-existsimpermissible[dep]}, we turn to a version of Abraham Wald's (\citeyear{wald1947cct}) Complete Class Theorem, which we prove as \Cref{thm:cct}. % \todo{what are the two versions referred to?}
We state it in a general setting and then explain how they apply to our case. Along the way, we prove a more standard version of Wald's theorem.
\subsection{Wald theorem}
 To state them, we need some definitions.

\begin{itemize}
	\item $\Omega$ is a finite set of states.
	\item A probability function over $\Omega$ is a normalised function $p : \Omega \to [0, 1]$, i.e., $\sum_{\omega \in \Omega} p(w) = 1$. Given a random variable (or vector) $X\in\Re^\Omega$, we write $p(X)$ for the expectation of $X$, i.e., $p(X)=\Exp_p[X] = \sum_{\omega\in\Omega}p(\omega)X(\omega)$.% applying the probability function to random variables. 
	\item $\O$ is a set of ``options''. In our application it will be $\Nu$, containing (probabilistic) picking strategies, $\n$.
	\item $\Uwald:\O\times\Omega\to [l,u]$ is a bounded ``utility function''. In our application, it will be $\Uwald(\n,\omega)=\Exp_{\mu^*}[\U(\n,\omega)]$.\footnote{We have assumed it is bounded; however all that is actually needed for the proof is that it is bounded above, i.e., we could allow $\Uwald:\O\times\Omega\to (-\infty,0]$.}
		\item Given an option $o$, the utility profile of $o$ is the random variable (or vector) $\Uwald(o) \in\Re^\Omega$ with $\Uwald(o)(\omega)=\Uwald(o,\omega)$.%, however $\Uwald$ is specified. 
		\item So, given an option $o$ and a probability function $p$ over $\Omega$, $p(\Uwald(o)) = \Exp_p[\Uwald(o)] = \sum_{\omega \in \Omega} p(\omega) \Uwald(o)(\omega) = \sum_{\omega \in \Omega} p(\omega) \Uwald(o, \omega)$.
	\end{itemize}
%\end{itemize}


%$\O$ is the set of picking functions. 
%
%We have $\Uwald:\O\to [0,1]$; as we have assumed that utilities are bounded. In fact, all that is needed for the result is that they are bounded above; we could have $\Uwald:\O\to(-\infty,0]$. 
%Background assumptions:
%\begin{itemize}
%	%	\item Finitely many possibilities, $\Omega$. 
%	\item Utilities are bounded (at least bounded above). This is essential, though it also follows from the existence of Bayes optimal points [I think, somehow spelled out]. 
%	\item Utilities are finite [should be removable]
%\end{itemize}
%$\O$ is a collection of ``options''. 
%In our setting, these will be the picking strategies, probabilistic or deterministic. 
%Perhaps they are possible credence functions, or other kinds of uncertainty models, or update rules, or decision theories, or ice cream flavours. We assume we have some measure of utility of those options, simply a function $\Uwald:\O\times\Omega\to\Re$. This might be epistemic utility, or practical utility, or whatever else it is that one is trying to optimise. 
%We can think of $\Uwald(o)$ as a vector in $\Re^\Omega$. 


%
%
%\begin{definition}
%	A probability $p$ is a non-negative normalised linear functional on $\Re^\Omega$. That is, $p:\Re^\Omega$ such that
%	\begin{enumerate}
%		\item Non-negative: $X(\omega)\geq Y(\omega)\implies p(X)\geq p(Y)$
%		\item Normalised: $p(\mathbf{1})=\mathbf{1}$
%		\item Linear: $p(cX+dY)=cp(X)+dp(Y)$.
%	\end{enumerate}
%	When $\Omega$ is finite, we might think of such $p$ as specified by probability mass function $p(\omega)$ for each $\omega$ which are non-negative and normalised. Then for any $X\in\Re^\Omega$, $p(X)=\sum_\omega p(\omega)X(\omega)$. 
%	
%	The utility profile of an option is $\Uwald(o)\in\Re^\Omega$ as expected, i.e., $\Uwald(o)(\omega)=\Uwald(o,\omega)$, however $\Uwald$ is specified. 
%	
%	An option $o$ is Bayes for $p$ in $\O$  iff $p(\Uwald(o))\geq p(\Uwald(o'))$ for every $o'\in \O$. 
%	%	
%	%	We're working in infinite dimensions. A ``probability'' $p$ is just a linear functional which is positive and normalised. That is, we're merely assuming finite additivity. The notion of being Bayes is defined similarly. 
%\end{definition}


%Consider 












 %They don't require the Bayes option to be identical to the original probabilities. 


%I believe that JK's addition to the usual Wald is to identify the features of $\Uwald$ that allows the argument to go through rather than relying on the integral form of the utility function. 


%
%We can start thinking of everything just with vectors. Let
%\begin{equation}
%	\Uwald(\O):=\{\Uwald(o)\given o\in \O\}\subseteq\Re^\Omega
%\end{equation}
%\begin{definition}Bayes-existing and Bayes-continuous iff: for every probability $p$, there is some $X\in \Uwald(\O)$ which is Bayes for $p$. And if $o$ is Bayes for $p$ and $p_1,p_2,\ldots$ are probabilities converging to $p$ then there is some sequence of $y_n\in \Uwald(\O)$, with each $y_n$ Bayes for $p_n$, and tBayes options for $p_n$ whose which converge to $
%\end{definition}






%\begin{definition}
%	$\Uwald$ is Bayes-existing on $\O$ iff for every probability $P$ there is some $o\in \O$ which is Bayes for $P$. 
%\end{definition}
\begin{definition}
Relative to $\Uwald$:

	$o$ is \emph{strictly dominated in $\O$} iff there is $o'\in\O$ with $\Uwald(o',\omega)>\Uwald(o,\omega)$ for all $\omega$. $o$ is called \emph{admissible} if it is not strictly dominated. 
	
	$o$ is \emph{weakly dominated in $\O$} iff there is $o'\in\O$ with $\Uwald(o',\omega)\geq\Uwald(o,\omega)$ for all $\omega$ and $\Uwald(o',\omega)>\Uwald(o,\omega)$ for some $\omega$.
	
	%For a probability function $p$ over $\Omega$, we will use $p(\Uwald(o)):=\Exp_p[\Uwald(o)]$. %\todo{are we assuming finite $\Omega$??}
	$o$ is \emph{Bayes for $p$ in $\O$}  iff, for all $o'\in\O$, $p(\Uwald(o))\geq p(\Uwald(o'))$. 
	
	$o$ is \emph{Bayes in $\O$} iff there is some probability $p$ such that $o$ is Bayes for $p$. %\todo{I don't think we'd defined it! added it here. }
\end{definition}






%This tells us that to avoid dominance, you need to be the sort of thing that probabilities think are optimal. Even if $\Uwald$ is measuring accuracy of credences themselves, it doesn't tell us that probabilities themselves are the things that are non-dominated unless one has an additional assumption that probabilities themselves are exactly the kinds of things that are evaluated as optimal by probabilities, which is exactly what strict propriety gives us. 
%We need to show:
%\begin{itemize}
%	\item If $o$ is Bayes then it is not strictly dominated; and if is Bayes for a regular probability then it is not weakly dominated. 
%	\item If $o$ is not weakly dominated, then it is Bayes.
%	\item If $o$ is merely weakly dominated, i.e., weakly dominated but not strictly dominated, then it is Bayes for a irregular probability. \todoold{is this the way we show it? Or do we do the whole proof again for the strict one?}
%\end{itemize}
%Moreover, \begin{itemize}
	%	\item If $o$ is weakly dominated, then there is $o'$ which dominates it which is Bayes (and thus is not itself even weakly dominated).
	%\end{itemize}\todoold{does this follow from the above? No. Actually, it's not true without other assumptions. E.g, when $\Uwald(\O)$ is convex but not necessarily closed then it isn't true. It is what we prove in the cts case.}
	
	%Maybe we should instead show:
	
	%\begin{theorem}[Complete Class Theorem]\label{thm:cct}\ 
	%	\begin{enumerate}[{\normalfont (I)}]
		%		\item If $o$ is Bayes then it is admissible. 
		%		\item Suppose $\Uwald$ is convex on $\O$. Then, $o$ is Bayes iff $o$ is admissible.
		%		\item Suppose $\Uwald$ is Bayes-continuous on $\O$ and Bayes-existing on $\O$. Then, $o$ is Bayes iff $o$ is admissible.
		%	\end{enumerate}
	%\end{theorem}
	
	
	
	\begin{lemma}\label{thm:cct:Bayes implies admiss}
		If $o$ is Bayes in $\O$, then it is not strictly dominated in $\O$.
	\end{lemma}
	\begin{proof}
		Suppose it is strictly dominated. Then there is $o'$ such that $\Uwald(o,\omega)<\Uwald(o',\omega)$, for all $\omega$. So every probability function $p$ over $\Omega$, we have $p( \Uwald(o))<p(\Uwald(o'))$. %$\todo{Have we introduced this notation yet?}.
		Thus it is not Bayes.
		%	
		%	Suppose $o$ is weakly dominated. Then every \emph{regular} probability has $p\cdot \Uwald(o')>p\cdot \Uwald(o)$, so it is not Bayes for any regular probability. 
	\end{proof}
	
	From now on, we'll think directly in terms of vectors. We let $\Uwald(\O) := \Set{\Uwald(o)\given o\in \O}\subseteq\Re^\Omega$, and we write $\Conv(\Uwald(\O))$ for the convex hull of this set of real-valued vectors. We write $\cl(\Conv(\Uwald(\O)))$ for the closure of $\Conv(\Uwald(\O))$ in the product topology. This can also be characterised by limits of sequences, or more generally of nets: if a sequence (or net) of members of $\Conv(\Uwald(\O))$ is such that, for each coordinate, $\omega$, $X_\alpha(\omega)\longrightarrow X^*(\omega)$, then $X^*\in\cl(\Conv(\Uwald(\O)))$. 
	
%	We extend the notion of being Bayes for vectors as follows.
%	\begin{definition}[Bayes for vectors]
%		$X\in\Re^\Omega$ is \emph{Bayes for $p$ in $\Uwald(\O)$} iff $p(X)\geq p(Y)$ for all $Y\in \Uwald(\O)$.
%		$X$ is \emph{Bayes in $\Uwald(\O)$} if there is some probability $p$ where $X$ is Bayes for $p$ in $\Uwald(\O)$.
%	\end{definition}
%	Note that we haven't actually required $X$ to be in the set $\Uwald(\O)$ for it to be Bayes in $\Uwald(\O)$. The proof doesn't rely on this fact in any way, but it means that we're proving something a bit stronger: Bayes is equivalent to being non-dominated in general, whether the $X$ is in $\Uwald(\O)$ or not.
	
	The definitions of strict and weak dominance, and the definitions of being Bayes for $p$ and being Bayes simpliciter carry over straightforwardly to vectors. For instance, given two vectors $X, Y \in \Re^\Omega$, we say $X$ strictly dominates $Y$ if $X(\omega) > Y(\omega)$, for all $\omega$; and we say that $X$ is Bayes for $p$ in a given set of vectors if $p(X) \geq p(Y)$, for all $Y$ in that set; and so on.
	
	\begin{infversion}
		I'm allowing infinite disutility. $\Uwald:\Re^\Omega\to[-\infty,+\infty)$. 
	\end{infversion}
	
	Our first lemma says that if a vector is not Bayes in $\Uwald(\O)$, then it is strictly dominated in the convex hull of $\Uwald(\O)$.
	\begin{lemma}\label{thm:cct:admiss in conv are Bayes in conv}
		If $X\in\Re^\Omega$ and  there is no probability $p$ with $p(X)\geq p(\Uwald(o))$, for all $o\in\O$, then there is $Y\in\Conv(\Uwald(O))$ such that $Y(\omega)>X(\omega)$, for all $\omega$.
	\end{lemma}
	\begin{proof}
		Suppose $X$ is not strictly dominated in $\Conv(\Uwald(\O))$. 
		Let $\Dom_X$ be the set of strict dominators of $X$, i.e., $$\Dom_X :=\{Y\in \Re^\Omega\given \text{for all $\omega$, }Y(\omega)>X(\omega)\}.$$ Then, by assumption, $\Dom_X $ and $\Conv(\Uwald(\O))$ are disjoint. They are also both convex. And so, by the Separating Hyperplane Theorem, they can be separated by a non-zero linear functional \citep[Section 2.5.1]{boyd2004co}. That is, there is a linear functional, $f:\Re^\Omega\to\Re$, with $f\neq 0$ and a constant $c$ such that $f(Y)\geq c \geq f(Z)$ for any $Y\in \Dom_X $ and $Z\in \Conv(\Uwald(\O))$.
		%\todo{Find a proper reference for what we need!}
%		\citep[Theorem 5.61]{aliprantis2006infinite}. 
%		\todo{this ref doesn't get cts!! we don't actually need it though. So i removed from statement}
%		.\footnote{In fact, to apply their result, we need that at least one of them has an internal point. In finite dimensions, this is interior points \citep[Thm.~5.60]{aliprantis2006infinite}, and observe that $\Dom_X$ is non-empty and open, so has interior points. 
%%		 \begin{infversion}
%%			Although, it may fail if we allowed $+\infty$; so we'd need to impose that utilities are not $+\infty$ to get this bit.
%%		\end{infversion}
%	}\todo{it needs internal rather than interior opint,...}

		
		We now show that $f$ is non-negative. Let $Z\geq 0$ and suppose $f(Z)<0$. Then take any $Y\in \Dom_X $ and any $k > 0$, and note that $Y+kZ \in \Dom_X$, and so $f(Y + kZ) \geq c$. Then, since $f(Z) < 0$, we can make $f(Y+kZ)=f(Y)+kf(Z)$ arbitrarily small by making $k$ arbitrarily large. And, in particular, we can make $f(Y+kZ)=f(Y)+kf(Z)$ less than $c$. This gives a contradiction. 
		
		Also, since $f \neq 0$, there is $\omega$ such that $f(\omega)\neq 0$. After all, by linearity, $f(X) = \sum_{\omega\in\Omega}f(\omega)X(\omega)$, and so, if $f(\omega) = 0$, for all $\omega$, $f(X) = 0$, for all $X \in \Re^\Omega$, i.e., $f = 0$, which gives a contradiction. %, for otherwise it would be $0$ everywhere (as by linearity, it has the form $f(X)=\sum_{\omega\in\Omega}f(\omega)X(\omega)$) and the theorem gives us a non-zero linear functional.%\todo{iadded expln}
		
%				Now, any non-trivial monotone linear functional must have $f(\vec{1})\neq 0$.\todoold{why?????} And thus, we can ``normalise'' $f$ by dividing through by $f(\vec{1})$. \todoold{footnote that this isn't the usual notion of normalisation.}
		
		We can thus normalise $f$ to obtain our probability function $p$ over $\Omega$ with $p(Y)\geq c' \geq p(Z)$, for any $Y\in \Dom_X $ and $Z\in \Conv(\Uwald(\O))$.\begin{infversion}
			$\cap Fin$. If $Z$ not in Fin, then we also want to check that $p(Z)<c$. 
		\end{infversion}
		
		Now, $X\in\cl(\Dom_X )$, and so $p(X)\geq c'$, and so $p(X) \geq p(Z)$, for all $Z\in \Uwald(\O)\subseteq \Conv(\Uwald(\O))$, as required.
	\end{proof}
	
		This now gives us a standard version of Wald's Complete Class Theorem, which says: if $\Uwald(\O)$ is convex, then $o$ is Bayes in $\O$ iff $o$ is not strictly dominated in $\O$.\footnote{Note that this requires that $\Uwald(\O)$ is convex, not $\O$.} But this is not the version we apply to obtain our results. So we continue.
	
	This result doesn't show that, if $o$ is not Bayes, it is strictly dominated by something that is itself not dominated, and thus is Bayes. We get that from the next result. 
	
	%\begin{corollary}
	%	Suppose $\Uwald(\O)$ is convex. If $X$ is not Bayes in $\Uwald(\O)$ then it is strictly dominated in $\Uwald(\O)$. \todoold{For this case we don't have the result that it's strictly dominated by a Bayes option using \cref{thm:cct:dominator on boundry} and the fact that the $Z\in\cl(\Uwald(\O))$ which dominates it is not weakly dominated, and thus, by what we already have here, it is Bayes.. }
	%\end{corollary}
	%\begin{proof}
	%	Observe that $\Conv(\Uwald(\O))=\Uwald(\O)$ by assumption of convexity. So it follows immediately from \cref{thm:cct:admiss in conv are Bayes in conv}
	%\end{proof}
	
%	Our second lemma says that if $X$ is strictly domiant
	\begin{lemma}\label{thm:cct:dominator on boundry}
		Suppose $X$ is strictly  dominated in $\Conv(\Uwald(\O))$. Then we can find $Z\in\cl(\Conv(\Uwald(\O)))$ that strictly dominates $X$ and is itself not even weakly dominated in $\Conv(\Uwald(\O))$. \begin{infversion}
			and $Z$ in Fin.
		\end{infversion}
		%	If $X$ is not Bayes in $\Uwald(\O)$ then there is $X'\in\cl(\Conv(\Uwald(\O)))$ s.t. $X'$ dominates $X$ and $X'$ is non-dom in $\Conv(\Uwald(\O))$. 
	\end{lemma}
	In the usual setting for Wald's Complete Class Theorem, the vector $Z$ in $\cl(\Conv(\Uwald(\O)))$ that dominates $X$ and is not weakly dominated is called the `lower boundary' of the set; in our case, it would be `upper boundary', since we are working with positive utility rather than risk or disutility. This then says that, if a vector is dominated, it is dominated by something in the lower (upper) boundary. The result depends essentially on the fact that $\Uwald(\O)$ is bounded from above. 
	%\todoold{Note: just improving it in each coordinate isn't sufficient. }
	
	
	\begin{proof}
		Take any $Y\in \Conv(\Uwald(\O))$ that dominates $X$. Consider $A:=\{Z\in \cl(\Conv(\Uwald(\O)))\given  Z(\omega)\geq Y(\omega)\text{ for all $\omega$}\}$. Observe that this is closed (as it is the intersection of two closed sets) and bounded (as we assumed that utilities were bounded above), and thus compact. Let $f(Z):=\sum_\omega Z(\omega)$. Since $f$ is a continuous function, the Extreme Value Theorem ensure it obtains its maximum somewhere in $A$. This maximum point will be as required. 
	\end{proof}
	%\begin{proof}
	%	[Rewriting that more explicitly, not sure it helped though!]
	%	Start with any point, $x_0\in\cl(\Conv(\Uwald(\O)))$, that strictly dominates $X$. Then if possible, take $x_1$ to be a point in $\cl(\Conv(\Uwald(\O)))$ weakly dominating $x_0$, if it is not possible, then we have already found our desired $Z$. Continue this, choosing points in $\cl(\Conv(\Uwald(\O)))$ which weakly dominate the previous point, if possible, and if not possible, we are done: we have found the desired $Z\in\cl(\Conv(\Uwald(\O)))$ which is not weakly dominated. If this process didn't halt, then we have a sequence $\langle x_0,x_1,\ldots\rangle$ each of which is in $\cl(\Conv(\Uwald(\O)))$ and weakly dominates the previous one. We can then consider extending this sequence to the transfinite. Take $x_\omega$ to be the (pointwise) supremum of this sequence, observing that it is a limit point of the sequence [topology of pointwise convergence] so is in $\cl(\Conv(\Uwald(\O)))$, and it weakly dominates all the previous points, and we can then continue the construction from there, through the transfinite. Since there are at most continuum-many points to be chosen from, this process must at some point terminate. And since one can always take the limit point of any such sequence and check that it is in $\cl(\Conv(\Uwald(\O)))$, it must be an actual point that is found where the process terminates, i.e., giving us our required $Z$.
	%\end{proof}
	
	This result can also be proved by applying Zorn's lemma. That argument also works when $\Omega$ is infinite.\footnote{Define $\preccurlyeq$ a partial order on $A$ as the natural coordinatewise order. For any chain, consider its pointwise supremum, which exists because utilities are bounded above, and checking that it is in the $A$ since it is closed and this is a pointwise limit. Consequently, every chain has an upper bound, allowing the application of Zorn's lemma to guarantee the existence of a maximal element, which will be as required. } 
	
%	This can be proved by an extreme value theorem. We instead prove it directly. This is because the proof carries over to the infinite dimensional setting. 
%	
%	\begin{proof}	
%		Let $E:=\{Y\in\cl(\Conv(\Uwald(\O)))\given Y(\omega)>X(\omega)\text{ for all $\omega$}\}.$
%		
%		
%		Define $\preccurlyeq$ a partial ordering on $\Re^\Omega$ by $Y\preccurlyeq Z$ iff $Y(\omega)\leq Z(\omega)$. This partially orders $E$. We will use Zorn's lemma.
%		
%		Let $C$ be a chain in $E$, i.e., a collection of members of $E$ which is totally ordered by $\preccurlyeq$, i.e., where for $Y,Y'\in C$, $Y\preccurlyeq Y'$ or $Y'\preccurlyeq Y$. 
%		
%		Define $Z_C\in\Re^\Omega$ by $Z_C(\omega):=\sup\{Y(\omega)\given Y\in C\}$. Since utilities are bounded above for each $\omega$, this is well defined. 
%		
%		$Z_C(\omega)=\sup\{Y(\omega)\given Y\in C\}\geq Y(\omega)$ for all $Y\in C$. Thus $Z_C\succcurlyeq Y$ for all $Y\in C$. Also $Z_C(\omega)\geq Y(\omega)>X(\omega)$. So, to check that $Z_C$ is an upper bound for $C$ which is in $E$ we just need to check that $Z_C\in \cl(\Conv(\Uwald(\O)))$. 
%		
%		Since $C$ is a totally ordered by $\preccurlyeq$, it is a directed set, and the collection $\{Y\}_{Y\in C}$ defines a net in $\Re^\Omega$. For any fixed $\omega\in\Omega$, $\{Y(\omega)\}_{Y\in C}$ is a non-decreasing net of real numbers, and thus converges to $Z_C(\omega)=\sup\{Y(\omega)\given Y\in C\}$.
%		Since we are working with the product topology, this coordinatewise convergence implies that the net $\{Y\}_{Y\in C}$ converges to $Z_C$; and thus, since each $Y\in E\subseteq \cl(\Conv(\Uwald(\O)))$, by the closeness of the set, also $Z_C\in\cl(\Conv(\Uwald(\O)))$. 
%		
%		We have thus shown that $Z_C$ is  an upper bound for the chain $\C$ in $E$. 
%		We can now apply Zorn's lemma to show the existence of a maximal element in $E$. That is, some $Z\in E$ with $Y\succcurlyeq Z$ and $Y\in E$ implies $Y=Z$. This $Z$ is in $\cl(\Conv(\Uwald(\O)))$ and strictly dominates $X$. It is also not even weakly dominated in $\cl(\Conv(\Uwald(\O)))$, after all, any such weak dominator would be in $E$, contradicting the maximality of $Z$. 
%	\end{proof}
	
	
	
	
	
	
	
	
	
%	\begin{proof}
%		\begin{infversion}
%			If $Y$ strictly dominates $X$, then $Y$ in Fin. 
%		\end{infversion}
%		Starting with any point that strictly dominates $X$, generate Y (possibly transfinite) sequence of members of $\cl(\Conv(\Uwald(\O)))$ each of which weakly dominates all the previous ones until no more can be found. This sequence might be transfinite but it will terminate, at least by the cardinality of $\Re^\Omega$. In fact, it must terminate at some successor ordinal, i.e., some point $Z\in\cl(\Conv(\Uwald(\O)))$ which is not weakly dominated in $\cl(\Conv(\Uwald(\O)))$, which will give us our required $Z$. 
%		
%		This is because, if our sequence is indexed by a limit ordinal, then we can consider the pointwise supremum, which exists because we have assumed that utilities are bounded above. And since the points in the sequence weakly dominate the earlier ones, and it is indexed by a limit ordinal, the supremum point is distinct from all the points in the sequence, and weakly dominates them all. This supremum point is the limit point of this sequence in the topology of pointwise convergence, because in each coordinate we have a non-decreasing sequence thus converging to its supremum. Thus, since $\cl(\Conv(\Uwald(\O)))$ is closed, i.e., it contains all its limit points, this pointwise supremum is in $\cl(\Conv(\Uwald(\O)))$ and it weakly dominates all the previous points. Thus, the sequence may be extended beyond this limit-ordinal.
%	\end{proof}
%	
%	\begin{proof}
%		[Alternative proof following JK]
%		
%		
%		Define $\preccurlyeq$ an ordering on $\Re^\Omega$ by $Y\preccurlyeq Z$ iff $Y(\omega)\leq Z(\omega)$ for all $\omega$. Take any point, $Y_0$, which strictly dominates $X$. Then let  $D:=\{Z\in \cl(\Conv(\Uwald(\O)))\given Z\succcurlyeq Y_0\}$. This is partially ordered by $\preccurlyeq$. 
%		
%		Moreover, observe that $D$ is compact. To show this, first observe that $D\subseteq \bigtimes_{\omega} [Y_0(D),\mathsf{upperbound}\Uwald(\omega)]$, which is compact by Tychonoff's theorem. And $D=\cl(\Conv(\Uwald(\O)))\cap\{Z\given Z\succcurlyeq Y_0\}$, both of which are closed, the former by stipulation, the latter since it is $\bigcap_\omega\{Z\given Z(\omega)\geq Y_0(\omega)\}$, each component of which can be seen to be closed, so it is an arbitrary intersection of closed sets. 
%		
%		So $D$ is a closed subset of a compact set, and thus is itself compact. 
%		
%		And thus, every net has a cluster point. $D$ is itself a directed set under $\preccurlyeq$. NO ITS NOT! ITS NOT DIRECTED... GEQ Y0 PART OF IT IS DIRECTED BUT NOT THE CL U PART. 		
%		
%		
%		
%		
%		
%	\end{proof}


%We say: \begin{definition}
%	$\Uwald(\O)$ is \emph{closed from above} iff for every $Z\in\cl(\Conv(\Uwald(\O)))$ which is not weakly dominated in $\Conv(\Uwald(\O))$ is itself in $\Uwald(\O)$. 
%\end{definition}
%\begin{corollary}
%	If $\Uwald(\O)$ is closed from above, then $o$ is Bayes iff $o$ is not strictly dominated. 
%\end{corollary}
%	This immediately gets us:
	
%	This now gives us:
%	\begin{corollary}
%		If $\Uwald(\O)$ is closed and convex, then 
%		$o$ is Bayes iff $o$ is not strictly dominated.
%	\end{corollary}
%	Note that this requires $\Uwald(\O)$ to be closed and convex, not $\O$. 
	
	
	This will not apply to our general case yet. For that, we need further assumptions on the relationship between $\Uwald$ and $\O$. 
%\todo{are these assns on U or O?}


\todo{have we anywhere mentioned the topology and closure?}
\begin{definition}\ 
	\begin{itemize}
		\item $\O$ is \emph{Bayes-existing} (relative to $\Uwald$) iff, for every probability $p$, there is some $o\in\O$ that is Bayes for $p$.
		\item $\Uwald$ is \emph{Bayes-continuous} on $\O$ iff, for all $o\in\O$, if $o$ is Bayes for $p$ and $p_1,p_2,\ldots$ are probabilities converging to $p$ then there is some sequence of options $o_1,o_2,\ldots$, with $o_n$ Bayes for $p_n$, whose utility profiles converge to those of $o$. 
	\end{itemize}
\end{definition}
%For example, if $\Uwald$ is a measure of accuracy which is continuous and strictly proper, then these will be satisfied. They are, however, \emph{much} weaker than that.
	
	\begin{lemma}\label{thm:cct:bdry are the Bayes optimal}
		Suppose $\Uwald$ is Bayes-continuous on $\O$ and $\O$ is Bayes-existing. Then, if $Z\in\cl(\Conv(\Uwald(\O)))$ is not weakly dominated in $\Conv(\Uwald(\O))$, then $Z\in \Uwald(\O)$ and $Z$ is Bayes  in $\Uwald(\O)$. 
%		
%		The proof also shows t
	\end{lemma}
	%In the Wald setting, that is, that the lower boundary of $\Conv(\Uwald(\O))$ is a subset of $\Uwald(\O)$. This is then called $\Uwald(\O)$ being ``closed from below'' [in our case, above, as we're doing positive utility not loss]. This proof is where the assumptions on $\Uwald$ are vital. 
	
	\begin{proof}
		%	\todoold{JK wanted a more direct proof rather than something like this pf contradiction; but it wont work. It relies essentially on the Bayes existing part - that there is such $\Uwald(o_{p^*})$, so will have to involve that directly. Bayes cty itself doesn't tell us anything about $Z$ which isn't in $\Uwald(\O)$.}
		Since $Z$ is not weakly dominated, it is also not strictly dominated. So, by \cref{thm:cct:admiss in conv are Bayes in conv}, there is some probability function $p^*$ on $\Omega$ with $p^*(Z)\geq p^*(\Uwald(o))$, for all $o$. Since $\O$ is Bayes-existing, there is some $o_{p^*}$ that is Bayes for $p^*$ in $\Uwald(\O)$. 
		
		We will now show that $\Uwald(o_{p^*})(\omega)\geq Z(\omega)$ for every $\omega$. It will follow from this that $\Uwald(o_{p^*})(\omega)=Z(\omega)$, for every $\omega$, since we know that $Z$ is not weakly dominated, and so $\Uwald(o_{p^*})=Z$.%. or $\Uwald(o_{p^*})$ weakly dominates $Z$, which would contradict our assumption that $Z$ is not weakly dominated. 
		
		%So, what we need to show is that for every  $\omega$, $\Uwald(o_{p^*})(\omega)\geq Z(\omega)$. 
		
		%The argument we will make will work for every $\omega$.
		Hold fixed a single $\omega$, which we call $\omega^*$. Let $\pi_{\omega^*}$ be the projection function for the ${\omega^*}$ that we are considering, i.e., $\pi_{\omega^*}(Y):=Y({\omega^*})$. Then define $p_n$ by:
		\begin{align}
			p_n=(1-\sfrac{1}{n})p^*+\sfrac{1}{n} \pi_{{\omega^*}}
		\end{align}Note that this depends on the $\omega^*$ under consideration. Observe that $p_n$ is a probability function on $\Omega$. And so, since $\O$ is Bayes-existing, for each $n$, there is some $o_{p_n}$ that is Bayes optimal for $p_n$, i.e., $p_n(\Uwald(o_{p_n}))\geq p_n(\Uwald(o))$, for all $o$. Since we have assumed $Z\in\cl(\Conv(\Uwald(\O)))$, also $p_n( \Uwald(o_{p_n}))\geq p_n(Z)$.\footnote{To show this, we first observe it for any $Z\in \Conv(\Uwald(\O))$, just taking a mixture, and then note that taking limits can't break a non-strict inequality, $\geq$.}\todoold{should it be an official separate lemma?}
		
		We also know that $p^*(Z)\geq p^*(\Uwald(o_{p_n}))$. So, since $p_n$ is a mixture of $p^*$ and $\pi_{\omega^*}$,  to get that $p_n( \Uwald(o_{p_n}))\geq p_n(Z)$ we must in fact have that $\pi_{{\omega^*}}(\Uwald(o_{p_n}))\geq \pi_{\omega^*}(Z)$. That is, we can conclude that $\Uwald(o_{p_n})(\omega^*)\geq Z(\omega^*)$. 
		
		%		We will now show that $\Uwald(o_{p_n})({{\omega^*}^*})\geq Z({{\omega^*}^*})$ for all ${{\omega^*}^*}$. Suppose, for contradiction, that $Z({{\omega^*}^*})>\Uwald(o_{p_n})({{\omega^*}^*})$. Then $\pi_{{\omega^*}^*}(Z)>\pi_{{\omega^*}^*}(\Uwald(o_{p_n}))$. Since we know that $Z$ is Bayes for $p^*$ in $\Uwald(\O)$ and $\Uwald(o_{p_n})\in \Uwald(\O)$, also $p^*(Z)\geq p^*(\Uwald(o_{p_n}))$. Since $p_n$ is a mixture of $p^*$ and $\pi_{{\omega^*}^*}$ we would thus have $p_n(Z)>p_n(\Uwald(o_{p_n}))$, contradicting our choice of $\Uwald(o_{p_n})$ being Bayes for $p_n$. 
		
		Observe that $p_n\longrightarrow p^*$. So, since $\Uwald$ is Bayes-continuous on $\O$, $\Uwald(o_{p_n})\longrightarrow \Uwald(o_{p^*})$, so $\Uwald(o_{p_n})({\omega})\longrightarrow \Uwald(o_{p^*})({\omega})$ for each ${\omega}$. Thus, since $\Uwald(o_{p_n})({\omega^*})\geq Z({\omega^*})$ for all $n$, also $\Uwald(o_{p^*})(\omega^*)\geq Z(\omega^*)$. 
		
		Now, this worked for any $\omega$. That is, for any $\omega$ we can construct the relevant sequence and apply this argument. So, we have in fact shown that $\Uwald(o_{p^*})(\omega)\geq Z(\omega)$ for all $\omega$. And so, as noted above, it follows that $\Uwald(o_{p^*})=Z$, for if $\Uwald(o_{p^*})(\omega) > Z(\omega)$ for any $\omega$, $\Uwald(o_{p^*})$ would weakly dominate $Z$, and, by assumption, this isn't the case.
	\end{proof}
	This proof in fact shows that the assumptions on $\O$ and $\Uwald$ are very strong. It shows that for every probability there is a unique member of $\cl(\Conv(\Uwald(\O)))$ that is not weakly dominated; thus also that for every regular probability, there is a unique Bayes option. 
	
%	\begin{theorem}
%		Suppose $\Uwald$ is Bayes existing and Bayes continuous. Then if $X$ is not Bayes in $\Uwald(\O)$, it is strictly dominated in $\Uwald(\O)$, moreover, it is strictly dominated by a Bayes point in $\Uwald(\O)$.
%	\end{theorem}
%	\begin{proof}
%		If $X$ is not Bayes in $\Uwald(\O)$, then, by \cref{thm:cct:admiss in conv are Bayes in conv}, it is strictly dominated in $\Conv(\Uwald(\O))$. 
%		
%		By \cref{thm:cct:dominator on boundry} it is thus strictly dominated by some $Z\in\cl(\Conv(\Uwald(\O)))$ which is itself not weakly dominated in $\Conv(\Uwald(\O))$. By \cref{thm:cct:bdry are the Bayes optimal}, in fact $Z\in \Uwald(\O)$, and moreover, it is in fact a Bayes point; as required.
%	\end{proof}
%	This applies to any $X$, whether or not it is in $\Uwald(\O)$ itself, but of course we actually want the result for $o$. 
	\begin{theorem}\label{thm:cct}
		Suppose $\O$ is Bayes-existing and $\Uwald$ is Bayes-continuous on $\O$. Then, if $o$ is not Bayes then there is $o'$ that strictly dominates it; moreover, it is strictly dominated by an option that is itself Bayes and not even weakly dominated. 
	\end{theorem}
\begin{proof}
			If $o$ is not Bayes in $\Uwald(\O)$, then, by \cref{thm:cct:admiss in conv are Bayes in conv}, $\Uwald(o)$ is strictly dominated in $\Conv(\Uwald(\O))$. 
	
	By \cref{thm:cct:dominator on boundry} it is thus strictly dominated by some $Z\in\cl(\Conv(\Uwald(\O)))$ which is itself not weakly dominated in $\Conv(\Uwald(\O))$. By \cref{thm:cct:bdry are the Bayes optimal}, in fact $Z = \Uwald(o_Z)$, for some $o_Z$ in $\O$, and moreover, $o_Z$ is Bayes, as required.
\end{proof}


We now have two versions of Wald's Complete Class Theorem: the first we proved along the way to proving the second. First: if $\Uwald(\O)$ is convex then $o$ is Bayes iff $o$ is not strictly dominated. Second: if $\Uwald$ is Bayes-continuous over $\O$ and $\O$ is Bayes-existing, then again $o$ is Bayes iff $o$ is not strictly dominated.

\subsection{Applying Wald's Complete Class Theorem to probabilistic picking strategies for imprecise decision theories}\label{sect:wald-app:appendix}


%\begin{colored}{violet}

\begin{itemize}
	\item Fix $\mu^*$ a measure over $\D$. 
\item The options, $\O$, are a specified collection of probabilistic picking strategies, $\Nu$.
\item The utility of a probabilistic picking strategy $\n$ at $\omega$ is the expectation of the utility you'll obtain at $\omega$ by picking in accordance with $\n$.
\\$\Uwald:\Nu\times\Omega\to[l,u]$ defined by $\Uwald(\nu)(\omega):=\Exp_{\mu^*}[\U(\nu)(\omega)]$.
%\item $\Uwald(\n)(\omega):=\Exp_{\mu^*}[\U(\nu)(\omega)]$. 
\\That is, $\Uwald(\nu)(\omega)=\Exp_{D\sim \mu^*}[\U(\nu)(\omega,D)]=\Exp_{D\sim \mu^*}[\Exp_{a\sim \nu_D}[\U(a)(\omega)]]$.
%\item $\Uwald(\n)(\omega):=\Exp_{\mu^*}[\U(\n, -)(\omega)]=\Exp_{\mu^*}[\Exp_{\n_{-}}[ \U(\cdot)(\omega)]$. 
\end{itemize}

Recall \cref{def:EU-complete}, which says when $\Nu$ is $\EU$-complete.%, and observe that Bayes-existing immediately follows. 
\begin{lemma}\label{thm:cct-appln:existing}
	Suppose $\Nu$ is $\EU$-complete.
	
	Then $\nu$ is Bayes for $p$ in $\O$, relative to $\Uwald$, iff $\nu$ $\mu^*$-surely picks for $\EU_p$. 
	
	Also $\Nu$ is Bayes-existing, relative to $\Uwald$.
\end{lemma}
\begin{proof}
	$\nu$ is Bayes for $p$ in $\Nu$, relative to $\Uwald$, iff
	for all $\nu'\in\Nu$, $p(\Uwald(\nu))\geq p(\Uwald(\nu'))$. That is, $\Exp_p[\Exp_{\mu^*}[\U(\nu)]]\geq \Exp_p[\Exp_{\mu^*}[\U(\nu')]]$. 
	This is when $\nu\in\EU_{p\times\mu^*}(\Nu)$. 
	
	By \cref{thm:EU-appendix corollary}, using the $\EU$-completeness of $\Nu$, this is just when $\nu$ $\mu^*$-surely picks for $\EU_p$.
	
	By $\EU$-completeness, for any $p$ there is some such $\nu\in\Nu$. So $\Nu$ is Bayes-existing, relative to $\Uwald$. 
\end{proof}

Recall \cref{def:suff spread}, which says when a measure requires almost everywhere decisiveness.
\begin{lemma}\label{thm:cct-appln:cts}
	Suppose $\Nu$ is $\EU$-complete. 
	
	If ${\mu^*}$ requires almost everywhere decisiveness,
	then $\Uwald$ is Bayes continuous on $\Nu$.
%	then $\nu, \omega \mapsto\Uwald(\n)(\omega)$ is Bayes continuous on $\Nu$.%\todo{here the variables are being used whereas earlier we just did $\Exp_{\mu^*}[\Exp_{\n_D}[\U]]]$. We should proabbly be consistent}
\end{lemma}%\todo{remove ctbly add}
%Recall that we have assumed that all probabilities are countably additive. 
\begin{proof}
Suppose $p^*$ is a probability function over $\Omega$. And suppose $p_1,p_2\ldots$ is a sequence of probability functions over $\Omega$ that converges to $p^*$.
%	We will show that for any $\n^{p^*}$ which is Bayes for $p^*$ and $\n^{p_k}$ which are Bayes for $p_k$, we have the utility profiles of $\n^{p_k}$ converge to the utility profile of $\nu^{p^*}$. 

Take $\nu^*\in\Nu$ Bayes for $p^*$ and $\nu^1,\nu^2,\ldots$ in $\Nu$ with $\nu^k$ Bayes for $p_k$. This is possible by \cref{thm:cct-appln:existing}, and also by that \namecref{thm:cct-appln:existing}, $\nu^*$ $\mu^*$-surely picks for $\EU_{p^*}$ and each $\nu^k$ $\mu^*$-surely picks for $\EU_{p_k}$. 
That is, $\mu^*(\Set{D \given \nu^*_{\;D}(\EU_{p^*}(D)) = 1})=1$, and $\mu^*(\Set{D  \given \nu^k_{\;D}(\EU_{p_k}(D)) = 1})=1$ for each $k$.

Let $$E:=\Set{D\given \nu^*_{\;D}(\EU_{p^*}(D)) = 1\text{ and for all $k$,  $\nu^k_{\;D}(\EU_{p_k}(D)) = 1$}}.$$
By countable additivity, $\mu^*(E)=1$. 

Let $$S:=\{D\given \EU_{p^*}(D)\text{ is a singleton}\}.$$ As $\mu^*$ requires almost everywhere decisiveness, $\mu^*(S)=1$. 

%
%
%We will show that for each $\omega\in\Omega$,  $\Uwald(\n^{p_k})(\omega)\longrightarrow\Uwald(\nu^*)(\omega)$; that is, $\Exp_{\mu^*}[\U(\nu^k)(\omega)]\longrightarrow\Exp_{\mu^*}[\U(\nu^*)(\omega)]$. 

Take any $\omega^*\in\Omega$ and $D^*\in E\cap S$. 

$\EU_{p^*}(D^*)$ is a singleton, so let $\EU_{p^*}(D^*)=\{a^*\}$. As $\nu^*_{\;D^*}(\{a^*\})=1$, observe that  $\U(\nu^*)(\omega^*,D^*)=\U(a^*)(\omega^*)$. 

Expected utility is continuous as a function of probabilities; \todo{Any more comment or justification here?}i.e., for all $a\in\A$, $\Exp_{p_k}[\U(a)]\longrightarrow \Exp_{p^*}[\U(a)]$. Thus, as $D^*$ is finite, there is some $N\in\mathbb{N}\setminus\{0\}$ such that for all $k>N$, $\EU_{p_k}(D^*)=\{a^*\}$.%
\footnote{If $D^*$ is an infinite  compact set, one can use Berge's Maximum Theorem to observe that $\EU_p(D^*)$ is upper hemi-continuous, so that if $p_k\longrightarrow p^*$ and $V$ is an open set with $\EU_{p^*}(D^*)\subseteq V$, then there is some $N$ such that for all $k>N$, $\EU_{p_k}(D^*)\subseteq V$. Let $V_{\epsilon}=\{a\given \abs{\U(a)(\omega^*)-\U(a^*)(\omega^*)}<\epsilon\}$, which is open superset of $\EU_{p^*}(D^*)=\{a^*\}$. So there is some $N$ such that for all $k>N$, any $a_k\in\EU_{p_k}(D^*)$ is in $V_{\epsilon}$, and so $\abs{\U(a)(\omega^*)-\U(a^*)(\omega^*)}<\epsilon$; thus also $\abs{\U(\nu^k)- a^*(\omega^*)}<\epsilon$; so $\U(\nu^k)(\omega^*,D^*)\longrightarrow\U(\nu^*)(\omega^*,D^*)$. } 

And so, for each $k>N$, $\nu^k_{\;D^*}(\{a^*\})=1$ and  so $\U(\nu^k)(\omega^*,D^*)=\U(a^*)(\omega^*)=\U(\nu^*)(\omega^*,D^*)$. 

This gives us that $\U(\nu^k)(\omega^*,D^*)\longrightarrow\U(\nu^*)(\omega^*,D^*)$. 

So we have that for any  $D\in E\cap S$, $\U(\nu^k)(\omega^*,D)\longrightarrow\U(\nu^*)(\omega^*,D)$.
As we know that  $\mu^*(E\cap S)=1$, we can use a Dominated Convergence Theorem (as utilities are bounded) to obtain
$\Exp_{\mu^*}[\U(\nu^k)(\omega^*)]\longrightarrow\Exp_{\mu^*}[\U(\nu^*)(\omega^*)]$. That is, $\Uwald(\nu^k)(\omega^*)\longrightarrow\Uwald(\nu^*)(\omega^*)$. 

As this holds for any $\omega\in\Omega$, we have that $\Uwald$ is Bayes continuous on $\Nu$. 
\end{proof}
%\end{colored}

%\begin{proof}
%Suppose $p^*$ is a probability function over $\Omega$. And suppose $p_1,p_2\ldots$ is a sequence of probability functions over $\Omega$ that converges to $p^*$, that is, $p_1,p_2\ldots \longrightarrow p^*$. We will show that for any $\n^{p^*}$ which is Bayes for $p^*$ and $\n^{p_n}$ which are Bayes for $p_n$, we have $\Uwald(\n^{p_n})\longrightarrow\Uwald(\n^{p^*})$. 
%
%Suppose that $D$ is such that: (i) $\EU_{p^*}(D)= \{a^*\}$, (ii) $\n^{p_n}_D(\EU_{p_n}(D))=1$, and (iii) $\n^{p^*}_D(\EU_{p^*}(D))=1$, so that $\n^{p^*}_D(\{a^*\}) = 1$. 
%For every $a$,  $\Exp_{p_n}[\U(a)]\longrightarrow\Exp_{p^*}[\U(a)]$. 
%If $D$ is finite, there must be some $N$ such that for all $n>N$, also $\EU_{p_n}(D)=\{a^*\}$. 
%And then $\U(\n^{p_n})(\omega, D)=\Exp_{\n^{p_n}_D}a(\omega)=a^*(\omega)= \Exp_{\n^{p^*}_D}a(\omega) = \U(\n^{p^*})(\omega, D)$.\footnote{If $D$ is an infinite  compact set, one can use Berge's Maximum Theorem to observe that $\EU_p(D)$ is upper hemi-continuous, so that if $p_n\longrightarrow p^*$ and $V$ is an open set with $\EU_{p^*}(D)\subseteq V$, then there is some $N$ such that for all $n>N$, $\EU_{p_n}(D)\subseteq V$. Let $V_{\epsilon}=\{a\given \abs{a(\omega)-a^*(\omega)}<\epsilon\}$, which is open containing $\EU_{p^*}(D)=\{a^*\}$. So there is some $N$ such that for all $n>N$, any $a_n\in\EU_{p_n}(D)$ is in $V_{\epsilon}$, and so $\abs{a(\omega)-a^*(\omega)}<\epsilon$; thus also $\abs{\Exp_{\nu_D^{p_n}} a(\omega)- a^*(\omega)}<\epsilon$; so the utility profiles converge. }
%
%
%Next, we show that the set of $D$ for which (i), (ii), and (iii) hold has measure 1, and so, since the utilities are bounded, a Dominated Convergence Theorem gives us:
%$$\Exp_{\mu^*}[\U(\n^{p_n})(\omega)] \longrightarrow \Exp_{\mu^*}[\U(\n^{p^*})(\omega)]$$which is what we wish to prove.
%
%We have supposed that $\n^{p^*}$ is Bayes for $p^*$ and $\n^{p_n}$ are Bayes for $p_n$. Thus, by \cref{thm:EU-appendix}, $\n^{p^*}$ ${\mu^*}$-surely picks for $\EU_{p^*}$
%and $\n^{p_n}$ ${\mu^*}$-surely pick for $\EU_{p_n}$. 
%Let:
%\begin{itemize}
%	\item $\X^* = \Set{D \in \D \given \n^{p^*}_D(\EU_{p^*}(D)) = 1 }$
%	\item $\X^n = \Set{D \in \D \given \n^{p_n}_D(\EU_{p^n}(D)) = 1 }$
%	\item $\Y^* = \Set{D \in \D \given \EU_{p^*}(D) \emph{ is a singleton}}$
%\end{itemize}
%We thus know that ${\mu^*}(\X^*) = {\mu^*}(\X^n)=1$. We also know that ${\mu^*}(\Y^*) = 1$, since we have assumed that ${\mu^*}$ requires almost everywhere decisiveness. And so, since ${\mu^*}$ is countably additive,
%$${\mu^*}\left (\X^* \cap \bigcap^n_{n=1} \X^n \cap \Y^* \right ) = 1.$$This completes the proof.
%\end{proof}

\begin{corollary}\label{thm:cct-applns:corr}
	Suppose that $\Nu$ is EU-complete, and suppose $\mu^*$ requires almost everywhere decisiveness. 
	
%	If $\n$ does not $\mu^*$-surely pick for $p$, for any probability $p$, then there is some $\n'$
	
	If there is no probability $p$ over $\Omega$ for which $\n$ maximises $\Exp_{p}[\Exp_{\mu^*}[\U(\n)]]$; then there is some $\n'$ such that $\Exp_{\mu^*}[\U(\n')(\omega)]>\Exp_{\mu^*}[\U(\n)(\omega)]$ for all $\omega\in\Omega$. 
\end{corollary}
\begin{proof}
	This is immediate from \cref{thm:cct,thm:cct-appln:existing,thm:cct-appln:cts}.
\end{proof}
\begin{corollary}\label{cor:max-dom}
		Suppose that $\Nu$ is EU-complete, $\mu^*$ requires almost everywhere decisiveness. %\todo{why are we explicitly stating ctbly add here. Surely for the existence of the conditionals we need the ctbly add. i was assuming that we had assumed somewhere in general that it was ctbly add.....!!!!!}
		
	If $\n$ does not $\mu^*$-surely pick for $\EU_p$ for any probability $p$, then there is some $\n'$ such that for all probabilities $p$, $\Exp_{p\times\mu^*}[\U(\n')]>\Exp_{p\times\mu^*}[\U(\n)]$. 
\end{corollary}
\begin{proof}
	By \cref{thm:EU-appendix}, if $\n$ does not $\mu^*$-surely pick for any probability $p$, $\n$ does not maximise $\Exp_{p\times\mu^*}[\U(\n)]$ for any $p$. Observe, also that $\Exp_p[\Exp_{\mu^*}[\U(\n)]]=\Exp_{p\times\mu^*}[\U(\n)]$. So by \cref{thm:cct-applns:corr}, there is $\n'$ with  $\Exp_{\mu^*}[\U(\n')(\omega)]>\Exp_{\mu^*}[\U(\n)(\omega)]$ for all $\omega$; and thus, $\Exp_{p}[\Exp_{\mu^*}[\U(\n')]]>\Exp_p[\Exp_{\mu^*}[\U(\n)]]$ for all probabilities $p$; which gives us the claim.
\end{proof}
\cref{thm:max-nu} follows from this. \cref{thm:max-existsimpermissible[dep]} follows from this together with \cref{thm:ead-existsimpermissible[dep]}, since Maximality is more permissive than E-Admissibility.



Let $\c$ be any choice function. 


\begin{proposition}[\cref{thm:atomless-existsimpermissible}]
	If $\mu^*$ is atomless and $\mu^*\{D\given \c(D)\subseteq\EU_p(D)\}<1$ then there is $\s$ which picks for $\c$ but for no $p$ does it $\mu^*$-surely pick for $\EU_p$. 
\end{proposition}
\begin{proof}
	
	Let $t_q(D):=\sup_{a \in D} \Exp_q[\U(a)]$.
	
	Let $G(q,D,\epsilon):=\{b\given t_q(D)>\Exp_q[b]+\epsilon\}$. 
	
	  \begin{sublemma}
		There is some $\epsilon_q>0$ such that $\mu^*\{D\given G(q,D,\epsilon_q)\cap\c(D)\neq \emptyset\}>0$. 
	\end{sublemma}
	\begin{proof}
		We have assumed that $\mu^*\{D\given \c(D)\not \subseteq\EU_p(D)\}>0$. 
		Observe
		\begin{align}
			\{D\given \c(D)\not\subseteq\EU_p(D)\}&=\{D\given\exists b\in\c(D)\text{ and }t_q(D)>\Exp_q[b] \}\\
			&=\bigcup_{k\in\mathbb{N}}\{D\given\exists b\in \c(D)\text{ and }t_q(D)>\Exp_q[b]+\nicefrac{1}{k} \}\\
			&=\bigcup_{k\in\mathbb{N}}\{D\given G(q,D,\nicefrac{1}{k})\cap c(D)\neq \emptyset\}
		\end{align}
		so it follows from countable additivity that there is some $k$ such that $\mu^*\{D\given G(q,D,\nicefrac{1}{k})\cap\c(D)\neq \emptyset\}>0$. This gives us our $\epsilon_q$ as $\nicefrac{1}{k}$ for this $k$. 
	\end{proof}
	
	
	We have assumed that utility is bounded. Put $M>0$ such that $\|\U(a)\|_\infty=\sup\{|\U(a)(\omega)|\given \omega\in\Omega\}\leq M$ for all $a$, that is $M\geq\max\{|l|,|h|\}$ if $\U:\A\to[l,h]^\Omega$. 	Let $$U_q:=\{p\in\Prob\given \|q-p\|_1<\frac{\epsilon_q}{4M}\}.$$
	These are open, and cover $\Prob$ as $p\in U_p$. 
	So by compactness, there is a finite sub-cover, $U_{q_1},\ldots, U_{q_n}$. 
	
	Let $$C_i:=\{D\given G(q_i,D,\epsilon_{q_i})\cap \c(D)\neq\emptyset\}.$$
	and note that we have $\mu^*(C_i)>0$ by choice of $\epsilon_{q_i}$.
	\begin{sublemma}
		We can choose $E_i\subseteq C_i$ pairwise disjoint and with $\mu^*(E_i)>0$
	\end{sublemma}
	\begin{proof}
		This uses the atomlessness of  $\mu^*$.
		
		Put $\alpha=\min\{\mu^*(C_1),\ldots,\mu^*(C_k)\}$. 
		
		Choose $E_1\subseteq C_1$ with $0<\mu^*(E_1)\leq \frac{\alpha}{k}$ (possible since $\mu^*$ is atomless). 
		
		Then $\mu^*(C_2\setminus E_1)\geq\alpha-\frac{\alpha}{k}\geq\frac{\alpha}{k}$ so we can choose $E_2\subseteq C_2\setminus E_1$ with $0<\mu^*(E_2)\leq\frac{\alpha}{k}$. 
		
		Then $\mu^*(C_3\setminus(E_1\cup E_2))\geq\alpha-2\frac{\alpha}{k}\geq \frac{\alpha}{k}$ so we can choose $E_3\subseteq C_3\setminus (E_1\cup E_2)$ with $0<\mu^*(E_3)\leq\frac{\alpha}{k}$. 
		
		And so on, with the final stage ensuring $\mu^*(C_k\setminus(E_1\cup\ldots\cup E_{k-1}))\geq\alpha-(k-1)\frac{\alpha}{k}=\frac{\alpha}{k}$ so we can choose $E_k\subseteq C_k\setminus (E_1\cup \ldots\cup E_{k-1})$ with $0<\mu^*(E_k)\leq\frac{\alpha}{k}$.  
	\end{proof}
	
	Then put $\s(D)\in G(q,D,\epsilon_q)\cap\c(D)$ for $D\in E_i$, and $\s(D)\in \c(D)$ for $D\notin\bigcup_{i=1,\ldots,k} E_i$. 
	
	Observe that $\s(D)$ picks for $\c$ by definition. 
	
	Take any $p\in\Prob$. 
	As $U_{q_1},\ldots, U_{q_n}$ cover $\Prob$, there is some $i$ such that $p\in U_{q_i}$. 
	
	We will show that for any $D\in E_i$, $\s(D)\notin\EU_p(D)$. This will use the following sublemma:
		\begin{sublemma}
		Suppose $p\in U_q$. If $b\in G(q,D,\epsilon_q)$ then $b\notin\EU_p(D)$.
	\end{sublemma}
	\begin{proof} As $b\in G(q,D,\epsilon_q)$,  $t_q(D)>\Exp_q[\U(b)]+\epsilon_q$, where $t_q(D)=\sup_{a \in D}\Exp_q[\U(a)]$. Take $a^*\in \EU_q(D)$ so that $\Exp_q[\U(a^*)]=t_q(D)$ so that $\Exp_q[\U(a^*)]-\Exp_q[\U(b)]\geq \epsilon_q$. 
		
		As  $p\in U_q$, we have $\|q-p\|_1<\frac{\epsilon_q}{4M}$.
		
		So	
		\begin{align}
			\Exp_p[\U(a^*)]-\Exp_p[\U(b)]&=\left(\Exp_q[\U(a^*)]-\Exp_q[\U(b)]\right)+(p-q)\cdot(\U(a^*)-\U(b))\\
			&\geq \epsilon_q -|(p-q)\cdot(\U(a^*)-\U(b))|\\
			&\geq \epsilon_q -\|p-q\|_1\|\U(a^*)-\U(b)\|_\infty&&\text{H\"older's indequality}\\
			&\geq  \epsilon_q -\frac{\epsilon_q}{4M}\times 2M=\epsilon_q -\nicefrac{\epsilon_q}{2}=\nicefrac{\epsilon_q}{2}>0
		\end{align}
		This shows that $b\notin\EU_p(D)$. 
	\end{proof}
	Since we have chosen $\s(D)\in G(q_i,D,\epsilon_{q_i})$ for $D\in E_i$, we have $\{D\given \s(D)\notin\EU_p(D)\}\supseteq E_i$, and thus, $\mu^*\{D\given \s(D)\notin\EU_p(D)\}>0$. 
\end{proof}















\begin{proposition}[\cref{thm:max-nu-reg-nec}]
	Suppose $\Nu$ is $\EU$-complete. 
	Suppose that $\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$ and $\mu^*$ requires almost everywhere decisiveness. Suppose that, for every probability $p$, $\mu^*\{D\given \Maximality_\IP(D)\subseteq\EU_p(D)\}< 1$. Then, if $\n$ is a regular picking strategy for $\Maximality_{\IB(\cdot|-)}$ then $\n\notin \Maximality_\IB(\Nu)$.
\end{proposition}

\begin{proof}
	Suppose $\nu$ is a regular picking strategy for $\Maximality_{\IB(\cdot|-)}$ and the conditions of the theorem hold. 
	
	Take any $p\in\IP$.
	If $\Maximality_{\IB(\cdot|-)}(D)\not\subseteq\EU_p(D)$, then, since $\n_D$ is a regular probability function, $\nu_D(\EU_p(D))< 1$. 
	Since 
	$b_\D\{D\given \Maximality_{\IB(\cdot|-)}(D)\not\subseteq\EU_p(D)\}>0$, we have $\mu^*\{D\given \nu(\EU_p(D))<1\}>0$.
	 So $\nu$ does not $\mu^*$-surely pick for $\EU_p$. Since this holds for any $p \in \IP$, \cref{cor:max-dom} tells us that $\nu\notin\Maximality_\IB(\Nu)$. 
\end{proof}

\begin{colored}{blue}

\begin{proposition}[\cref{thm:gamma-nu}]
Suppose $\Nu$ is $\EU$-complete. Suppose that 
		$\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$ and $\mu^*$ requires almost everywhere decisiveness. Then if $\n \in \Maximin_\IB(\Nu)$, there is some probability $p$ where $\n$ $\mu^*$-surely picks for $\EU_p$.
		
		Suppose that for every probability $p$, $\mu^*\{D\given \Maximin_\IP(D)\subseteq\EU_p(D)\}<1$. 
		Then if $\n$ is regular for $\Maximin_\IP$ then $\n\notin \Maximin_\IB(\Nu)$.

%		If, in addition, $\mu^*\{D\given \Maximin_\IP(D)\text{ is singleton}\}=1$, then 
%	 there is $\s$ which picks for $\Maximin_\IP$ but which is not in $\Maximin_\IB(\S)$. 

	\end{proposition}


\begin{proof}
	Suppose that $\n \in \Maximin_\IB(\Nu)\subseteq\Maximality_\IB(\Nu)$. By  \cref{thm:max-nu}, there is some probability $p$ where $\n$ $\mu^*$-surely picks for $\EU_p$.
	
	
	Suppose $\nu$ is a regular picking strategy for $\Maximin_\IP$ and the conditions above hold. 
	
	Take any $p\in\IP$.
	If $\Gamma_{\IP}(D)\not\subseteq\EU_p(D)$, then, since $\n_D$ is a regular probability function, $\nu_D(\EU_p(D))< 1$. 
	Since 
	$\mu^*\{D\given \Maximin_\IP(D)\not\subseteq\EU_p(D)\}>0$, we have $\mu^*\{D\given \nu(\EU_p(D))<1\}>0$.
	 So $\nu$ does not $\mu^*$-surely pick for $\EU_p$. Since this holds for any $p \in \IP$, we must have $\n \not\in \Maximin_\IB(\Nu)$.
	 
\end{proof}
\end{colored}










\begin{comment}

\section{JK Results Old}

Let $\c$ be any choice function. Let $r:\Decs\rightarrow[0,1)$ be any measurable statistic, \textit{e.g.},  $r(D)=\Bigl(\sum_{x\in D}\|x\|^{2}\Bigr)\bmod 1$. 

\begin{enumerate}
\item[(A1)] \textbf{Positive disagreement\!.}\\[2pt]
      For every $p\in P$, $\mu^*(B_p)>0$, where
      \[
        B_{p}:=\bigl\{D\in\Decs\given \c(D)\not \subseteq\EU_p(D)\bigr\}.
      \]
\item[(A2)] \textbf{Menu richness\!.}\\[2pt]
      For every open interval $I\subset[0,1)$
      \[
        \mu^*\bigl(\,D\in B_{p}\given r(\c(D))\in I \bigr)>0,
      \]
%         \emph{Note:} For many choice functions (E-Admissibility, Maximality, $\Gamma$-Maximin) $(\text{A2})$ holds if decision problems in $\mu$'s support contain gambles with a component that can vary continuously over a sufficiently large range.
\end{enumerate}


\begin{theorem}\label{thm:selection-func-exists}
Given \textup{(A1)} and \textup{(A2)}, there exists a measurable function
$
  \s:\Decs\to\mathbb \A
$
which picks for $\c$ but for no $p$ does it $\mu^*$-surely pick for $\EU_p$. 
\end{theorem}

\begin{proof}
For any $D\in\Decs$, enumerate the choice set in lexicographic order
$
  \c(D)=\{x_{1}(D),\dots,x_{n_D}(D)\}.
$
where $n_D=|\c(D)|$. Partition $[0,1)$ into $n_D$ intervals
$
  I_{j}(D)=\bigl[\tfrac{j-1}{n_D},\tfrac{j}{n_D}\bigr)
$.
Define
\[
  k(D)=\min\bigl\{j\given r(\c(D))\in I_{j}(D)\bigr\},
  \qquad
  s(D)=x_{k(D)}(D).
\]
Measurability follows immediately from the measurability of $r$ and $\min$, and $s(D)\in\c(D)$ by construction. So $\s$ picks for $\c$.

Choose $p\in\IP$.

\medskip
\noindent
\textbf{Step 1.}  
For each $D\in B_{p}$ choose
$x_{\beta(D)}(D)\notin\EU_{p}(D)$.
If $r(D)\in I_{\beta(D)}(D)$ then $s(D)=x_{\beta(D)}(D)\notin\EU_{p}(D)$.


\medskip
\noindent
\textbf{Step 2.}
Define
$
  A_{p}:=\{D\in B_{p}\given r(\c(D))\in I_{\beta(D)}(D)\}.
$
Because $I_{\beta(D)}(D)$ has positive length $1/n_D$, assumption \textup{(A2)} implies $\mu^*(A_{p})>0$.




\medskip
\noindent
\textbf{Step 3.}  
For all $D\in A_{p}$, $s(D)\notin\EU_{p}(D)$, hence
\[
  \mu^*\bigl(\,D\given s(D)\notin\EU_{p}(D)\bigr)\ge\mu^*(A_{p})>0.
\]
Therefore
$
  \mu^*\bigl(\,D\given s(D)\in\EU_{p}(D)\bigr)<1.
$
So $\s$ does not $\mu^*$-surely pick for $\EU_p$.

\end{proof}




\begin{lemma}\label{lem:simple-suff-cond}
	If $\c$ is a choice function, \textup{(A1)} holds, $\mu^*$ is absolutely continuous with respect to the Borel measure on $(\Decs,\Sigma)$, $q:\Decs\rightarrow\mathbb{R}$ is a $\mu^*$-measurable statistic, $r:\Decs\rightarrow[0,1)$ is defined by $r(D):=|q(D)|\bmod 1$, and $f_p$ is the marginal density for $q$ of $\mu^*_p(\cdot):=\mu^*(\cdot\cap B_p)/\mu^*(B_p)$, then the following is sufficient for \textup{(A2)}: there exist $\tau\in\mathbb R$, $\delta\ge 1$, $\epsilon>0$ such that $f_p(t)\ge \epsilon$ for a.e.\ $t\in[\tau,\tau+\delta]$.
\end{lemma}

\begin{proof}
	For any open $I\subset[0,1)$,
	\[
	\mu^*_p(r(\c(D))\in I)\geq\mu^*_p(q(\c(D))\in [\tau,\tau+\delta])=\int_{[\tau,\tau+\delta]} f_p(t)\,dt\geq\epsilon\cdot\delta>0.
	\]
	This implies $\mu^*\bigl(\,D\in B_{p}\given r(\c(D))\in I \bigr)>0$.
\end{proof}



\section{CCM Old}
\begin{theorem}
	If $\mu^*$ is atomless and $\mu^*\{D\given \c(D)\subseteq\EU_p(D)\}<1$ then there is $\s$ which picks for $\c$ but for no $p$ does it $\mu^*$-surely pick for $\EU_p$. 
\end{theorem}
\begin{proof}
	
	Let $t_q(D):=\sup_{a \in D} \Exp_q[\U(a)]$.
	
	Let $G(q,D,\epsilon):=\{b\given t_q(D)>\Exp_q[b]+\epsilon\}$. 
	
	  \begin{sublemma}
		There is some $\epsilon_q>0$ such that $\mu^*\{D\given G(q,D,\epsilon_q)\cap\c(D)\neq \emptyset\}>0$. 
	\end{sublemma}
	\begin{proof}
		We have assumed that $\mu^*\{D\given \c(D)\not \subseteq\EU_p(D)\}>0$. 
		Observe
		\begin{align}
			\{D\given \c(D)\not\subseteq\EU_p(D)\}&=\{D\given\exists b\in\c(D)\text{ and }t_q(D)>\Exp_q[b] \}\\
			&=\bigcup_{k\in\mathbb{N}}\{D\given\exists b\in \c(D)\text{ and }t_q(D)>\Exp_q[b]+\nicefrac{1}{k} \}\\
			&=\bigcup_{k\in\mathbb{N}}\{D\given G(q,D,\nicefrac{1}{k})\cap c(D)\neq \emptyset\}
		\end{align}
		so it follows from countable additivity that there is some $k$ such that $\mu^*\{D\given G(q,D,\nicefrac{1}{k})\cap\c(D)\neq \emptyset\}>0$. This gives us our $\epsilon_q$ as $\nicefrac{1}{k}$ for this $k$. 
	\end{proof}
	
	
	We have assumed that utility is bounded. Put $M>0$ such that $\|\U(a)\|_\infty=\sup\{|\U(a)(\omega)|\given \omega\in\Omega\}\leq M$ for all $a$, that is $M\geq\max\{|l|,|h|\}$ if $\U:\A\to[l,h]^\Omega$. 	Let $$U_q:=\{p\in\Prob\given \|q-p\|_1<\frac{\epsilon_q}{4M}\}.$$
	These are open, and cover $\Prob$ as $p\in U_p$. 
	So by compactness, there is a finite sub-cover, $U_{q_1},\ldots, U_{q_n}$. 
	
	Let $$C_i:=\{D\given G(q_i,D,\epsilon_{q_i})\cap \c(D)\neq\emptyset\}.$$
	and note that we have $\mu^*(C_i)>0$ by choice of $\epsilon_{q_i}$.
	\begin{sublemma}
		We can choose $E_i\subseteq C_i$ pairwise disjoint and with $\mu^*(E_i)>0$
	\end{sublemma}
	\begin{proof}
		This uses the atomlessness of  $\mu^*$.
		
		Put $\alpha=\min\{\mu^*(C_1),\ldots,\mu^*(C_k)\}$. 
		
		Choose $E_1\subseteq C_1$ with $0<\mu^*(E_1)\leq \frac{\alpha}{k}$ (possible since $\mu^*$ is atomless). 
		
		Then $\mu^*(C_2\setminus E_1)\geq\alpha-\frac{\alpha}{k}\geq\frac{\alpha}{k}$ so we can choose $E_2\subseteq C_2\setminus E_1$ with $0<\mu^*(E_2)\leq\frac{\alpha}{k}$. 
		
		Then $\mu^*(C_3\setminus(E_1\cup E_2))\geq\alpha-2\frac{\alpha}{k}\geq \frac{\alpha}{k}$ so we can choose $E_3\subseteq C_3\setminus (E_1\cup E_2)$ with $0<\mu^*(E_3)\leq\frac{\alpha}{k}$. 
		
		And so on, with the final stage ensuring $\mu^*(C_k\setminus(E_1\cup\ldots\cup E_{k-1}))\geq\alpha-(k-1)\frac{\alpha}{k}=\frac{\alpha}{k}$ so we can choose $E_k\subseteq C_k\setminus (E_1\cup \ldots\cup E_{k-1})$ with $0<\mu^*(E_k)\leq\frac{\alpha}{k}$.  
	\end{proof}
	
	Then put $\s(D)\in G(q,D,\epsilon_q)\cap\c(D)$ for $D\in E_i$, and $\s(D)\in \c(D)$ for $D\notin\bigcup_{i=1,\ldots,k} E_i$. 
	
	Observe that $\s(D)$ picks for $\c$ by definition. 
	
	Take any $p\in\Prob$. 
	As $U_{q_1},\ldots, U_{q_n}$ cover $\Prob$, there is some $i$ such that $p\in U_{q_i}$. 
	
	We will show that for any $D\in E_i$, $\s(D)\notin\EU_p(D)$. This will use the following sublemma:
		\begin{sublemma}
		Suppose $p\in U_q$. If $b\in G(q,D,\epsilon_q)$ then $b\notin\EU_p(D)$.
	\end{sublemma}
	\begin{proof} As $b\in G(q,D,\epsilon_q)$,  $t_q(D)>\Exp_q[\U(b)]+\epsilon_q$, where $t_q(D)=\sup_{a \in D}\Exp_q[\U(a)]$. Take $a^*\in \EU_q(D)$ so that $\Exp_q[\U(a^*)]=t_q(D)$ so that $\Exp_q[\U(a^*)]-\Exp_q[\U(b)]\geq \epsilon_q$. 
		
		As  $p\in U_q$, we have $\|q-p\|_1<\frac{\epsilon_q}{4M}$.
		
		So	
		\begin{align}
			\Exp_p[\U(a^*)]-\Exp_p[\U(b)]&=\left(\Exp_q[\U(a^*)]-\Exp_q[\U(b)]\right)+(p-q)\cdot(\U(a^*)-\U(b))\\
			&\geq \epsilon_q -|(p-q)\cdot(\U(a^*)-\U(b))|\\
			&\geq \epsilon_q -\|p-q\|_1\|\U(a^*)-\U(b)\|_\infty&&\text{H\"older's indequality}\\
			&\geq  \epsilon_q -\frac{\epsilon_q}{4M}\times 2M=\epsilon_q -\nicefrac{\epsilon_q}{2}=\nicefrac{\epsilon_q}{2}>0
		\end{align}
		This shows that $b\notin\EU_p(D)$. 
	\end{proof}
	Since we have chosen $\s(D)\in G(q_i,D,\epsilon_{q_i})$ for $D\in E_i$, we have $\{D\given \s(D)\notin\EU_p(D)\}\supseteq E_i$, and thus, $\mu^*\{D\given \s(D)\notin\EU_p(D)\}>0$. 
\end{proof}

\end{comment}






















\begin{colored}{red}
	\subsection{Theorems}

\Cref{thm:max-nu,thm:max-nu-reg-nec,thm:gamma-nu}
\begin{proposition}[\cref{thm:max-nu}]Suppose $\Nu$ is $\EU$-complete. Suppose that 
	$\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$ and $\mu^*$ requires almost everywhere decisiveness.
	Then if $\n \in \Maximality_\IB(\Nu)$, then there is some probability $p$ such that $\n$ $\mu^*$-surely picks for $\EU_p$.%\todo{did we know that $p$ in $\IP$??}
	\todoold{I removed the converse because I don't know if the probability has to be in the original set, not sure if that follows from the Wald..???}
\end{proposition}


\begin{proposition}[\cref{thm:max-nu-reg-nec}]
	Suppose $\Nu$ is $\EU$-complete. 
	Suppose that $\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$ and $\mu^*$ requires almost everywhere decisiveness. Suppose that for every probability $p$, $\mu^*\{D\given \Maximality_\IP(D)\subseteq\EU_p(D)\}< 1$.\footnote{Equivalently, that for every probability $p$ there is a non-negligible set of decision problems for which there is some $a\in D$ which is not an $\EU_p$ act but which is Maximal: $\mu^*\{D\given \exists a\in D\left[(\exists b{\in} D \, \Exp_{p}(a)<\Exp_{p}(b))\text{ and }\forall b{\in} D\, \exists p'{\in}\IP \,\Exp_{p'}(b)\leq \Exp_{p'}(a)\right]\}>0$} %\todo{this might actaully need to say every p rather than every p in P, no??? It's supposed to say, it's not an EU strategy, so that we can use the fact that it does not mu surely pick for any EUp???!!!}
	Then, if $\n$ is a regular picking strategy for $\Maximality$ then $\n\notin \Maximality_\IB(\Nu)$.\todo{do we also state that there is a strategy ruled out? Is it affected by our issues with EAd?}
\end{proposition}


\begin{proof}
	content...
\end{proof}
\end{colored}







%%	thm:chiocefns-nu-reg-nec,thm:gamma}
%	 follow from this, making use of \cref{thm:EU-appendix}.
%	 
%{\color{violet}	
%	 \begin{proof}[Proof illustration]
%	 	If $\n$ does not $\mu^*$-surely pick for any probability $p$, then it is not a maximiser of $\Exp_p[\Uwald(\n)]=\Exp_p[\Exp_{\mu^*}\U(\n)]=\Exp_{p\times\mu^*}[\U(\n)]$ for any $p$; i.e., it is not Bayes.
%	 	
%	 	It is thus is dominated, i.e., there is $\n'$ with $\Uwald(\n')(\omega)>\Uwald(\n)(\omega)$ for all $\omega$; i.e., $\Exp_{\mu^*}\U(\n')(\omega)>\Exp_{\mu^*}\U(\n)(\omega)$ for all $\omega$; and thus, $\Exp_{p}\Exp_{\mu^*}[\U(\n')]>\Exp_p\Exp_{\mu^*}[\U(\n)]$ for all probabilities $p$. 
%	 \end{proof}
%}
\todooldinfo{If we're rewriting the EU result, check how this looks!}




\newpage
\color{red}
\section{E-Ad thm}



\subsection{CCM}


%\begin{theorem}
%Suppose $\IB=\IP\times\{\mu^*\}$ and for $p\neq q$, $\mu^*\{D\given \EU_p(D)\cap\EU_q(D)=\emptyset\}=1$. 
%
%Lets assume that we have some two $E_1,E_2$ disjoint subsets of $\Decs$ which both have $\mu^*$ positive measure. 
%
%Define:
%\begin{itemize}
%	\item $A_p(D)=\EAd_\IP(D)\setminus \EU_p(D)$
%	\item $B_p=\{D\given A_p(D)\neq \emptyset\}$
%\end{itemize}
%
%If $\mu^*(B_p)>0$ for all $p\in\IP$ then there is $\s$ which picks for $\EAd_\IP$ but is not $\mu^*$-surely $\EU_p$.
%\end{theorem}
%\begin{proof}
%	Consider two members, $p_1,p_2$ from $\IP$. 
%	
%	And take disjoint subsets $E_1,E_2$ of $\Decs$ with $\mu^*(E_i)>0$. 
%	
%	Put $\s(D)\in\EU_{p_1}(D)$ for $D\in E_1$ and  $\s(D)\in\EU_{p_2}(D)$ for $D\in E_2$; and $\s(D)$ can be any member of $\EAd_\IP(D)$ for $D\notin\{E_1,E_2\}$. So $\s$ picks for $\EAd_\IP$.
%	
%	For any $p\in\IP$, take $i$ st $p\neq p_i$. For $D\in E_i$, $\s(D)\in\EU_{p_i}(D)$. So by zero agreement, $\s(D)\notin\EU_p(D)$, at least $\mu^*$-surely.
%	
%	So $\mu^*\{D\given \s(D)\notin\EU_p(D)\}\geq \mu(E_i)>0$. 
%	
%	Thus, $\mu^*\{D\given \s(D)\notin \EU_{p}(D)\}\geq \mu^*(E_n)>0$. Thus $\s$ does not $\mu$-surely pick for $\EU_{p}$. 
%	
%	
%	
%\end{proof}

\begin{theorem}[CCM]\label{thm:ead-existsimpermissible[indep]:CCM-1}
	Completely independent. 
	
	Suppose $\{p_i\given i\in I\}\subseteq \IP$ and we have disjoint $E_i\subseteq\Decs$ such that for all $(p,\mu)\in\IB$, there is some $i\in I$ with
	 $\mu\{D\in E_i\given \EU_{p_i}(D)\cap \EU_p(D)= \emptyset\}>0$.
	
	Then there is $\s$ which picks for $\EAd_\IP$ but there is no $p\times\mu\in \IB$ such that $\s$ $\mu$-surely pick for $\EU_p$.
\end{theorem}
\begin{proof}
	
	Put $\s(D)\in\EU_{p_i}(D)$ for $D\in E_i$. For $D\notin\bigcup_{i\in I}E_i$, put $\s(D)$ anything in $\EAd_\IP(D)$.  So $\s$ picks for $\EAd_\IP$. 
	
	Take any $p\times\mu\in\IB$. For at least one of $i\in I$, 	 $\mu\{D\in E_i\given \EU_{p_i}(D)\cap \EU_p(D)= \emptyset\}>0$. Thus
	 \begin{equation}
		\mu\{D\in E_i\given \s(D)\notin\EU_p(D)\}\geq\mu\{D\in E_i\given \EU_{p_i}(D)\cap \EU_p(D)= \emptyset\}>0
	\end{equation}
	Thus $\s$ does not $\mu$-surely pick for $\EU_p$.
\end{proof}
This can be verified in many examples. 

\begin{example}
	Consider the example from \cref{eg:coord}, putting $E_1=\{D^{\mathrm{coord}}_1\}$ and $E_2=\{D^{\mathrm{coord}}_2\}$. 
	
	If $p=0.5$ were added to $\IP$ then it would fail, because then $\EU_{.5}(D)=D$ for both these $D$. It would rationalise any picking strategy. 
	
	Adding any $p\neq 0.5$ to $\IP$ would still satisfy it: just take some $p_1>0.5$ and $p_2<0.5$. Each $p$ assigns positive measure to its choice set disagreeing with either $p_1$s or $p_2$s. 
\end{example}
\begin{example}
	If $p_1,p_2,p_3\in\IP$ and $\mu_1(D_1)=1$, etc, where:
	\begin{itemize}
		\item $D_1$ is such that $\EU_{p_1}(D_1)\cap\EU_{p_2}(D_1)\neq \emptyset$ but $\EU_{p_1}(D_1)\cap\EU_{p_3}(D_1)= \emptyset$
		\item $D_2$ is such that $\EU_{p_2}(D_2)\cap\EU_{p_3}(D_2)\neq \emptyset$ but $\EU_{p_2}(D_2)\cap\EU_{p_1}(D_2)= \emptyset$
		\item $D_3$ is such that $\EU_{p_3}(D_3)\cap\EU_{p_1}(D_3)\neq \emptyset$ but $\EU_{p_3}(D_3)\cap\EU_{p_2}(D_3)= \emptyset$
	\end{itemize}then this is an example where we cannot find an example with just $|I|=2$ but we can with $|I|=3$, at least so long as the other $(p,\mu)\in\IP$ have positive measure to disagreeing with one of these $p_1,p_2,p_3$. 
\end{example}
It could also be extended to allow for proper distributions by allowing each $\mu$ having some $J\subseteq I$ st:  $\mu(\bigcup_{j\in J}\{D\in E_j\given \EU_{p_j}(D)\cap \EU_p(D)= \emptyset\})>0$.



%Measurability? ChatGPT says: ``Kuratowski–Ryll–Nardzewski to choose measurable selectors on each slice.''???


Question: how does it relate to ``it does not look like an EU picking''?

%		Perhaps by allowing the randomised strategies we can remove the zero ties thing? 
%			
%	\begin{theorem}
	%		Suppose we allow any randomised picking strategies. 
	%		
	%					Suppose $\IB$ is a set of $p\times \mu$ containing distinct $p_1,p_2$. 
	%					Assume that there is some $E\subseteq\Decs$ such that for all $p\times\mu\in\IB$, $0<\mu(E)<1$. 
	%		
	%				Then there is $\n$ which picks for $\EAd_\IP$ but there is no $p\times\mu\in \IB$ such that $\n$ $\mu$-surely pick for $\EU_p$.
	%	\end{theorem}
%	\begin{proof}
	%		content...
	%	\end{proof}

\begin{corollary}
	Suppose that for every $(p,\mu)\in\IB$, and $q\neq p$ $\mu\{D\given \EU_p(D)\cap \EU_q(D)=\emptyset\}=1$. And suppose that there is $E\subseteq\Decs$ st every $\mu$ has $0<\mu(E)<1$.
\end{corollary}
\begin{proof}
	Take such an $E$ and put $E_1=E$ and $E_2=\Decs\setminus E$, so that these are disjoint and $\mu(E_i)>0$ for all $\mu$. 
	
	Take any distinct $p_1,p_2\in\IP$.  Then every $p\in\IP$ is distinct from at least one of $p_1$ or $p_2$. Suppose $p$ is distinct from $p_i$. Then $\mu\{D\given \EU_p(D)\cap \EU_{p_i}(D)=\emptyset\}=1$. Thus $\mu\{D\in E_i\given\EU_p(D)\cap \EU_{p_i}(D)=\emptyset\}=\mu(E_i)>0$. 
	
	This gives us the assumptions of \cref{thm:ead-existsimpermissible[indep]:CCM-1} clearly follow. 
\end{proof}


We can show this is satisfied given some other assumptions:

\begin{corollary}[CCM version of \cref{thm:ead-existsimpermissible[indep]:RP-1}]\label{thm:ead-existsimpermissible[indep]:CCM-1:nondegentakeleave}
	Completely independent. 
	
	Assume there are $l<0<h$ such that for all $g\in[l,h]^\Omega$, there is some $a\in\A$ such that $\U(a)=g$. 
	
	Suppose $\IP$ is non-singleton and for every $(p,\mu)\in\IB$, for every $U$ open non-empty $\subseteq\A$, $\mu$ assigns strictly positive measure to $\{\{a,0\}\given a\in U\}$.
	
	Then there is $\s$ which picks for $\EAd_\IP$ but there is no $p\times\mu\in \IB$ such that $\s$ $\mu$-surely pick for $\EU_p$.
\end{corollary}
\begin{proof}
	
	Suppose $V_1$ and $V_2$ are disjoint non-empty subsets of $[l,h]^\Omega$ and for all $g\in \Re^\Omega$ there is some $\lambda_1$ such that $\lambda_1 g\in V_1$ and $\lambda_2>0$ such that $\lambda_2 g\in V_2$. 
	For example, we could put  $V_1:=\{g\in[l,h]^n\given \|g\|<0.5\}$ and $V_2:=\{g\in[l,h]^n\given \|g\|>0.5\}$ (assuming that $l<-0.5<0.5<h$). 
	
	Take any distinct $p^*_1,p^*_2\in \IP$.
	
	Suppose $p$ is distinct from $p^*_i$. 
	There is some $g\in\Re^\Omega$ such that $\Exp_p[g]>0>\Exp_{p^*_i}[g]$. 
	By assumption on $V_i$, there is some $\lambda >0$ with $\lambda g\in V_i$. Also $\Exp_p[\lambda g]>0>\Exp_{p^*_i}[\lambda g]$. 
	
	So $\{g\in V_i\given \Exp_p[g]>0>\Exp_{p^*_i}[g]\}\neq \emptyset$. 
	
	It is also an open subset of $\Re^\Omega$, as expectation is continuous. 
	
	So, for every $(p,\mu)\in\IB$, $\mu\{\{a,0\}\given \U(a)\in\{g\in V_i\given \Exp_p[g]>0>\Exp_{p^*_i}[g]\} \}>0$
	
	
	\begin{colored}{red}
		
	
	
	
	
	

	WLOG suppose $l<-1$ and $u>1$.  Otherwise work with transformed utilities ($+$ and $\times$). 
	So that by our assumption on $\A$, for any $g\in[-1,1]^\Omega$, there is some $a\in \A$ such that $\U(a)=g$. 
	
	Let $V_1:=\{g\in[-1,1]^n\given \|g\|<0.5\}$ and $V_2:=\{g\in[-1,1]^n\given \|g\|>0.5\}$. 
	
	Put $E_1:=\{\{a,0\}\given \U(a)\in V_1\}$ and $E_2:=\{\{a,0\}\given \U(a) \in V_2\}$. 
	
	
	Let \begin{equation}
		\mathrm{Disagree}(p,q):=
		\begin{split}&
		\{g\in\Re^\Omega\given \Exp_p[g]>0\text{ and }\Exp_q[g]<0\}\\
		&\cup\{g\in\Re^\Omega\given \Exp_p[g]<0\text{ and }\Exp_q[g]>0\}.
	\end{split}
	\end{equation}
	Note that it is open. 
	
	Also, if $g\in \mathrm{Disagree}(p,q)$ then $\lambda g\in\mathrm{Disagree}(p,q)$.	
	
	Also observe that $\EU_{q}(\{a,0\})\cap \EU_{p}(\{a,0\})=\emptyset$ iff $\U(a)\in \mathrm{Disagree}(p,q)$.
	
	Now take any $p_1,p_2$ distinct in $\IP$. We will show that for any $q\in\IP$, for at least one of $p_1$ or $p_2$, $\mu \{D\in E_i\given \EU_{p_i}(D)\cap \EU_p(D)= \emptyset\}>0$, as required for \cref{thm:ead-existsimpermissible[indep]:CCM-1}. 
	
	Note that $\{\{a,0\}\given \U(a)\in V_i\cap \mathrm{Disagree}(p_i,q)\}\subseteq \{D\in E_i\given \EU_{p_i}(D)\cap \EU_p(D)= \emptyset\}$. 
	And observe that $\{\{a,0\}\given \U(a)\in V_i\cap \mathrm{Disagree}(p_i,q)\}$ is open. So, by our assumption on $\mu$, it suffices to show that it is non-empty. 
	
	For $q\neq p_1$, construct $g^*\in \mathrm{Disagree}(p_1,q)$. To do this, take $\omega^*$ such that $q(\omega^*)\neq p_1(\omega^*)$. 
	Let $r=\frac{q(\omega^*)+p_i(\omega^*)}{2}>0$ and consider the Dutch-book-style bet $g^*(\omega)=\begin{cases}
		1-r&\omega=\omega^*\\
		-r&\omega\neq \omega^*
	\end{cases}$
	
	By choosing $\lambda$ appropriately, we can ensure that $\|\lambda g^*\|<0.5$, thus that $\lambda g^*\in V_1$. So $V_1\cap \mathrm{Disagree}(p_1,q)\neq\emptyset$. 
	By our assumption on $\A$, also there exists $a^*\in\A$ with $\U(a^*)=\lambda g^*$. 
	So we have our required non-emptyness of $\{\{a,0\}\given \U(a)\in V_1\cap \mathrm{Disagree}(p_1,q)\}$.
	
	For $q=p_1$, it is distinct from $p_2$, so using an analogous argument we can find a member of $V_2\cap \mathrm{Disagree}(p_2,q)$ and then observe it corresponds to some member of $\A$. 
	
	We can then apply \cref{thm:ead-existsimpermissible[indep]:CCM-1}.
	\end{colored}
\end{proof}

This is perhaps slightly odd $\mu$, in general they'll assign 0-measure to these take-it-or-leave it decisions. They are not open subsets of $\Decs$ and are of lower dimension. We can instead do it for full support $\mu$. 

\begin{corollary}Completely independent. 
	
	Assume $\U(\A)=[l,h]^\Omega$. In particular, for every $g\in [l,h]^\Omega$ there is some $a\in \A$ with $\U(a)=g$. 
	
	Suppose $\IP$ contains distinct $p_1,p_2$ and for every $(p,\mu)\in\IB$, $\mu$ has full support on $\Decs$ (assigning strictly positive measure to every non-empty open subset of $\Decs$).
	
	Then there is $\s$ which picks for $\EAd_\IP$ but there is no $p\times\mu\in \IB$ such that $\s$ $\mu$-surely pick for $\EU_p$.
	
	Suppose $\IB$ contains distinct $b_1,b_2$ any for all $b\in\IB$, $b_\Decs$ assigns strictly positive measure to every non-empty subset of $\Decs$. 
\end{corollary}
\begin{proof}
	
	\begin{sublemma}
	Let $E$ be of the form $\{D\in\D\given D\subseteq V\}$ where $V$ is an open subset of $[l,h]^\Omega$.
				
		For distinct $q_1,q_2$, 
		$\{D\in E\given \EU_{q_1}(D)\cap \EU_{q_2}(D)=\emptyset\}$ is open and non-empty $\subseteq\Decs$.
	\end{sublemma}
	\begin{proof}
		
%		It is open: As $E$ is open, we just need to show that $\{D\given \EU_{q_1}(D)\cap \EU_{q_2}(D)=\emptyset\}$ is open. 
%		Since $q_1\neq {q_2}$ there are $a_1,a_2\in\A$ such that $\Exp_{q_1}[\U(a_1)]>\Exp_{q_1}[\U(a_2)]$ and $\Exp_{q_2}[\U(a_1)]<\Exp_{q_2}[\U(a_2)]$. For example, use a construction like in \cref{thm:ead-existsimpermissible[indep]:CCM-1:nondegentakeleave}. 
%		As $\Exp$ is continuous, we can also find open $U_1\ni a_1$ and $U_2\ni a_2$ with the same inequality of expectations. 
%		So $\{D\given D\cap U_1=\emptyset\text{ and }D\cap U_2=\emptyset\}$ is open and it is a subset of $\{D\given \EU_{q_1}(D)\cap \EU_{q_2}(D)=\emptyset\}$.
%		
	
	
	\textbf{It is nonempty:}
	
	Take any $D_0\in E$. If $\EU_{q_1}(D_0)\cap \EU_{q_2}(D_0)=\emptyset$ this suffices. 
	
	Otherwise there is some $a_0\in \EU_{q_1}(D_0)\cap \EU_{q_2}(D_0)$. 
	
	As in \cref{thm:ead-existsimpermissible[indep]:CCM-1:nondegentakeleave}, we can find some $g^*$ such that $\Exp_{q_1}[g^*]>0>\Exp_{q_2}[g^*]$, and, moreover, can choose a scalar small enough so that $\U(a_0)+\lambda g^*\in[l,h]^n$ and thus that $a_0+\lambda g^*\in\A$ (abusing notation). 
	
	So $\Exp_{q_1}[\U(a_0+\lambda g^*)]>\Exp_{q_1}[\U(a_0)]$ and $\Exp_{q_2}[\U(a_0+\lambda g^*)]<\Exp_{q_2}[\U(a_0)]$.
	
	Consider $D^*=D_0\cup\{a_0+\lambda g^*\}$, recalling that $a_0\in D_0$. 
	
	Observe that $\EU_{q_1}(D^*)=\{a_0+\lambda g^*\}$ but that $a_0+\lambda g^*\notin\EU_{q_2}(D^*)$ as it finds $a_0$ preferable. 
	Thus $\EU_{q_1}(D^*)\cap \EU_{q_2}(D^*)=\emptyset$.
	
	As $\U(a_0)+\lambda g^*\in V$ by choice of $\lambda$, $D^*\subseteq V$, so $D^*\in E$, as required. 
	
		\textbf{It is open:}
		
		Take any $D_0\in E$ with $\EU_{q_1}(D_0)\cap \EU_{q_2}(D_0)=\emptyset$. 
		
				Let $t_1=\max_{a\in D_0}\Exp_{q_1}[\U(a)]$ and $t_2=\max_{a\in D_0}\Exp_{q_2}[\U(a)]$.
				
				As  $\EU_{q_1}(D_0)\cap \EU_{q_2}(D_0)=\emptyset$, for all $a\in D_0$, either $t_1>\Exp_{q_1}(a)$ or  $t_2>\Exp_{q_2}(a)$. Thus $f(a):=\max\{t_1-\Exp_{q_1}[\U(a)],t_2-\Exp_{q_2}[\U(a)]\}>0$ for all $a\in D_0$. As $D_0$ is finite, put $\delta=\min_{a\in D_0}f(a)>0$. So that for all $a\in D_0$, either  $\Exp_{q_1}[\U(a)]\leq t_1-\delta$ or $\Exp_{q_2}[\U(a)]\leq t_2-\delta$
		
		Put $\epsilon=\nicefrac{\delta}{2}$. Suppose $d(D_0,D)<\epsilon$. That is, for all $a\in D_0$ there is some $c\in D$ such that $d(a,c)<\epsilon$ and for all $c\in D$ there is some $a\in D_0$ with $d(a,c)<\epsilon$. 
		
		Take any $a_1\in \EU_{q_1}(D_0)$, so $\Exp_{q_1}[\U(a_1)]=t_1$. There is some $c_1\in D$ such that $d(a_1,c_1)<\epsilon$, and thus $\Exp_{q_1}[\U(c_1)]>t_1-\epsilon$. Thus, $\max_{c\in D}\Exp_{q_1}[\U(c)]>t_1-\epsilon$, and so if $c\in \EU_{q_1}(D)$, then $\Exp_{q_1}[\U(c)]>t_1-\epsilon$. 
		
		
		By an analogous argument, if $c\in \EU_{q_2}(D)$ then $\Exp_{q_2}[\U(c)]>t_2-\epsilon$. 
		
		For any $c\in D$, there is some $a_c\in D_0$ such that $d(c,a_c)<\epsilon$. If, also,  $c\in \EU_{q_1}(D)\cap\EU_{q_2}(D)$ then 
		\begin{align}
			&\Exp_{q_1}[\U(a_c)]>\Exp_{q_1}[\U(c)]-\epsilon>t_1-2\epsilon\\
			\text{and }&\Exp_{q_2}[\U(a_c)]>\Exp_{q_2}[\U(c)]-\epsilon>t_2-2\epsilon
		\end{align}
		This is not possible by choice of $\epsilon=\nicefrac{\delta}{2}$. 		
%	
%	
%	
%		
%		\textbf{It is open:} 
%		As $E$ is open, we just need to show that $\{D\given \EU_{q_1}(D)\cap \EU_{q_2}(D)=\emptyset\}$ is open.
%		
%		The complement is $$\{D\given \EU_{q_1}(D)\cap \EU_{q_2}(D)\neq \emptyset\}=\bigcup_{a\in \A}\{D\given a\in \EU_{q_1}(D)\text{ and } a\in\EU_{q_2}(D)\}$$
%		
%		For each fixed $a\in \A$, $\{b\given \Exp_q[\U(b)]\leq\Exp_q[\U(a)]\}$ is closed $\subseteq\A$. So $$\{D\given D\subseteq \{b\given \Exp_q[\U(b)]\leq\Exp_q[\U(a)]\}\}$$ is closed in $\Decs$. $\{D\given a\in\EU_q(D)\}$ is the intersection of this with the closed set $\{D\given a\in D\}$. 
%		
%		So $\{D\given \EU_{q_1}(D)\cap \EU_{q_2}(D)\neq \emptyset\}$ is an intersection of closed sets and thus is closed. 
%		
		 \end{proof}
		 
		 	Let $V_1,V_2$ be any disjoint non-empty open subsets of $[l,h]^\Omega$. Let $E_i:=\{D\in\D\given D\subseteq V_i\}$. 
		 	
	Take any $p_1,p_2$ distinct members of $\IP$. 
	
	For any 
	
	 \cref{thm:ead-existsimpermissible[indep]:CCM-1}.	
\end{proof}



\begin{theorem}[CCM]\label{thm:ead-existsimpermissible[indep]:reg}
	Completely independent. 
	
	Suppose that for every $p\times \mu\in \IB$, $\mu\{D\given \EAd_\IP(D)\subseteq \EU_p(D)\}\neq 1$. That is, for all $p\times \mu\in \IB$, $\mu\{D\given \text{there is $p'\in\IP$ with }\EU_{p'}(D)\not\subseteq\EU_p(D)\}>0$. 
	
	If $\nu$ is a regular picking strategy for $\EAd_\IP$, then there is no $p\times\mu\in \IB$ such that $\nu$ $\mu$-surely pick for $\EU_p$.
\end{theorem}
\begin{proof}
	Suppose $\nu$ is a regular picking strategy for $\EAd_\IP$. 
	
	For $p\times\mu\in\IB$, if $\EAd_\IP(D)\not\subseteq \EU_p(D)$, then $\nu(\EU_p(D))\neq 1$, by regularity. As 
	$\mu\{D\given \EAd_\IP(D)\not\subseteq \EU_p(D)\}>0$, then $\mu\{D\given \nu(\EU_p(D))<1\}>0$. So $\nu$ does not $\mu$-surely pick for $\EU_p$.  
\end{proof}
\subsection{JK}







\begin{proposition}[JK]\label{thm:ead-existsimpermissible[indep]:JK-1}

Suppose $\D$ and $\Omega$ are completely independent in $\IB$ (so that every $b\in\IB$ has the form $p\times\mu_p$).
	
	Then, $\s\in\EAd_\IB(\Strategies)$ iff there is some $p\times \mu_p\in\IB$ such that $\s$ $\mu_p$-surely picks for $\EU_p$. 
	
	
	
If there is a partition $\X$ of $\IP$ and a family $\left\{ B_x \given x\in\X\right\}$ of mutually disjoint $B_x\subseteq\Decs$ satisfying
\begin{enumerate}
\item $(\forall D\in B_x)\EAd_\IP(D)\setminus\EAd_x(D)\not=\varnothing$
\item $(\forall p\in x)\mu_p(B_x)>0$
\end{enumerate}
then there is some $\s$ that picks for $\EAd_\IP$ but which is not in $\EAd_\IB(\Strategies)$.

\end{proposition}
\begin{proof}

For any $x\in\X$ and any $D\in B_x$, let $\s(D)$ be any element of $\EAd_\IP(D)\setminus\EAd_x(D)$. For any $D\in\Decs\setminus\left(\cup_{x\in\X}B_x\right)$, let $\s(D)$ be any element of $\EAd_\IP(D)$.

By construction $\s$ picks for $\EAd_\IP$. And for any $p\times \mu_p\in\IB$, $\s$ does not $\mu_p$-surely pick for $\EU_p$ since (1) $p\in x$ for some $x\in \X$, (2) $\mu_p(B_x)>0$, and (3) for any $p'\in x$, $\s$ does not pick for $\EU_{p'}$ on $B_x$. Hence $\s\not\in\EAd_\IB(\Strategies)$.

\end{proof}



\begin{proposition}
	Suppose $\Nu$ is $\EU$-complete. 
	Suppose that $\IB$ has the form $\{p\times \mu^*\given p\in \IP\}$ and $\mu^*$ requires almost everywhere decisiveness. Suppose that for every probability $p$, $\mu^*\{D\given \Maximality_\IP(D)\subseteq\EU_p(D)\}< 1$.\footnote{Equivalently, that for every probability $p$ there is a non-negligible set of decision problems for which there is some $a\in D$ which is not an $\EU_p$ act but which is Maximal: $\mu^*\{D\given \exists a\in D\left[(\exists b{\in} D \, \Exp_{p}(a)<\Exp_{p}(b))\text{ and }\forall b{\in} D\, \exists p'{\in}\IP \,\Exp_{p'}(b)\leq \Exp_{p'}(a)\right]\}>0$} %\todo{this might actaully need to say every p rather than every p in P, no??? It's supposed to say, it's not an EU strategy, so that we can use the fact that it does not mu surely pick for any EUp???!!!}
	Then, if $\n$ is a regular picking strategy for $\Maximality$ then $\n\notin \Maximality_\IB(\Nu)$.%\todo{do we also state that there is a strategy ruled out? Is it affected by our issues with EAd?}
\end{proposition}


\begin{proof}



\end{proof}



\textit{Example}. 

\begin{itemize}
\item $\Omega=\left\{ H, T\right\}$

\item $\IP=\left\{ \left<t, 1-t\right>\given 0\leq t\leq 1\right\}$

\item $\mu= \left<1/2,1/2\right>$


\item $\IB=\IP\times\{\mu\}$
\end{itemize}

$$
\begin{array}{r|cc}
D_1 & \emph{H} &\emph{T} \\\hline 
\text{A} & \text{\pounds 5} & -\text{\pounds 10}  \\
0 & \text{\pounds0} & \text{\pounds 0}  \\
\end{array}
\hspace{10mm}
\begin{array}{r|cc}
D_2 & \emph{H} &\emph{T} \\\hline 
\text{B} & -\text{\pounds 10} & \text{\pounds 5}  \\
0 & \text{\pounds0} & \text{\pounds 0}  \\
\end{array}
$$

\begin{itemize}
\item $\Decs=\left\{ D_1, D_2 \right\}$

\item $x_1=\left\{ \left<t, 1-t\right>\given 0\leq t< 2/3\right\}$
\item $x_2=\left\{ \left<t, 1-t\right>\given 2/3\leq t\leq 1\right\}$

\item $B_{x_1}=\left\{ D_1\right\}$
\item $B_{x_2}=\left\{ D_2\right\}$

\item $\EAd_\IP(D_1)\setminus\EAd_{x_1}(D_1)=D_1\setminus\left\{0\right\}=\left\{A\right\}$

\item $\EAd_\IP(D_2)\setminus\EAd_{x_2}(D_2)=D_2\setminus\left\{0\right\}=\left\{B\right\}$

\item $\s(D_1)=A$, $\s(D_2)=B$
\end{itemize}
\section{RP's version}

\begin{proposition}[RP]\label{thm:ead-existsimpermissible[indep]:RP-1}
	
	Suppose $\D$ and $\Omega$ are completely independent in $\IB$ (so that every $b\in\IB$ has the form $p\times\mu$).
	
	Suppose EVERY? $\mu$ assigns strictly positive measure to every $\{\{a,0\}\given a\in U\}$ for $U$ non-empty open subset of $\A$, and ASSUMPTIONS ABOUT $\A$. 
	
	If $\IP$ is not precise, there is some $\s$ that picks for $\EAd_\IP$ but which is not in $\EAd_\IB(\Strategies)$.
\end{proposition}
\begin{proof}
	Suppose $\Omega = \{\omega_1, \ldots, \omega_n\}$. Suppose $a \in [l, h]^n$. Then write $\overline{a}$ for the act such that $\U(\overline{a}, \omega_i) = a_i$, for each $i$, and write $\overline{0}$ for the act such that $\U(\overline{0}, \omega_i) = 0$, for all $i$. Given $a \in [l, h]^n$ and $\varepsilon > 0$, let $B_\varepsilon(a)$ be the ball with centre $a$ and radius $\varepsilon$.
	
	If $\IP$ is not precise, there are $p, q$ in $\IP$ such that $p \neq q$. Then there is $a^\star$ and $\varepsilon$ such that $B_\varepsilon(a^\star) \subseteq [l, h]^n$ and, for all $a$ in $B_\varepsilon(a^\star)$, $\Exp_p[\U(\overline{a})] > 0 = \Exp_p[\U(\overline{0})]$ and $\Exp_q[\U(\overline{a})] < 0 = \Exp_q[\U(\overline{0})]$. Now, we pick a hyperplane $H$ that includes $a^\star$ and doesn't include $0$, and divide the ball $B_\varepsilon(a^\star) \subseteq [l, h]^n$ into two hemispheres $X_1$ and $X_2$ that lie either side of the hyperplane. Then we define $\s$ as follows:
	$$
	\s(\{\overline{a}, \overline{0}\}) = \left \{ 
	\begin{array}{rl}
		\overline{a} & \text{if } \overline{a} \in X_1 \\
		\overline{0} & \text{if } \overline{a} \in X_2 
	\end{array}
	\right.
	$$
	Then $\s$ picks for $\EAd_\IP$, since $p$ rationalizes its picks for $\{\overline{a}, \overline{0}\}$ with $a$ in $X_1$ and $q$ rationalizes its picks for $\{\overline{a}, \overline{0}\}$ with $a$ in $X_2$.
	
	Next, take any $r$ in $\IP$, and let $H_r = \{a \mid \Exp_r[\U(\overline{a})] = 0\}$. Then, $H \neq H_r$, since $H_r$ contains $0$ but $H$ does not. So, there is a non-null subset $Y_1$ of $X_1$ and a non-null subset $Y_2$ of $X_2$ that both lie on the same side of $H_r$. And so either $\s$ does not pick for $\EU_r$ for all $\{\overline{a}, \overline{0}\}$ with $a$ in $Y_1$, or $\s$ does not pick for $\EU_r$ for all $\{\overline{a}, \overline{0}\}$ with $a$ in $Y_2$. Either way, $\s$ does not $\mu$-surely pick for $\EU_r$. 
	
	
	
	%We wish to show that there is $a$ in $B_\varepsilon(a^\star)$ such that $\s$ does not pick for $\EU_r$ on $\{\overline{a}, \overline{0}\}$. Suppose $\s$ does pick for $\EU_r$ for all $\{\overline{a}, \overline{0}\}$ with $a$ in $B_\varepsilon(a^\star)$. Then $H_r = H$. And yet $H$ includes $0$ and $H_r$ does not, which gives a contradiction.
	
\end{proof}


\todo[inline]{CCM: OK. So this is constructing sets like in my current \cref{thm:ead-existsimpermissible[indep]:CCM-1}. I don't think RPs proof is right as it stands, as why think there's positive measure to these pairwise decs. Oh, right, that's hidden in the ``non-degenerate''! Although I'm stil not sure they quite get pos meaure. The pairwise are a lower dimensional subspace...?

I've got a different proof of this above.
}





\subsection{JK version of RP}









\begin{proposition}[{JK version of RP \cref{thm:ead-existsimpermissible[indep]:RP-1}}]\label{thm:ead-existsimpermissible[indep]:JK-2}

If $\IP$ is imprecise and convex, then there is a partition $\X$ of $\IP$ and a family $\left\{ B_x \given x\in\X\right\}$ of mutually disjoint $B_x\subseteq\Decs$ satisfying
\[
(\forall D\in B_x)\EAd_\IP(D)\setminus\EAd_x(D)\not=\varnothing.
\]

\end{proposition}




\begin{proof}
For any $f\in \mathbb{R}^n$, let 
\[
\underline{\IP}(f)=\inf\left\{E_p(f)\given p\in\IP\right\},\; \overline{\IP}(f)=\sup\left\{E_p(f)\given p\in\IP\right\}.
\]
Since $\IP$ is imprecise, there is some $g\in \mathbb{R}^n$ such that $\underline{\IP}(g)<\overline{\IP}(g)$. Since $\IP$ is convex, there is some $p\in\IP$ such that $\underline{\IP}(g)<E_p(g)<\overline{\IP}(g)$. Define 
\[
x_1=\left\{q\in\IP\given E_q(g)\leq E_p(g)\right\},\; x_2=\left\{q\in\IP\given E_q(g)>E_p(g)\right\}.
\]
Then $\X=\left\{x_1,x_2\right\}$ partitions $\IP$. For any $q\in x_1$ and $\delta>0$
\[
E_q(g-E_p(g)-\delta)=E_q(g)-E_p(g)-\delta\leq-\delta<0
\]
In particular this holds for $q=p$. And if $0<\delta<\overline{\IP}(g)-E_p(g)$ then
\begin{align}
\overline{\IP}(g-E_p(g)-\delta)&=\overline{\IP}(g)-E_p(g)-\delta\\
&>\overline{\IP}(g)-E_p(g)-(\overline{\IP}(g)-E_p(g))\\
&=0
\end{align}
Since $\IP$ is convex, $E_p(g-E_p(g)-\delta)<0$ and $\overline{\IP}(g-E_p(g)-\delta)>0$ implies that there are $r,r^\prime\in x_2$ such that 
\begin{align}
E_r(g-E_p(g)-\delta)&<0\\
E_{r^\prime}(g-E_p(g)-\delta)&>0
\end{align}
Let $\delta_1=\frac{\overline{\IP}(g)-E_p(g)}{2}$ and $h_1=g-E_p(g)-\delta_1$. Let $B_{x_1}$ be the set of binary decision problems defined by
$$
B_{x_1} = \{ \{h_1+\epsilon,0\} : -\frac{\delta_1}{2}\leq\epsilon\leq\frac{\delta_1}{2} \}.
$$
%For any $q\in x_1$ and $-\frac{\delta_1}{2}\leq\epsilon\leq\frac{\delta_1}{2}$, $E_q(h_1+\epsilon)<0$ which implies
Then
\begin{align}
(\forall D\in B_{x_1})\EAd_{x_1}(D)&=\{0\}\\
(\forall D\in B_{x_1})\EAd_{x_2}(D)&=D
\end{align}
Hence
\[
(\forall D\in B_{x_1})\EAd_\IP(D)\setminus\EAd_{x_1}(D)\not=\varnothing.
\]
Next, we construct $B_{x_2}$. For any $q\in x_2$ and $\delta>0$
\[
E_q(-g+E_p(g)-\delta)=-E_q(g)+E_p(g)-\delta<0
\]
This also holds for $q=p$. If $0<\delta<\overline{\IP}(-g)-E_p(-g)$ then
\begin{align}
\overline{\IP}(-g+E_p(g)-\delta)&=\overline{\IP}(-g)-E_p(-g)-\delta\\
&>\overline{\IP}(-g)-E_p(-g)-(\overline{\IP}(-g)-E_p(-g))\\
&=0
\end{align}
Note that $x_1=\left\{q\in\IP\given E_q(-g)\geq E_p(-g)\right\}$. Since $\IP$ is convex, $E_p(-g+E_p(g)-\delta)<0$ and $\overline{\IP}(-g+E_p(g)-\delta)>0$ implies that there are $r,r^\prime\in x_1$ such that 
\begin{align}
E_r(-g+E_p(g)-\delta)&<0\\
E_{r^\prime}(-g+E_p(g)-\delta)&>0
\end{align}
Let $\delta_2=\frac{\overline{\IP}(-g)-E_p(-g)}{2}$ and $h_2=g+E_p(g)-\delta_2$. Let $B_{x_2}$ be the set of binary decision problems defined by
$$
B_{x_2} = \{ \{h_2+\epsilon,0\} : -\frac{\delta_2}{2}\leq\epsilon\leq\frac{\delta_2}{2} \}.
$$
Then
\begin{align}
(\forall D\in B_{x_2})\EAd_{x_1}(D)&=D\\
(\forall D\in B_{x_2})\EAd_{x_2}(D)&=\{0\}
\end{align}
Hence
\[
(\forall D\in B_{x_2})\EAd_\IP(D)\setminus\EAd_{x_2}(D)\not=\varnothing.
\]




\begin{corollary}\label{thm:ead-existsimpermissible[indep]:JK-2-corollary}

If $\IP$ is imprecise and convex, then there is a partition $\X$ of $\IP$, a family $\left\{ B_x \given x\in\X\right\}$ of mutually disjoint $B_x\subseteq\Decs$, and some measure $\mu$ satisfying
\begin{enumerate}
\item $(\forall D\in B_x)\EAd_\IP(D)\setminus\EAd_x(D)\not=\varnothing$
\item $\mu(B_x)>0$
\end{enumerate}

\end{corollary}

\todo[inline]{CCM: this can't be true. measure 1 on decs where they all agree...  You've also got a positive to non-degen assumption? Yes, you need to use $\mu(B_x)>0$... }










\end{proof}






\subsection{JK Gen Suff}







\begin{theorem}[JK]\label{thm:ead-existsimpgen[indep]:JK}




Suppose $\D$ and $\Omega$ are completely independent in $\IB$ (so that every $b\in\IB$ has the form $p\times\mu_p$).
	
%	Then, $\s\in\EAd_\IB(\Strategies)$ iff there is some $p\times \mu_p\in\IB$ such that $\s$ $\mu_p$-surely picks for $\EU_p$. 
	


Suppose further that there is some $E\subseteq\Decs$ such that for all $X\in E$ there are $f_X\in\EAd_\IP(X)$ and $g_X\in X$ satisfying
\begin{enumerate}
\item $(\forall p\in\IP)(\exists E_p\subseteq E)\mu_p(E_p)>0$;
\item $(\forall F\subseteq E_p)\left[\posi(\left\{f_X-g_X\given X\in F\right\}\cup\D_p)\cap\mathbb{R}^n_{<0}=\varnothing\;\Rightarrow\;\mu_p(F)=0\right]$
\end{enumerate}
where $\posi(A)=\left\{\sum_{k=1}^m\lambda_k h_k \given m\in\mathbb{N},\;h_1,\hdots,h_m\in A,\;\lambda_1,\hdots\lambda_m>0\right\}$ for any $A\subseteq\mathbb{R}^n$, and $\D_p=\left\{h\in\mathbb{R}^n\given E_p(h)\geq0\right\}$.

Then, there is some $\s$ that picks for $\EAd_\IP$ but which is not in $\EAd_\IB(\Strategies)$

\end{theorem}
\begin{proof}

	
For any $X\in E$, let $\s(x)=f_X$. For $X\notin E$, let $\s(X)$ be anything in $\EAd_\IP(X)$.  So $\s$ picks for $\EAd_\IP$. 


	Choose any $p\times\mu_p\in\IB$. By assumption there is some $E_p\subseteq E$ such that $\mu_p(E_p)>0$ and
\[
(\forall F\subseteq E_p)\left[\posi(\left\{f_X-g_X\given X\in F\right\}\cup\D_p)\cap\mathbb{R}^n_{<0}=\varnothing\;\Rightarrow\;\mu_p(F)=0\right]
\]
Suppose for contradiction that $\s$ $\mu_p$-surely pick for $\EU_p$. Then $f_X\in\EU_p(X)$ $\mu_p$-a.e. on $E_p$, or equivalently, $f_X\in\EU_p(X)$ on $F$ for some $F\subseteq E_p$ with $\mu_p(E_p)=\mu_p(F)>0$. In that case,
\[
\posi(\left\{f_X-g_X\given X\in F\right\}\cup\D_p)\cap\mathbb{R}^n_{<0}=\varnothing
\]
since	 $E_p(f_X-g_X)\geq0$ for all $X\in F$ and $E_p(h)\geq0$ for all $h\in\D_p$. This implies $\mu_p(F)=0$ which contradicts $\mu_p(E_p)=\mu_p(F)>0$.



	
	\end{proof}





\begin{theorem}[JK]\label{thm:moregen1}

Suppose $\D$ and $\Omega$ are completely independent in $\IB$ (so that every $b\in\IB$ has the form $p\times\mu_p$).
	
	Suppose $\{p_i\given i\in I\}\subseteq \IP$ and we have disjoint $E_i\subseteq\Decs$ such that for all $(p,\mu_p)\in\IB$, there is some $i\in I$ with
	 $\mu_p\{D\in E_i\given \EU_{p_i}(D)\cap \EU_p(D)= \emptyset\}>0$.
	
	Then there is some $E\subseteq\Decs$ such that for all $X\in E$ there are $f_X\in\EAd_\IP(X)$ and $g_X\in X$ satisfying
\begin{enumerate}
\item $(\forall p\in\IP)(\exists E_p\subseteq E)\mu_p(E_p)>0$;
\item $(\forall F\subseteq E_p)\left[\posi(\left\{f_X-g_X\given X\in F\right\}\cup\D_p)\cap\mathbb{R}^n_{<0}=\varnothing\;\Rightarrow\;\mu_p(F)=0\right]$
\end{enumerate}

\end{theorem}

\begin{proof}
Let $E=\cup _{i\in I} E_i$. Choose $f_X\in\EU_{p_i}(X)$ for $X\in E_i$ and $g_X\in X\setminus\{f_X\}$. For any $p\in\IP$, let $E_p=\{X\in E_i\given \EU_{p_i}(X)\cap \EU_p(X)= \emptyset\}$. Choose $F\subseteq E_p$ and suppose that 
\[
\posi(\left\{f_X-g_X\given X\in F\right\}\cup\D_p)\cap\mathbb{R}^n_{<0}=\varnothing
\]
Since $f_X\in\EU_{p_i}(X)$ for $X\in F\subseteq E_p\subseteq E_i$, $f_X\notin \EU_p(X)$. Hence $f_X-g_X \notin \D_p$. But $\D_p$ is maximal. So $\posi(\left\{h\right\}\cup\D_p)\cap\mathbb{R}^n_{<0}\not=\varnothing$ for any $h\notin \D_p$. Hence $F=\varnothing$ which implies $\mu_p(F)=0$.



\end{proof}







\begin{theorem}[JK]\label{thm:moregen2}

Suppose $\D$ and $\Omega$ are completely independent in $\IB$ (so that every $b\in\IB$ has the form $p\times\mu_p$).
	
	Suppose there is a partition $\X$ of $\IP$ and a family $\left\{ B_x \given x\in\X\right\}$ of mutually disjoint $B_x\subseteq\Decs$ satisfying
\begin{enumerate}
\item $(\forall X\in B_x)\EAd_\IP(X)\setminus\EAd_x(X)\not=\varnothing$
\item $(\forall p\in x)\mu_p(B_x)>0$
\end{enumerate}

	
	Then there is some $E\subseteq\Decs$ such that for all $X\in E$ there are $f_X\in\EAd_\IP(X)$ and $g_X\in X$ satisfying
\begin{enumerate}
\item $(\forall p\in\IP)(\exists E_p\subseteq E)\mu_p(E_p)>0$;
\item $(\forall F\subseteq E_p)\left[\posi(\left\{f_X-g_X\given X\in F\right\}\cup\D_p)\cap\mathbb{R}^n_{<0}=\varnothing\;\Rightarrow\;\mu_p(F)=0\right]$
\end{enumerate}

\end{theorem}

\begin{proof}
Let $E=\cup _{x\in\X} B_x$. Choose $f_X\in\EAd_\IP(X)\setminus\EAd_x(X)$ for any $x\in\X$ and $X\in B_x$, and $g_X\in X\setminus\{f_X\}$. For any $p\in\IP$, let $E_p=B_x$, where $x$ is the unique element of $\X$ with $p\in x$. Choose $F\subseteq E_p$ and suppose that 
\[
\posi(\left\{f_X-g_X\given X\in F\right\}\cup\D_p)\cap\mathbb{R}^n_{<0}=\varnothing
\]
Since $f_X\notin\EAd_x(X)$ for $X\in F\subseteq E_p=B_x$, $f_X\notin \EU_p(X)$. Hence $f_X-g_X \notin \D_p$. But $\D_p$ is maximal. So $\posi(\left\{h\right\}\cup\D_p)\cap\mathbb{R}^n_{<0}\not=\varnothing$ for any $h\notin \D_p$. Hence $F=\varnothing$ which implies $\mu_p(F)=0$.



\end{proof}








\end{document}
\subsection{An example}
We can construct an example to illustrate our result using the Ellsberg paradox. 

\begin{quote}
	An urn contains 90 balls. You know that 30 of them are red, and the remaining 60 are black and yellow, but you don’t know how many are black and how many are yellow. I am about to draw a ball from the urn.
\end{quote}
And so, if the states of the world are \emph{Red}, \emph{Black}, \emph{Yellow}, you might naturally take your credal set to be $\IP = \Set{p \given p(\emph{Red}) = \sfrac{1}{3}\ \&\ p(\emph{Black})+p(\emph{Yellow}) = \sfrac{2}{3}}$.
Now consider the following two possible decision problems, $D^{\mathrm{Ellsberg}}_1$ and $D^{\mathrm{Ellsberg}}_2$:
$$
\begin{array}{r|ccc}
D^{\mathrm{Ellsberg}}_1 & \emph{Red} & \emph{Black} &\emph{Yellow} \Bstrut \\\hline \Tstrut\IP & \sfrac{1}{3} & \multicolumn{2}{c}{\sfrac{2}{3}}\Bstrut \\\hline \hline\Tstrut 
\text{1A} & \text{\pounds 10} & \text{\pounds 0}  & \text{\pounds 0} \\
\text{1B} & \text{\pounds 1} & \text{\pounds 11}  & \text{\pounds 1} 
\end{array}
\hspace{10mm}
\begin{array}{r|ccc}
D^{\mathrm{Ellsberg}}_2 & \emph{Red} & \emph{Black} &\emph{Yellow} \Bstrut \\\hline \Tstrut\IP & \sfrac{1}{3} & \multicolumn{2}{c}{\sfrac{2}{3}}\Bstrut \\\hline \hline\Tstrut 
\text{2A} & \text{\pounds 11} & \text{\pounds 1}  & \text{\pounds 11} \\
\text{2B} & \text{\pounds 0} & \text{\pounds 10}  & \text{\pounds 10} 
\end{array}
$$
Faced with these decisions, people often give the Ellsberg preferences: $\text{1A} \succ \text{1B}$ and $\text{2B} \succ \text{2A}$.\footnote{In fact, we have added a small constant to the usual versions of 1B and 2A, reflecting the fact that people strictly prefer the usual version of 1A over the usual version of 1B, and so are willing to pay a penalty for making that choice; we've taken that penalty to be \pounds 1.}


We can then calculate which acts maximize expected utility by the lights of a probability function in $\IP$ (\cref{tab:Ellsberg EU recommendations}).

\begin{table}[ht]
	\[
	\begin{array}{lcc}
		\toprule
		\text{Constraint on } p(\emph{Yellow}) & \EU_p(D^{\mathrm{Ellsberg}}_1) & \EU_p(D^{\mathrm{Ellsberg}}_2) \\
		\midrule
		p(\emph{Yellow}) < \tfrac{7}{30} & \{1B'\} & \{2B\} \\[1mm]
		p(\emph{Yellow}) = \tfrac{7}{30} & \{1B'\} & \{2A,\,2B\} \\[1mm]
		\tfrac{7}{30} < p(\emph{Yellow}) < \tfrac{13}{30} & \{1B'\} & \{2A\} \\[1mm]
		p(\emph{Yellow}) = \tfrac{13}{30} & \{1A,\,1B'\} & \{2A'\} \\[1mm]
		p(\emph{Yellow}) > \tfrac{13}{30} & \{1A\} & \{2A'\} \\
		\bottomrule
	\end{array}
	\]
\caption{EU\(_p\) recommendations for decisions \(D^{\mathrm{Ellsberg}}_1\) and \(D^{\mathrm{Ellsberg}}_2\).\label{tab:Ellsberg EU recommendations}}

\end{table}

So, faced with $D^{\mathrm{Ellsberg}}_1$, either 1A or 1B is E-Admissible; and faced with $D^{\mathrm{Ellsberg}}_2$, either 2A or 2B is E-Admissible. And so any picking strategy picks for E-Admissibility in this case. However, the strategy that picks $1A$ from $D^{\mathrm{Ellsberg}}_1$ and $2B$ from $D^{\mathrm{Ellsberg}}_2$ picks for E-Admissibility, but it does not maximize expected utility by the lights of any $\langle p, \mu \rangle$ in $\IB$. That is, it is not in $\EAd_\IB(\S)$. 

There are, however, strategies that pick for E-Admissibility and that E-Admissibility deems permissible: that is, $\s$ picks for $\EAd_\IP$, and $\s$ is in $\EAd_\IB(\S)$. For example, the strategy that picks $1A$ from $D^{\mathrm{Ellsberg}}_1$ and $2A$ from $D^{\mathrm{Ellsberg}}_2$. 

So E-admissibility deems some of its strategies permissible and others not. In fact, for every E-Admissible act in a fixed decision $D$, there is an E-Admissibility strategy which is E-Admissible and which selects that option in $D$. What might be ruled out, however, is certain combinations. For the strategy to be E-Admissible, it requires coordination across the various decision problems. 




%
%
%What does our decision theory tell us to choose in these decisions? 
%
%In $D^{\mathrm{Ellsberg}}_1$, the $\EU_p$ action is to chooses $1A$ if $p(\text{Red})>\sfrac{1}{3}$ and $1B$ if $p(\text{Red})<\sfrac{1}{3}$. When $p(\text{Red})>\sfrac{1}{3}$, it is indifferent and thus both ways of picking in $\EU_p$. Thus, for $D^{\mathrm{Ellsberg}}_1$, both picking $1A$ and $1B$ are E-Admissible actions, as one has a credal set containing both such probabilities. 
%
%In $D^{\mathrm{Ellsberg}}_2$, the $\EU_p$ action is to chooses $2A$ if $p(\text{Yellow})>\sfrac{1}{3}$ and $2B$ if $p(\text{Yellow})<\sfrac{1}{3}$. Thus, again, for $D^{\mathrm{Ellsberg}}_2$, both picking $2A$ and $2B$ are E-Admissible actions, as one has a credal set containing both such probabilities. 
%
%We can now judge which \emph{strategies} are E-Admissible. To do this we need to specify your uncertainty, $\mu$, over which decision you'll be faced with. Let's suppose you think it's equally likely. 




\subsection{$\Gamma$-maximin}
Some decision theories go beyond E-Admissibility and permit only some subset of the E-Admissible acts. Any such theory will be susceptible to the same self-undermining concerns that we saw affecting E-admissibility above: there will be strategies that pick for the choice function given by that theory that the theory itself deems impermissible. The situation may in fact be worse for such theories because for E-Admissibility there are guaranteed to be some strategies that pick for E-Admissibility that E-Admissibility also permits: strategies that successfully coordinate across decisions. But for more restrictive theories these coordinated strategies may be ruled out by the theory, and we might have the result that all the strategies that pick for the theory's choice function are deemed impermissible by the theory. 

A prominent example of a theory that is more restrictive than E-Admissibility is $\Gamma$-Maximin. 

\begin{definition}[$\Gamma$-Maximin$_\IP$ ($\Maximin_\IP$) ] 
$$
\Maximin_\IP(D) = \left \{ a \in D \mid (\forall a' \in D)\left [\min_{p \in \IP} \Exp_p[\U(a)'] \leq \min_{p \in \IP} \Exp_p[\U(a)] \right ] \right \}
$$
(This should only be applied when these minima exist, e.g., when $\IP$ is a closed convex set.)\todoold{closed? closed and convex?}
\end{definition}
In the Ellsberg case as described above, this requires one to select $1A$ in $D^{\mathrm{Ellsberg}}_1$ and $2B$ in $D^{\mathrm{Ellsberg}}_2$; that is the only strategy recommended by $\Maximin_\IP$ is one that is not E-Admissible. It is thus also not itself acceptable according to Maximin. That is, there is a unique $\Maximin_\IP$ strategy $\s$, and this is not in $\Maximin_{\IB}(\S)$. Maximin undermines its own recommendations, evaluating its unique picking strategy to be impermissible. 

\todooldinfo{Do we have a general result saying that for any $\mu$, Gamma-Maximin undermines all the compatible strategies?? RP: my sense is we can't get this, because there will be some string of decision problems whose $\min_{p \in P}$ is given by a single p in P.}
















% That is, is $\s_{\mathrm{Ellsberg}}$ in $\Maximin_\IB(\S)$? And the answer is no. If an act $a$ is permissible by the lights of $\Gamma$-Maximin applied to a credal set $\IP$, then there must be some $p$ in $\IP$ for which $a$ maximizes expected utility. After all, as we saw above, if $\s$ maximizes expected utility for $\langle p, \mu \rangle$, then $\s$ picks for $\EU_p$. But $\s_{\mathrm{Ellsberg}}$ does not maximize expected utility for any $\langle p, \mu \rangle$ in $\IB$. Indeed, this fact accounts for Ellsberg's use of the case: like Allais, he wished to provide natural preferences that could not be captured by expected utility theory. So, at least in the Ellsberg case, where we are uncertain whether we'll face $D^{\mathrm{Ellsberg}}_1$ or $D^{\mathrm{Ellsberg}}_2$, $\Gamma$-Maximin is self-undermining. The only picking strategy that picks for that decision theory with $\IP$---namely, $\s_{\mathrm{Ellsberg}}$---is not permitted by that decision theory with $\IB$.


%We can then judge which strategies are E-Admissible, i.e., which strategies are such that there is at least one probability function which evaluates them as optimal. To answer this, we have to describe the agent's uncertainty over the states of the world and the decision problems together. We will represent this with a set of probabilities $\IB$ over $\Omega\times\D$, where each probability in $\IB$ treats $\Omega$ and $\D$ as independent. So we can equally think of $\IB$ as a set of pairs $p\times \mu$ where $p$ is in probability function over $\Omega$ and $\mu$ is a probability function over $\D$. For $\IB$ to extend $\IP$, it must be that... \todooldinfo{JK to help with making this stuff correct}


%We now have the tools to apply the criteria of E-Admissibility to strategies themselves. First, we specify the set of picking strategies that E-Admissibility deems permissible:% and we have:%\todooldinfo{is this now a defn or a thm??} 
%\begin{definition}
% $$\EAd_\IB(\Strategies) = \Set{\s \in \Strategies \given (\exists \langle p, \mu \rangle \in \IB)(\forall \s' \in \Strategies)(\Exp_{p, \mu}[\U(\s)]\geq\EU_{p\times\mu}[\U(\s')]})$$
%\end{definition}
%But we know from \cref{thm:eu-uniquely-optimal} that the only strategies which maximise $\EU_{p\times\mu}[\U(\s)]$ are those that $\mu$-surely pick for $\EU_p$. We thus immediately have:
%\begin{theorem}
%	$\s\in\EAd_{\IB}(\Strategies)$ iff $\s$  $\mu$-surely picks for $\EU_p$, for some $p\times \mu\in \IB$. 
%\end{theorem}
%This tells us that the only strategies that are E-Admissible are those that $\mu$ is certain pick for $\EU_p$, for some $p$ in the credal set $\IP$. 





%Suppose you have imprecise credal set $\Set{p_1,p_2}$, where $p_1$ recommends $a_1$ and $p_2$ recommends $a_2$. The E-admissible s

%This requires coordination across decision problems! There is no \emph{inherent} imprecision permissible. \todoold{this final sentence needs to be moved}




%\subsection{Reflections}
\subsection{Can a decision theory require coordination?}
$\Gamma$-Maximin requires one to choose options that the original theory rejects. It undermines its own recommendations. This is a significant problem. 

For E-Admissibility it is not quite so problematic as it only rejects some strategies compatible with its recommendations. What we learn from this is that E-Admissibility requires us to coordinate our picking plans across various decision problems we think we might be faced with. 

This is perhaps quite familiar to supporters of E-Admissibility. The kind of case we have described can also be used to demonstrated diachronic irrationality and it can be responded to by requiring coordination between ones way of picking across time. \todoold{refs etc!!!}

There is something a bit more problematic in applying this strategy to choice strategies rather than diachronic coordination. There's something weird about it that it's not just giving you guidance in each case, which is kind of what we thought a dec theory would do?? For example, when the general formalism is developed for imprecise probability it is presented in terms of so-called choice functions. These prescribe a set of acts from each decision which are those that are not ruled out. It is $C:\D\to\A$; there's nothing in this formalism to describe coordination. 

\todooldinfo{help me with this above section please. RP: I'm not sure what to say either! It seems to me that resolute choice (i.e. coordination) is as good a solution in our case as in the diachronic case? But I take it the two arguments we gave in 1.1 against self-undermining theories are arguments against resolute choice. Yes, you could be resolute, but it gives rise to dilemmas: you have reason beforehand to commit to a coordinated resolute decision, but then when faced with the decision, you've no reason to stick with that commitment.}

\todoold{we thought of a segway into next section, but now I don't see it.}



\subsection{Maximality and more general choice functions}\label{sect:Max}


\todooldinfo{I think this section is the right track, but will need writing up better.}
We have so far looked at the imprecise decision theories of E-Admissibility and $\Gamma$-Maximin, and shown that only the strategies that $\mu$-surely pick for $\EU_p$ for some $p$ in $\IP$ that are evaluated as permissible according to these theories.% because it is only these strategies which are evaluated as optimal according to some probability $p$ in the credal set $\IP$. 
The argument does not, however, apply directly to the decision rule of Maximality. 
Maximality only rejects an available action if there is a particular alternative which every probability in $\IP$ agrees to be better. It is not sufficient that each probability in $\IP$ thinks that something is better. 

\begin{definition}
	$a\in \Maximality_\IP(D)$ iff $$\exists a'\in D\;\forall p\in\IP\quad \Exp_p(a')>\Exp_p(a')$$
\end{definition}
%\todooldinfo{should we introduce more general choice functions too??}





\end{document}
